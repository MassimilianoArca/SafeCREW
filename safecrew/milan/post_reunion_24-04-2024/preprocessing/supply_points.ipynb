{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supply Points (Case dell'Acqua) Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_folder = os.path.join('..', '..', 'utils')\n",
    "\n",
    "with open(os.path.join(utils_folder, 'onedrive.txt'), 'r') as f:\n",
    "    cloud_data_folder = os.path.join(f.readline().strip(), 'Case dell\\'acqua')\n",
    "\n",
    "grab_samples_folder = os.path.join(cloud_data_folder, \"Grab Samples\")\n",
    "sensors_folder = os.path.join(cloud_data_folder, \"Sensori\")\n",
    "\n",
    "local_data_folder = os.path.join('..', '..', 'data', 'second_phase')\n",
    "clean_data_folder = os.path.join(local_data_folder, \"Clean Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tra i grab non c'è l'ORP, mentre\n",
    "# tra i sensori non c'è DOC (c'è il TOC) e L'UVA254\n",
    "\n",
    "# Quindi in comune abbiamo:\n",
    "# Color, TOC, Nitrati, Turbidity, pH, Temperature, Conductivity, Free Chlorine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Grab Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_df = pd.DataFrame()\n",
    "for filename in os.listdir(grab_samples_folder):\n",
    "    if grab_df.empty:\n",
    "        grab_df = pd.read_excel(os.path.join(grab_samples_folder, filename))\n",
    "    else:\n",
    "        df = pd.read_excel(os.path.join(grab_samples_folder, filename))\n",
    "        grab_df = pd.concat([grab_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(utils_folder, \"columns_types.json\")) as f:\n",
    "    column_types = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns = column_types[\"metadata_columns\"]\n",
    "features_columns = column_types[\"features_columns\"]\n",
    "targets_columns = column_types[\"targets_columns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns that are not in the column_types.json file\n",
    "grab_df = grab_df[metadata_columns + features_columns + targets_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix LOD values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def convert_string_values(s):\n",
    "    if isinstance(s, (int, float)):\n",
    "        return s\n",
    "    elif pd.isna(s):\n",
    "        return None\n",
    "    else:\n",
    "        if \",\" in s:\n",
    "            s = s.replace(\",\", \".\")\n",
    "        if \"<\" in s:\n",
    "            number = re.findall(r\"\\d+\\.?\\d*\", s)\n",
    "            return float(number[0]) / 2 if number else None\n",
    "        elif \">\" in s:\n",
    "            number = re.findall(r\"\\d+\\.?\\d*\", s)\n",
    "            return float(number[0]) if number else None\n",
    "        elif \"*\" in s or re.search(\"[a-zA-Z]\", s):\n",
    "            number = re.findall(r\"\\d+\\.?\\d*\", s)\n",
    "            return float(number[0]) if number else None\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_label(value):\n",
    "    if isinstance(value, (int, float)):\n",
    "        return \"Normal\"\n",
    "    elif pd.isna(value):\n",
    "        return \"Normal\"\n",
    "    elif \"<\" in value:\n",
    "        return \"Less than\"\n",
    "    elif \">\" in value:\n",
    "        return \"Greater than\"\n",
    "    else:\n",
    "        return \"Normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in features_columns + targets_columns:\n",
    "    label_column = column + \"_label\"\n",
    "    grab_df.loc[:, label_column] = grab_df[column].apply(set_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_df[features_columns] = grab_df[features_columns].map(\n",
    "    convert_string_values\n",
    ")\n",
    "\n",
    "grab_df[targets_columns] = grab_df[targets_columns].map(\n",
    "    convert_string_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sensor Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_dict = {}\n",
    "\n",
    "for sensor_file in os.listdir(sensors_folder):\n",
    "    if sensor_file == \".DS_Store\":\n",
    "        continue\n",
    "    \n",
    "    sensor_folder = os.path.join(sensors_folder, sensor_file)\n",
    "    for filename in os.listdir(sensor_folder): \n",
    "        \n",
    "        if not filename.endswith(\".xlsx\"):\n",
    "            continue\n",
    "        \n",
    "        house_code = filename.split(\"_\")[0]\n",
    "        if house_code not in sensor_dict:\n",
    "            sensor_dict[house_code] = pd.read_excel(os.path.join(sensor_folder, filename), header=1)\n",
    "        else:\n",
    "            df = pd.read_excel(os.path.join(sensor_folder, filename), header=1)\n",
    "            sensor_dict[house_code] = pd.concat([sensor_dict[house_code], df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_dict['via TABACCHI'].columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_mapping = {\n",
    "    \"Measurement interval=900[sec] (Export-Aggregation disabled)\": \"DateTime\",\n",
    "    \"Measurement interval=999[sec] (Export-Aggregation disabled)\": \"DateTime\",\n",
    "    \"Measurement interval=0[sec] (Export-Aggregation disabled)\": \"DateTime\",\n",
    "    \"COLORtrue - Measured value [Hazen-eq.] (Limit:0.00-300.00)\": \"Color (CU)\",\n",
    "    \"TOCeq - Measured value [mg/l] (Limit:0.00-22.00)\": \"TOC (mg/l)\",\n",
    "    \"NO3eq - Measured value [mg/l] (Limit:0.00-88.00)\": \"Nitrate (mg/l)\",\n",
    "    \"UV254t - Measured value [Abs/m] (Limit:0.00-71.00)\": \"UVA254 (1/m)\",\n",
    "    \"Turbidity - Measured value [FTUeq] (Limit:0.00-170.00)\": \"Turbidity (FTU)\",\n",
    "    \"pH - Measured value (Limit:0.00-14.00)\": \"pH\",\n",
    "    \"Temperature - Measured value [C] (Limit:-5.00-100.00)\": \"Temperature (°C)\",\n",
    "    \"Conductivity - Measured value [uS/cm] (Limit:0.10-600000.00)\": \"Conductivity (μS/cm)\",\n",
    "    \"Free Chlorine - Measured value [mg/l] (Limit:0.00-2.00)\": \"Free Chlorine (mg/l)\",\n",
    "}\n",
    "\n",
    "\n",
    "for house_code, df in sensor_dict.items():\n",
    "    sensor_dict[house_code] = df.rename(columns=columns_mapping)\n",
    "    \n",
    "    # set to get unique values\n",
    "    columns = set(columns_mapping.values())\n",
    "    \n",
    "    \n",
    "    sensor_dict[house_code] = sensor_dict[house_code][list(columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_df.drop(\n",
    "    columns=[\n",
    "        'Codice punto di prelievo',\n",
    "        'Rapporto di prova',\n",
    "    ],\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_df['Punto di prelievo'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change name of Punta di prelievo values to match codes\n",
    "def change_name(name):\n",
    "    if \"Tognazzi\" in name:\n",
    "        return \"Tognazzi\"\n",
    "    elif \"Tabacchi\" in name:\n",
    "        return \"Tabacchi\"\n",
    "    elif \"Gramsci\" in name:\n",
    "        return \"Gramsci\"\n",
    "    elif \"Berna\" in name:\n",
    "        return \"Berna\"\n",
    "    elif \"Bande Nere\" in name or \"Piazzale Giovanni\" in name:\n",
    "        return \"Bande Nere\"\n",
    "    elif \"Prealpi\" in name:\n",
    "        return \"Prealpi\"\n",
    "    elif \"Chiostergi\" in name:\n",
    "        return \"Chiostergi\"\n",
    "    elif \"Montevideo\" in name or \"Montevid\" in name:\n",
    "        return \"Montevideo\"\n",
    "    elif \"Fortunato\" in name:\n",
    "        return \"Fortunato\"\n",
    "    else:\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_df['Punto di prelievo'] = grab_df['Punto di prelievo'].map(change_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_df['Data di prelievo'] = pd.to_datetime(grab_df['Data di prelievo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the name of the keys to match the names in the grab_df\n",
    "sensor_dict['Tabacchi'] = sensor_dict.pop('via TABACCHI')\n",
    "sensor_dict['Tognazzi'] = sensor_dict.pop('via Tognazzi')\n",
    "sensor_dict['Prealpi'] = sensor_dict.pop('Piazza Prealpi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in grab_df['Punto di prelievo'].unique():\n",
    "    sensor_df = sensor_dict.pop(code)\n",
    "    sensor_df['DateTime'] = pd.to_datetime(sensor_df['DateTime'])\n",
    "    sensor_df.set_index('DateTime', inplace=True)\n",
    "    sensor_dict[code] = sensor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute number of missing values for each column\n",
    "for code in grab_df['Punto di prelievo'].unique():\n",
    "    code_df = grab_df[grab_df['Punto di prelievo'] == code]\n",
    "    for column in features_columns + targets_columns:\n",
    "        # count the number of missing values\n",
    "        missing_values = code_df[column].isna().sum()\n",
    "        if missing_values > 0:\n",
    "            print(f\"{code} has {missing_values} missing values in column {column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute number of rows that have at least one missing value\n",
    "for code in grab_df['Punto di prelievo'].unique():\n",
    "    code_df = grab_df[grab_df['Punto di prelievo'] == code]\n",
    "    \n",
    "    missing_values = code_df[features_columns + targets_columns].isna().any(axis=1).sum()\n",
    "    if missing_values > 0:\n",
    "        print(f\"{code} has {missing_values} rows with missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the Berna rows with missing values\n",
    "row_index = grab_df[\n",
    "    (grab_df['Punto di prelievo'] == \"Berna\") & (grab_df[features_columns + targets_columns].isna().any(axis=1))\n",
    "].index\n",
    "\n",
    "grab_df.drop(row_index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the moment no imputation is done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in sensor_dict.keys():\n",
    "    sensor_df = sensor_dict[code]\n",
    "    for column in sensor_df.columns:\n",
    "        missing_values = sensor_df[column].isna().sum()\n",
    "        if missing_values > 0:\n",
    "            print(f\"{code} has {missing_values} missing values in column {column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of missing values is very low, so we can do implicit imputation with time interpolation\n",
    "for code in sensor_dict.keys():\n",
    "    sensor_df = sensor_dict.pop(code)\n",
    "    sensor_df.interpolate(method='time', inplace=True)\n",
    "    sensor_dict[code] = sensor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_df.to_excel(os.path.join(clean_data_folder, \"grab.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(clean_data_folder, \"sensors\")):\n",
    "    os.mkdir(os.path.join(clean_data_folder, \"sensors\"))\n",
    "    \n",
    "for code in sensor_dict.keys():\n",
    "    sensor_dict[code].to_excel(os.path.join(clean_data_folder, \"sensors\", f\"{code}.xlsx\"), index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safecrew-3OLHM_8n-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
