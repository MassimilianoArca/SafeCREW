{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supply Points Analysis between Grab and Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from statsmodels.tsa.seasonal import STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_folder = os.path.join('..', '..', 'utils')\n",
    "\n",
    "data_folder = os.path.join('..', '..', 'data')\n",
    "clean_data_folder = os.path.join(data_folder, 'Clean Data')\n",
    "metadata_folder = os.path.join(data_folder, 'Metadata')\n",
    "plot_folder = os.path.join(data_folder, 'Plots')\n",
    "\n",
    "sensor_folder = os.path.join(clean_data_folder, 'sensors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_df = pd.read_excel(os.path.join(clean_data_folder, 'grab.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_dict = {}\n",
    "\n",
    "for file in os.listdir(sensor_folder):\n",
    "    if file.endswith('.xlsx'):\n",
    "        sensor_dict[file.split('.')[0]] = pd.read_excel(os.path.join(sensor_folder, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(utils_folder, \"columns_types.json\")) as f:\n",
    "    column_types = json.load(f)\n",
    "    \n",
    "metadata_columns = column_types[\"metadata_columns\"]\n",
    "features_columns = column_types[\"features_columns\"]\n",
    "targets_columns = column_types[\"targets_columns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import contains\n",
    "\n",
    "\n",
    "label_columns = [col for col in grab_df.columns if contains(col, 'label')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename grab columns\n",
    "feature_mapping = {\n",
    "    \"Cloro residuo libero (al prelievo) (mg/L di Cl2)\": \"Free Chlorine (mg/L)\",\n",
    "    \"Colore (Cu)\": \"Color (CU)\",\n",
    "    \"Concentrazione ioni idrogeno (unità pH)\": \"pH\",\n",
    "    \"Conduttività a 20°C (µS/cm)\": \"Conductivity (uS/cm)\",\n",
    "    \"TOC - carbonio organico totale (mg/L di C)\": \"TOC (mg/L)\",\n",
    "    \"Temperatura (al prelievo) (°C)\": \"Temperature (°C)\",\n",
    "    \"Torbidità (NTu)\": \"Turbidity (NTU)\",\n",
    "    \"Nitrati (mg/L)\": \"Nitrate (mg/L)\",\n",
    "    \n",
    "}\n",
    "\n",
    "targets_mapping = {\n",
    "    \"Batteri coliformi a 37°C (MPN/100 mL)\": \"Coliforms (MPN/100mL)\",\n",
    "    \"Bromodiclorometano (µg/L)\": \"Bromodichloromethane (µg/L)\",\n",
    "    \"Bromoformio (µg/L)\": \"Bromoform (µg/L)\",\n",
    "    \"Cloroformio (µg/L)\": \"Chloroform (µg/L)\",\n",
    "    \"Conta delle colonie a 22°C (UFC/mL)\": \"Colony count at 22°C (UFC/mL)\",\n",
    "    \"Conteggio colonie a 30°C (UFC/mL)\": \"Colony count at 30°C (UFC/mL)\",\n",
    "    \"Conta delle colonie a 37°C (UFC/mL)\": \"Colony count at 37°C (UFC/mL)\",\n",
    "    \"Dibromoclorometano (µg/L)\": \"Dibromochloromethane (µg/L)\",\n",
    "    \"Enterococchi (MPN/100 mL)\": \"Enterococci (MPN/100mL)\",\n",
    "    \"Escherichia coli (MPN/100 mL)\": \"Escherichia coli (MPN/100mL)\",\n",
    "    \"Pseudomonas aeruginosa (UFC/250 mL)\": \"Pseudomonas aeruginosa (UFC/250mL)\",\n",
    "    \"Acido Perfluoroottanoico PFOA (µg/L)\": \"Perfluorooctanoic acid PFOA (µg/L)\",\n",
    "    \"Acido Perfluoroottansolfonico PFOS (µg/L)\": \"Perfluorooctanesulfonic acid PFOS (µg/L)\",\n",
    "    \"Somma di PFAS (µg/L)\": \"Sum of PFAS (µg/L)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename grab_df columns that contain features\n",
    "for column in grab_df.columns:\n",
    "    if column in targets_mapping:\n",
    "        grab_df.rename(columns={column: targets_mapping[column]}, inplace=True)\n",
    "        \n",
    "    if len(column.split('_')) > 1:\n",
    "        if column.split('_')[0] in feature_mapping:\n",
    "            new_name = feature_mapping[column.split('_')[0]]\n",
    "            new_name = new_name + '_' + column.split('_')[1]\n",
    "            grab_df.rename(columns={column: new_name}, inplace=True)\n",
    "            \n",
    "        if column.split('_')[0] in targets_mapping:\n",
    "            new_name = targets_mapping[column.split('_')[0]]\n",
    "            new_name = new_name + '_' + column.split('_')[1]\n",
    "            grab_df.rename(columns={column: new_name}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the label columns\n",
    "for column in grab_df.columns:\n",
    "    if column in label_columns:\n",
    "        \n",
    "        variable_name = column.split('_')[0]\n",
    "        \n",
    "        if variable_name in feature_mapping:\n",
    "            new_name = feature_mapping[variable_name]\n",
    "            new_name = new_name + '_' + column.split('_')[1]\n",
    "            grab_df.rename(columns={column: new_name}, inplace=True)\n",
    "            \n",
    "        if variable_name in targets_mapping:\n",
    "            new_name = targets_mapping[variable_name]\n",
    "            new_name = new_name + '_' + column.split('_')[1]\n",
    "            grab_df.rename(columns={column: new_name}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(\n",
    "    columns=pd.MultiIndex.from_product([feature_mapping.values(), ['N° Entries', 'N° Valid Samples', 'N° Missing', 'N° < LOQ', 'Mean', 'Std', 'Start Date', 'End Date']]),\n",
    "    index=grab_df['Code'].unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in grab_df['Code'].unique():\n",
    "    for feature in feature_mapping.values():\n",
    "        df = grab_df[grab_df['Code'] == code][['DateTime', feature, feature + \"_label\" ]].copy()\n",
    "    \n",
    "        if df.dropna().shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "\n",
    "    \n",
    "        start_date = df.dropna()['DateTime'].min().strftime(\"%Y-%m-%d\")\n",
    "        end_date = df.dropna()['DateTime'].max().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "\n",
    "        df = df[(df['DateTime'] >= start_date) & (df['DateTime'] <= end_date)]\n",
    "\n",
    "        missing_values = df[df[feature + '_label'].isna()].shape[0] / df.shape[0] * 100\n",
    "        \n",
    "        feature_df.loc[code, (feature, 'N° Entries')] = df.shape[0]\n",
    "\n",
    "        feature_df.loc[code, (feature, 'N° Valid Samples')] = (\n",
    "            df[feature + \"_label\"].notna().sum()\n",
    "        )\n",
    "        feature_df.loc[\n",
    "            code, (feature, \"N° Missing\")\n",
    "        ] = round(missing_values, 2)\n",
    "        \n",
    "        feature_df.loc[code, (feature, 'N° < LOQ')] = df[df[feature + \"_label\"] == \"Less than\"].shape[0]\n",
    "        \n",
    "        feature_df.loc[code, (feature, \"Mean\")] = df[feature].mean()\n",
    "        feature_df.loc[code, (feature, \"Std\")] = df[feature].std()\n",
    "        \n",
    "        feature_df.loc[code, (feature, \"Start Date\")] = start_date\n",
    "        feature_df.loc[code, (feature, \"End Date\")] = end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df = pd.DataFrame(\n",
    "    columns=pd.MultiIndex.from_product([targets_mapping.values(), ['N° Entries', 'N° Valid Samples', 'N° Missing', 'N° < LOQ', 'Mean', 'Std', 'Start Date', 'End Date']]),\n",
    "    index=grab_df['Code'].unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in grab_df['Code'].unique():\n",
    "    for target in targets_mapping.values():\n",
    "        df = grab_df[grab_df['Code'] == code][['DateTime', target, target + \"_label\" ]].copy()\n",
    "    \n",
    "        if df.dropna().shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "\n",
    "    \n",
    "        start_date = df.dropna()['DateTime'].min().strftime(\"%Y-%m-%d\")\n",
    "        end_date = df.dropna()['DateTime'].max().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "\n",
    "        df = df[(df['DateTime'] >= start_date) & (df['DateTime'] <= end_date)]\n",
    "\n",
    "        missing_values = df[df[target + '_label'].isna()].shape[0] / df.shape[0] * 100\n",
    "        \n",
    "        targets_df.loc[code, (target, 'N° Entries')] = df.shape[0]\n",
    "\n",
    "        targets_df.loc[code, (target, 'N° Valid Samples')] = (\n",
    "            df[target + \"_label\"].notna().sum()\n",
    "        )\n",
    "        targets_df.loc[\n",
    "            code, (target, \"N° Missing\")\n",
    "        ] = round(missing_values, 2)\n",
    "        \n",
    "        targets_df.loc[code, (target, 'N° < LOQ')] = df[df[target + \"_label\"] == \"Less than\"].shape[0]\n",
    "        \n",
    "        targets_df.loc[code, (target, \"Mean\")] = df[target].mean()\n",
    "        targets_df.loc[code, (target, \"Std\")] = df[target].std()\n",
    "        \n",
    "        targets_df.loc[code, (target, \"Start Date\")] = start_date\n",
    "        targets_df.loc[code, (target, \"End Date\")] = end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "feature_df.to_excel(\n",
    "    os.path.join(metadata_folder, 'Grab', 'features.xlsx')\n",
    ")\n",
    "\n",
    "targets_df.to_excel(\n",
    "    os.path.join(metadata_folder, 'Grab', 'targets.xlsx')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fix Conductivity name\n",
    "for sensor in sensor_dict:\n",
    "    sensor_dict[sensor].rename(columns={'Conductivity (μS/cm)': 'Conductivity (uS/cm)'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_columns = sensor_dict['Berna'].columns.difference(['DateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_df = pd.DataFrame(\n",
    "    columns=pd.MultiIndex.from_product([sensor_columns, ['N° Data', 'N° Missing', 'Mean', 'Std']]),\n",
    "    index=list(sensor_dict.keys())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sensor in sensor_dict.keys():\n",
    "    for column in sensor_columns:\n",
    "        \n",
    "        if sensor == 'Berna' and column == 'Turbidity (FTU)':\n",
    "            \n",
    "            df = sensor_dict[sensor].copy()\n",
    "            # remove rows with Turbidity > 2\n",
    "            df = df[df['Turbidity (FTU)'] <= 2]\n",
    "            \n",
    "            \n",
    "            sensors_df.loc[sensor, (column, 'N° Data')] = df[column].count()\n",
    "            sensors_df.loc[sensor, (column, 'N° Missing')] = df[column].isna().sum()\n",
    "            sensors_df.loc[sensor, (column, 'Mean')] = df[column].mean()\n",
    "            sensors_df.loc[sensor, (column, 'Std')] = df[column].std()\n",
    "            continue\n",
    "            \n",
    "        sensors_df.loc[sensor, (column, 'N° Data')] = sensor_dict[sensor][column].count()\n",
    "        sensors_df.loc[sensor, (column, 'N° Missing')] = sensor_dict[sensor][column].isna().sum()\n",
    "        sensors_df.loc[sensor, (column, 'Mean')] = sensor_dict[sensor][column].mean()\n",
    "        sensors_df.loc[sensor, (column, 'Std')] = sensor_dict[sensor][column].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_df.to_excel(\n",
    "    os.path.join(metadata_folder, 'Sensor', 'sensors.xlsx')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the time series of the sensors and the grab data\n",
    "\n",
    "for code in grab_df['Code'].unique():\n",
    "    for feature in feature_mapping.values():\n",
    "        \n",
    "        g_df = grab_df[grab_df['Code'] == code].copy()\n",
    "        \n",
    "        s_df = sensor_dict[code].copy()\n",
    "        \n",
    "        \n",
    "        # moving average on sensor data\n",
    "        \n",
    "        ma_s_df = s_df.copy()\n",
    "        \n",
    "        ma_s_df.set_index('DateTime', inplace=True)\n",
    "        ma_s_df = ma_s_df.rolling(window=4*24).mean()  \n",
    "        \n",
    "        loess_s_df = s_df.copy()\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=g_df['DateTime'],\n",
    "                y=g_df[feature],\n",
    "                mode='markers',\n",
    "                name='Grab'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=s_df['DateTime'],\n",
    "                y=s_df[feature],\n",
    "                mode='lines',\n",
    "                name='Sensor'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=ma_s_df.index,\n",
    "                y=ma_s_df[feature],\n",
    "                mode='lines',\n",
    "                name='Sensor MA'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f'{code} - {feature}',\n",
    "            xaxis_title='DateTime',\n",
    "            yaxis_title=feature\n",
    "        )\n",
    "        \n",
    "        if not os.path.exists(os.path.join(plot_folder, \"Comparison\", \"15min\", \"Timeseries\", code)):\n",
    "            os.makedirs(os.path.join(plot_folder, \"Comparison\", \"15min\", 'Timeseries', code))\n",
    "        \n",
    "        feature_ = feature.replace('/', '_')\n",
    "        \n",
    "        # fig.write_image(\n",
    "        #     os.path.join(\n",
    "        #         plot_folder, \"Comparison\", \"15min\", \"Timeseries\", code, f'{feature_}.png'\n",
    "        #     )\n",
    "        # )\n",
    "        \n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplot Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the boxplots of the sensor data all together, without the code\n",
    "\n",
    "sensor_df = pd.concat(sensor_dict.values())\n",
    "\n",
    "for column in sensor_columns:\n",
    "    \n",
    "    fig = go.Figure()\n",
    "        \n",
    "    fig.add_trace(\n",
    "        go.Box(\n",
    "            y=sensor_df[column],\n",
    "            name=column\n",
    "        )\n",
    "    )\n",
    "        \n",
    "    fig.update_layout(\n",
    "        title=f'{column}',\n",
    "        yaxis_title=column\n",
    "    )\n",
    "    \n",
    "    column_ = column.replace('/', '_')\n",
    "    \n",
    "    fig.write_image(\n",
    "        os.path.join(\n",
    "            metadata_folder, 'Sensor', f'{column_}.png'\n",
    "        )\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the box plot of grab data and sensor data\n",
    "\n",
    "for code in grab_df['Code'].unique():\n",
    "    for feature in feature_mapping.values():\n",
    "        \n",
    "        g_df = grab_df[grab_df['Code'] == code].copy()\n",
    "        \n",
    "        s_df = sensor_dict[code].copy()\n",
    "        \n",
    "        # resample the sensor data\n",
    "        s_df['DateTime'] = pd.to_datetime(s_df['DateTime'])\n",
    "        s_df.set_index('DateTime', inplace=True)\n",
    "        s_df = s_df.resample('D').mean().reset_index()\n",
    "        \n",
    "        if feature == 'Free Chlorine (mg/l)':\n",
    "            s_df = s_df[s_df[feature] < 5]\n",
    "            \n",
    "        if feature == 'TOC (mg/l)':\n",
    "            s_df = s_df[s_df[feature] < 2]\n",
    "            \n",
    "        if feature == 'Turbidity (FTU)':\n",
    "            s_df = s_df[s_df[feature] < 1.5]\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=g_df[feature],\n",
    "                name='Grab'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=s_df[feature],\n",
    "                name='Sensor'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f'{code} - {feature}',\n",
    "            yaxis_title=feature\n",
    "        )\n",
    "        \n",
    "        if not os.path.exists(os.path.join(plot_folder, \"Comparison\", \"15min\", \"Boxplot\", code)):\n",
    "            os.makedirs(os.path.join(plot_folder, \"Comparison\", \"15min\", 'Boxplot', code))\n",
    "            \n",
    "        feature_ = feature.replace('/', '_')\n",
    "        \n",
    "        fig.write_image(\n",
    "            os.path.join(\n",
    "                plot_folder, \"Comparison\", \"15min\", \"Boxplot\", code, f'{feature_}.png'\n",
    "            )\n",
    "        )\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safecrew-3OLHM_8n-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
