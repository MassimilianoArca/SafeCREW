{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_folder = os.path.join(\"..\", \"..\", \"utils\")\n",
    "\n",
    "data_folder = os.path.join(\"..\", \"..\", \"data\")\n",
    "clean_data_folder = os.path.join(data_folder, \"Clean Data\")\n",
    "metadata_folder = os.path.join(data_folder, \"Metadata\")\n",
    "plot_folder = os.path.join(data_folder, \"Plots\", \"Feltre\")\n",
    "\n",
    "sensor_folder = os.path.join(clean_data_folder, \"sensors\")\n",
    "\n",
    "feltre_sqlites_folder = 'feltre_sqlites_second'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_part_df = pd.read_excel(os.path.join(clean_data_folder, 'Feltre', 'second_part.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrelation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_part_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variables = [\n",
    "    'ICC [1/mL]',\n",
    "    'HNAC [1/mL]',\n",
    "    # 'LNAC [1/mL]',\n",
    "    # 'HNAP [%]',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_variables = [\n",
    "    'Pressione [atm]',\n",
    "    'TOCeq [mg/l]',\n",
    "    'DOCeq [mg/l]',\n",
    "    'Turbidity [FTU]',\n",
    "    'Conductivity [uS/cm]',\n",
    "    'Temperature [°C]',\n",
    "    'pH',\n",
    "    'Free Chlorine [mg/l]',\n",
    "    'Nitrate [mg/l]',\n",
    "    'UV254 [1/m]',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in input_variables:\n",
    "    fig, ax = plt.subplots(figsize=(20, 12))\n",
    "    plot_acf(\n",
    "        second_part_df[variable],\n",
    "        lags=second_part_df.shape[0]-1,\n",
    "        title=variable,\n",
    "        use_vlines=True,\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    variable_ = variable.replace('/', '_')\n",
    "    \n",
    "    # plt.savefig(f'autocorrelation_{variable_}.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in target_variables:\n",
    "    fig, ax = plt.subplots(figsize=(20, 12))\n",
    "    plot_acf(\n",
    "        second_part_df[variable],\n",
    "        lags=second_part_df.shape[0]-1,\n",
    "        title=variable,\n",
    "        use_vlines=True,\n",
    "        ax=ax\n",
    "    )\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Autocorrelation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in input_variables:\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    plot_pacf(\n",
    "        second_part_df[variable],\n",
    "        title=variable,\n",
    "        use_vlines=True,\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    variable_ = variable.replace('/', '_')\n",
    "    \n",
    "    # plt.savefig(f'p_autocorrelation_{variable_}.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in target_variables:\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    plot_pacf(\n",
    "        second_part_df[variable],\n",
    "        title=variable,\n",
    "        use_vlines=True,\n",
    "        ax=ax\n",
    "    )\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Orders Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fare anche la partial acf, che serve per valutare la partial autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_d_results = pd.DataFrame(\n",
    "    index=input_variables + ['ICC [1/mL]', 'HNAC [1/mL]'],\n",
    "    columns=['AR_order', 'I_order (fixed)', 'MA_order', 'AIC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_d_ma_results = pd.DataFrame(\n",
    "    index=input_variables + ['ICC [1/mL]', 'HNAC [1/mL]'],\n",
    "    columns=['AR_order', 'I_order (fixed)', 'MA_order (fixed)', 'AIC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_fixed_results = pd.DataFrame(\n",
    "    index=input_variables + ['ICC [1/mL]', 'HNAC [1/mL]'],\n",
    "    columns=['AR_order', 'I_order', 'MA_order', 'AIC']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in input_variables + ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "    model = pm.auto_arima(\n",
    "        second_part_df[variable],\n",
    "        seasonal=False,\n",
    "        trace=False,\n",
    "        error_action='ignore',\n",
    "        suppress_warnings=True,\n",
    "        stepwise=True,\n",
    "        d=0,\n",
    "        D=0,\n",
    "        max_d=0,\n",
    "        max_D=0,\n",
    "    )\n",
    "    \n",
    "    results = model.get_params()\n",
    "    fixed_d_results.loc[variable, 'AR_order'] = results['order'][0]\n",
    "    fixed_d_results.loc[variable, 'I_order (fixed)'] = results['order'][1]\n",
    "    fixed_d_results.loc[variable, 'MA_order'] = results['order'][2]\n",
    "    fixed_d_results.loc[variable, 'AIC'] = model.aic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in input_variables + ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "    model = pm.auto_arima(\n",
    "        second_part_df[variable],\n",
    "        seasonal=False,\n",
    "        trace=False,\n",
    "        error_action='ignore',\n",
    "        suppress_warnings=True,\n",
    "        stepwise=True,\n",
    "        d=0,\n",
    "        D=0,\n",
    "        max_d=0,\n",
    "        max_D=0,\n",
    "        start_q=0,\n",
    "        start_Q=0,\n",
    "        max_q=0,\n",
    "        max_Q=0\n",
    "    )\n",
    "    \n",
    "    results = model.get_params()\n",
    "    fixed_d_ma_results.loc[variable, 'AR_order'] = results['order'][0]\n",
    "    fixed_d_ma_results.loc[variable, 'I_order (fixed)'] = results['order'][1]\n",
    "    fixed_d_ma_results.loc[variable, 'MA_order (fixed)'] = results['order'][2]\n",
    "    fixed_d_ma_results.loc[variable, 'AIC'] = model.aic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in input_variables + ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "    model = pm.auto_arima(\n",
    "        second_part_df[variable],\n",
    "        seasonal=False,\n",
    "        trace=False,\n",
    "        error_action='ignore',\n",
    "        suppress_warnings=True,\n",
    "        stepwise=True,\n",
    "    )\n",
    "    \n",
    "    results = model.get_params()\n",
    "    no_fixed_results.loc[variable, 'AR_order'] = results['order'][0]\n",
    "    no_fixed_results.loc[variable, 'I_order'] = results['order'][1]\n",
    "    no_fixed_results.loc[variable, 'MA_order'] = results['order'][2]\n",
    "    no_fixed_results.loc[variable, 'AIC'] = model.aic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_d_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_d_ma_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_fixed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results_df = pd.DataFrame(\n",
    "    index=input_variables + ['ICC [1/mL]', 'HNAC [1/mL]'],\n",
    "    columns=['AR_order', 'I_order', 'MA_order', 'AIC']\n",
    ")\n",
    "\n",
    "for variable in input_variables + ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "        best_result = min([no_fixed_results.loc[variable], fixed_d_results.loc[variable], fixed_d_ma_results.loc[variable]], key=lambda x: x['AIC'])\n",
    "        best_results_df.loc[variable, 'AR_order'] = best_result.iloc[0]\n",
    "        best_results_df.loc[variable, 'I_order'] = best_result.iloc[1]\n",
    "        best_results_df.loc[variable, 'MA_order'] = best_result.iloc[2]\n",
    "        best_results_df.loc[variable, 'AIC'] = best_result.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_features(df: pd.DataFrame, feature_name: str,  lags: int, rolling_window: int):\n",
    "    \n",
    "    if feature_name in df.columns:\n",
    "        # add lagged, rolling and expanding features for each variable in df    \n",
    "        if lags > 0:\n",
    "        \n",
    "            for lag in range(1, lags + 1):\n",
    "                df[f\"{feature_name}_lag{lag}\"] = df[feature_name].shift(lag)\n",
    "        \n",
    "        if rolling_window > 0:        \n",
    "            df[f\"{feature_name}_rolling{rolling_window}\"] = df[feature_name].rolling(rolling_window).mean()\n",
    "        \n",
    "    # fill NaN values with bfill\n",
    "    df.bfill(inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler all the variables\n",
    "scaler = MinMaxScaler()\n",
    "second_part_df[input_variables] = scaler.fit_transform(second_part_df[input_variables])\n",
    "second_part_df['ICC [1/mL]'] = scaler.fit_transform(second_part_df[['ICC [1/mL]']])\n",
    "second_part_df['HNAC [1/mL]'] = scaler.fit_transform(second_part_df[['HNAC [1/mL]']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lag = p_i + q_i for covariates\n",
    "copy_df = second_part_df.copy()\n",
    "\n",
    "for variable in input_variables:\n",
    "    n_lags = fixed_d_results.loc[variable, 'AR_order'] + fixed_d_results.loc[variable, 'MA_order']\n",
    "    copy_df = extend_features(copy_df, variable, n_lags, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just the AR part for the targets\n",
    "for variable in ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "    n_lags = fixed_d_results.loc[variable, 'AR_order']\n",
    "    copy_df = extend_features(copy_df, variable, n_lags, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARX Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.linear_model import OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summaries_df = pd.DataFrame(\n",
    "    index=input_variables,\n",
    "    columns=['ICC [1/mL]', 'HNAC [1/mL]']\n",
    ")\n",
    "\n",
    "for input_variable in input_variables:\n",
    "    for target_variable in ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "        \n",
    "        exog_df = copy_df[[col for col in copy_df.columns if input_variable in col]]\n",
    "        endog_df = copy_df[[col for col in copy_df.columns if target_variable in col]]\n",
    "        \n",
    "        # remove just the column target_variable\n",
    "        endog_df.drop(columns=[target_variable], inplace=True)\n",
    "        \n",
    "        exog_df = pd.concat([exog_df, endog_df], axis=1)\n",
    "        \n",
    "        # add constant\n",
    "        exog_df = sm.add_constant(exog_df)\n",
    "        \n",
    "        model = OLS(endog=copy_df[target_variable], exog=exog_df)\n",
    "        results = model.fit()\n",
    "        \n",
    "        results_summaries_df.loc[input_variable, target_variable] = results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarimax_results_df = pd.DataFrame(\n",
    "    index=input_variables,\n",
    "    columns=['ICC [1/mL]', 'HNAC [1/mL]']\n",
    ")\n",
    "\n",
    "for input_variable in input_variables:\n",
    "    \n",
    "    exog_df = copy_df[[col for col in copy_df.columns if input_variable in col]]\n",
    "    \n",
    "    for target_variable in ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "        \n",
    "        model = SARIMAX(\n",
    "            copy_df[target_variable],\n",
    "            exog=exog_df,\n",
    "            order=(2, 0 , 0),\n",
    "        )\n",
    "        \n",
    "        results = model.fit()\n",
    "        sarimax_results_df.loc[input_variable, target_variable] = results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results and compare with the OLS results\n",
    "for input_variable in input_variables:\n",
    "    for target_variable in ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "        print(\"=\"*100)\n",
    "        print(f\"Results for {input_variable} and {target_variable}:\")\n",
    "        print(\"=\"*100)\n",
    "        print(\"===SARIMAX===\")\n",
    "        print(sarimax_results_df.loc[input_variable, target_variable])\n",
    "        print(\"===OLS===\")\n",
    "        print(results_summaries_df.loc[input_variable, target_variable])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Granger Causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform granger causality test for each input variable and target variable\n",
    "\n",
    "granger_results_df = pd.DataFrame(\n",
    "    index=input_variables,\n",
    "    columns=['ICC [1/mL]', 'HNAC [1/mL]']\n",
    ")\n",
    "\n",
    "for input_variable in input_variables:\n",
    "    \n",
    "    maxlag = fixed_d_results.loc[input_variable, 'AR_order'] + fixed_d_results.loc[input_variable, 'MA_order']\n",
    "    \n",
    "    for target_variable in ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "        test_results = grangercausalitytests(x=copy_df[[target_variable, input_variable]], maxlag=maxlag)\n",
    "        \n",
    "        granger_results_df.loc[input_variable, target_variable] = [key for key in test_results.keys() if test_results[key][0]['ssr_ftest'][1] < 0.05] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "granger_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just the conductivity has no granger causality with the targets\n",
    "# so we can remove it from the input variables\n",
    "input_variables = [var for var in input_variables if var != 'Conductivity [mS/cm]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariates Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Feature Selection with AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_feature_selection_aic(df, target_variable, input_variables_list, ar_order=2):\n",
    "    \"\"\"\n",
    "    Perform backward feature selection based on AIC for a given target variable.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing all features\n",
    "    - target_variable: String, name of the target variable\n",
    "    - input_variables_list: List of input variable names (without lags)\n",
    "    - ar_order: Integer, AR order for the target variable\n",
    "    \n",
    "    Returns:\n",
    "    - selected_features: List of selected feature names\n",
    "    - aic_scores: Dictionary with AIC scores at each step\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all lagged features for input variables\n",
    "    all_input_features = []\n",
    "    for var in input_variables_list:\n",
    "        all_input_features.extend([col for col in df.columns if var in col and col != var])\n",
    "        all_input_features.append(var)  # Include the original variable too\n",
    "    \n",
    "    # Get lagged features for target variable (autoregressive terms)\n",
    "    target_features = [col for col in df.columns if target_variable in col and col != target_variable]\n",
    "    \n",
    "    # All features to consider\n",
    "    current_features = all_input_features + target_features\n",
    "    current_features = list(set(current_features))  # Remove duplicates\n",
    "    \n",
    "    # Initialize results\n",
    "    aic_scores = {}\n",
    "    iteration = 0\n",
    "    \n",
    "    print(f\"\\n=== Backward Feature Selection for {target_variable} ===\")\n",
    "    print(f\"Starting with {len(current_features)} features\")\n",
    "    \n",
    "    while len(current_features) > 1:\n",
    "        # Fit model with current features\n",
    "        exog_df = df[current_features].copy()\n",
    "        exog_df = sm.add_constant(exog_df)\n",
    "        \n",
    "        try:\n",
    "            model = OLS(endog=df[target_variable], exog=exog_df)\n",
    "            results = model.fit()\n",
    "            current_aic = results.aic\n",
    "            \n",
    "            print(f\"\\nIteration {iteration}: AIC = {current_aic:.4f} with {len(current_features)} features\")\n",
    "            aic_scores[f\"iteration_{iteration}\"] = {\n",
    "                'features': current_features.copy(),\n",
    "                'aic': current_aic,\n",
    "                'n_features': len(current_features)\n",
    "            }\n",
    "            \n",
    "            # Try removing each feature and calculate AIC\n",
    "            best_aic = current_aic\n",
    "            feature_to_remove = None\n",
    "            \n",
    "            # remove one feature at a time and check if the AIC decreases\n",
    "            # NOTE: it removes the feature that decreases the AIC the most\n",
    "            for feature in current_features:\n",
    "                temp_features = [f for f in current_features if f != feature]\n",
    "                \n",
    "                if len(temp_features) > 0:\n",
    "                    temp_exog = df[temp_features].copy()\n",
    "                    temp_exog = sm.add_constant(temp_exog)\n",
    "                    \n",
    "                    try:\n",
    "                        temp_model = OLS(endog=df[target_variable], exog=temp_exog)\n",
    "                        temp_results = temp_model.fit()\n",
    "                        temp_aic = temp_results.aic\n",
    "                        \n",
    "                        # If removing this feature improves (decreases) AIC, mark it for removal\n",
    "                        if temp_aic < best_aic:\n",
    "                            best_aic = temp_aic\n",
    "                            feature_to_remove = feature\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"Warning: Could not fit model without {feature}: {e}\")\n",
    "                        continue\n",
    "            \n",
    "            # If we found a feature to remove that improves AIC, remove it\n",
    "            if feature_to_remove is not None:\n",
    "                current_features.remove(feature_to_remove)\n",
    "                print(f\"Removed {feature_to_remove}, new AIC: {best_aic:.4f}\")\n",
    "            else:\n",
    "                print(\"No feature removal improves AIC. Stopping.\")\n",
    "                break\n",
    "                \n",
    "            iteration += 1\n",
    "            \n",
    "            # Safety check to avoid infinite loops\n",
    "            if iteration > 50:\n",
    "                print(\"Reached maximum iterations (50). Stopping.\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in iteration {iteration}: {e}\")\n",
    "            break\n",
    "    \n",
    "    # Final model\n",
    "    if len(current_features) > 0:\n",
    "        final_exog = df[current_features].copy()\n",
    "        final_exog = sm.add_constant(final_exog)\n",
    "        \n",
    "        try:\n",
    "            final_model = OLS(endog=df[target_variable], exog=final_exog)\n",
    "            final_results = final_model.fit()\n",
    "            final_aic = final_results.aic\n",
    "            \n",
    "            aic_scores[f\"final\"] = {\n",
    "                'features': current_features.copy(),\n",
    "                'aic': final_aic,\n",
    "                'n_features': len(current_features),\n",
    "                'model_summary': final_results.summary()\n",
    "            }\n",
    "            \n",
    "            print(f\"\\nFinal model: AIC = {final_aic:.4f} with {len(current_features)} features\")\n",
    "            print(f\"Selected features: {current_features}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fitting final model: {e}\")\n",
    "    \n",
    "    return current_features, aic_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply backward feature selection for both target variables\n",
    "bfs_results = {}\n",
    "\n",
    "# For ICC [1/mL]\n",
    "print(\"Starting backward feature selection for ICC [1/mL]...\")\n",
    "icc_ar_order = 2  # Use default value or extract properly\n",
    "selected_features_icc, aic_scores_icc = backward_feature_selection_aic(\n",
    "    df=copy_df, \n",
    "    target_variable='ICC [1/mL]', \n",
    "    input_variables_list=input_variables,\n",
    "    ar_order=icc_ar_order\n",
    ")\n",
    "\n",
    "bfs_results['ICC [1/mL]'] = {\n",
    "    'selected_features': selected_features_icc,\n",
    "    'aic_scores': aic_scores_icc\n",
    "}\n",
    "\n",
    "# For HNAC [1/mL]\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Starting backward feature selection for HNAC [1/mL]...\")\n",
    "hnac_ar_order = 2  # Use default value or extract properly\n",
    "selected_features_hnac, aic_scores_hnac = backward_feature_selection_aic(\n",
    "    df=copy_df, \n",
    "    target_variable='HNAC [1/mL]', \n",
    "    input_variables_list=input_variables,\n",
    "    ar_order=hnac_ar_order\n",
    ")\n",
    "\n",
    "bfs_results['HNAC [1/mL]'] = {\n",
    "    'selected_features': selected_features_hnac,\n",
    "    'aic_scores': aic_scores_hnac\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results summary\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"BACKWARD FEATURE SELECTION RESULTS SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for target in ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    selected_features = bfs_results[target]['selected_features']\n",
    "    aic_scores = bfs_results[target]['aic_scores']\n",
    "    \n",
    "    print(f\"Number of selected features: {len(selected_features)}\")\n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "    \n",
    "    if 'final' in aic_scores:\n",
    "        final_aic = aic_scores['final']['aic']\n",
    "        print(f\"Final AIC: {final_aic:.4f}\")\n",
    "        \n",
    "        # Display the final model summary\n",
    "        print(f\"\\nFinal Model Summary for {target}:\")\n",
    "        print(aic_scores['final']['model_summary'])\n",
    "    \n",
    "    print(f\"\\nAIC progression:\")\n",
    "    for step_key in aic_scores.keys():\n",
    "        if step_key != 'final':\n",
    "            step_data = aic_scores[step_key]\n",
    "            print(f\"  {step_key}: AIC = {step_data['aic']:.4f}, Features = {step_data['n_features']}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary DataFrame of selected features\n",
    "bfs_summary = pd.DataFrame({\n",
    "    'Target_Variable': ['ICC [1/mL]', 'HNAC [1/mL]'],\n",
    "    'Selected_Features_Count': [\n",
    "        len(bfs_results['ICC [1/mL]']['selected_features']),\n",
    "        len(bfs_results['HNAC [1/mL]']['selected_features'])\n",
    "    ],\n",
    "    'Final_AIC': [\n",
    "        bfs_results['ICC [1/mL]']['aic_scores']['final']['aic'] if 'final' in bfs_results['ICC [1/mL]']['aic_scores'] else None,\n",
    "        bfs_results['HNAC [1/mL]']['aic_scores']['final']['aic'] if 'final' in bfs_results['HNAC [1/mL]']['aic_scores'] else None\n",
    "    ],\n",
    "    'Selected_Features': [\n",
    "        ', '.join(bfs_results['ICC [1/mL]']['selected_features']),\n",
    "        ', '.join(bfs_results['HNAC [1/mL]']['selected_features'])\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nBackward Feature Selection Summary:\")\n",
    "print(bfs_summary.to_string(index=False, max_colwidth=80))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_feature_selection(df, target_variable, input_variables_list, alpha_values=None, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Perform Lasso feature selection for a given target variable.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing all features\n",
    "    - target_variable: String, name of the target variable\n",
    "    - input_variables_list: List of input variable names (without lags)\n",
    "    - alpha_values: List of alpha values for cross-validation. If None, uses default range\n",
    "    - cv_folds: Number of cross-validation folds\n",
    "    \n",
    "    Returns:\n",
    "    - selected_features: List of selected feature names\n",
    "    - lasso_results: Dictionary with Lasso results and performance metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all lagged features for input variables\n",
    "    all_input_features = []\n",
    "    for var in input_variables_list:\n",
    "        all_input_features.extend([col for col in df.columns if var in col and col != var])\n",
    "        all_input_features.append(var)  # Include the original variable too\n",
    "    \n",
    "    # Get lagged features for target variable (autoregressive terms)\n",
    "    target_features = [col for col in df.columns if target_variable in col and col != target_variable]\n",
    "    \n",
    "    # All features to consider\n",
    "    all_features = all_input_features + target_features\n",
    "    all_features = list(set(all_features))  # Remove duplicates\n",
    "    \n",
    "    # Prepare data\n",
    "    X = df[all_features].copy()\n",
    "    y = df[target_variable].copy()\n",
    "    \n",
    "    # Remove any rows with NaN values\n",
    "    mask = ~(X.isnull().any(axis=1) | y.isnull())\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    \n",
    "    print(f\"\\n=== Lasso Feature Selection for {target_variable} ===\")\n",
    "    print(f\"Dataset shape: {X.shape}\")\n",
    "    print(f\"Starting with {X.shape[1]} features\")\n",
    "    \n",
    "    # Standardize features\n",
    "    \n",
    "    # Set alpha values for cross-validation if not provided\n",
    "    if alpha_values is None:\n",
    "        alpha_values = np.logspace(-4, 2, 50)\n",
    "    \n",
    "    # Perform cross-validation to find optimal alpha\n",
    "    print(\"Performing cross-validation to find optimal alpha...\")\n",
    "    lasso_cv = LassoCV(alphas=alpha_values, cv=cv_folds, random_state=42, max_iter=10000)\n",
    "    lasso_cv.fit(X, y)\n",
    "    \n",
    "    optimal_alpha = lasso_cv.alpha_\n",
    "    print(f\"Optimal alpha: {optimal_alpha:.6f}\")\n",
    "    \n",
    "    # Fit Lasso with optimal alpha\n",
    "    lasso = Lasso(alpha=optimal_alpha, random_state=42, max_iter=10000)\n",
    "    lasso.fit(X, y)\n",
    "    \n",
    "    # Get selected features (non-zero coefficients)\n",
    "    selected_mask = lasso.coef_ != 0\n",
    "    selected_features = [all_features[i] for i in range(len(all_features)) if selected_mask[i]]\n",
    "    selected_coefficients = lasso.coef_[selected_mask]\n",
    "    \n",
    "    print(f\"Number of selected features: {len(selected_features)}\")\n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    y_pred = lasso.predict(X)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    \n",
    "    print(f\"\\nModel Performance:\")\n",
    "    print(f\"R² Score: {r2:.6f}\")\n",
    "    print(f\"MSE: {mse:.6f}\")\n",
    "    print(f\"RMSE: {np.sqrt(mse):.6f}\")\n",
    "    \n",
    "    # Create results dictionary\n",
    "    lasso_results = {\n",
    "        'optimal_alpha': optimal_alpha,\n",
    "        'selected_features': selected_features,\n",
    "        'selected_coefficients': selected_coefficients,\n",
    "        'feature_names': all_features,\n",
    "        'all_coefficients': lasso.coef_,\n",
    "        'r2_score': r2,\n",
    "        'mse': mse,\n",
    "        'rmse': np.sqrt(mse),\n",
    "        'cv_scores': lasso_cv.mse_path_.mean(axis=1),\n",
    "        'alpha_values': alpha_values,\n",
    "        'scaler': scaler,\n",
    "        'model': lasso\n",
    "    }\n",
    "    \n",
    "    return selected_features, lasso_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Lasso feature selection for both target variables\n",
    "lasso_results = {}\n",
    "\n",
    "# For ICC [1/mL]\n",
    "print(\"Starting Lasso feature selection for ICC [1/mL]...\")\n",
    "selected_features_icc_lasso, lasso_scores_icc = lasso_feature_selection(\n",
    "    df=copy_df, \n",
    "    target_variable='ICC [1/mL]', \n",
    "    input_variables_list=input_variables,\n",
    "    cv_folds=5\n",
    ")\n",
    "\n",
    "lasso_results['ICC [1/mL]'] = {\n",
    "    'selected_features': selected_features_icc_lasso,\n",
    "    'lasso_scores': lasso_scores_icc\n",
    "}\n",
    "\n",
    "# For HNAC [1/mL]\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Starting Lasso feature selection for HNAC [1/mL]...\")\n",
    "selected_features_hnac_lasso, lasso_scores_hnac = lasso_feature_selection(\n",
    "    df=copy_df, \n",
    "    target_variable='HNAC [1/mL]', \n",
    "    input_variables_list=input_variables,\n",
    "    cv_folds=5\n",
    ")\n",
    "\n",
    "lasso_results['HNAC [1/mL]'] = {\n",
    "    'selected_features': selected_features_hnac_lasso,\n",
    "    'lasso_scores': lasso_scores_hnac\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Lasso results summary\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"LASSO FEATURE SELECTION RESULTS SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for target in ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    selected_features = lasso_results[target]['selected_features']\n",
    "    lasso_scores = lasso_results[target]['lasso_scores']\n",
    "    \n",
    "    print(f\"Number of selected features: {len(selected_features)}\")\n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "    print(f\"Optimal alpha: {lasso_scores['optimal_alpha']:.6f}\")\n",
    "    print(f\"R² Score: {lasso_scores['r2_score']:.6f}\")\n",
    "    print(f\"MSE: {lasso_scores['mse']:.6f}\")\n",
    "    print(f\"RMSE: {lasso_scores['rmse']:.6f}\")\n",
    "    \n",
    "    # Display selected features with their coefficients\n",
    "    print(f\"\\nSelected Features and Coefficients:\")\n",
    "    for i, (feature, coef) in enumerate(zip(selected_features, lasso_scores['selected_coefficients'])):\n",
    "        print(f\"  {i+1:2d}. {feature:30s} = {coef:10.6f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cross-validation results for alpha selection\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "for i, target in enumerate(['ICC [1/mL]', 'HNAC [1/mL]']):\n",
    "    lasso_scores = lasso_results[target]['lasso_scores']\n",
    "    \n",
    "    # Plot CV scores vs alpha\n",
    "    axes[i].semilogx(lasso_scores['alpha_values'], lasso_scores['cv_scores'])\n",
    "    axes[i].axvline(x=lasso_scores['optimal_alpha'], color='red', linestyle='--', \n",
    "                   label=f'Optimal α = {lasso_scores[\"optimal_alpha\"]:.6f}')\n",
    "    axes[i].set_xlabel('Alpha (Regularization Parameter)')\n",
    "    axes[i].set_ylabel('Cross-Validation MSE')\n",
    "    axes[i].set_title(f'Lasso CV Results - {target}')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "print(\"The Lasso feature selection automatically determines the optimal regularization\")\n",
    "print(\"parameter (alpha) through cross-validation and selects features by driving\")\n",
    "print(\"less important coefficients to zero.\")\n",
    "print(\"\\nKey advantages of Lasso vs Backward Feature Selection:\")\n",
    "print(\"- Automatic regularization parameter tuning\")\n",
    "print(\"- Handles multicollinearity better\")\n",
    "print(\"- Computationally more efficient for large feature sets\")\n",
    "print(\"- Provides coefficient magnitudes for feature importance ranking\")\n",
    "print(\"\\nBoth methods can be used complementary to validate feature importance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame between BFS and Lasso results\n",
    "comparison_results = pd.DataFrame({\n",
    "    'Target_Variable': ['ICC [1/mL]', 'HNAC [1/mL]'],\n",
    "    'BFS_Features_Count': [\n",
    "        len(bfs_results['ICC [1/mL]']['selected_features']),\n",
    "        len(bfs_results['HNAC [1/mL]']['selected_features'])\n",
    "    ],\n",
    "    'BFS_Final_AIC': [\n",
    "        bfs_results['ICC [1/mL]']['aic_scores']['final']['aic'],\n",
    "        bfs_results['HNAC [1/mL]']['aic_scores']['final']['aic']\n",
    "    ],\n",
    "    'Lasso_Features_Count': [\n",
    "        len(lasso_results['ICC [1/mL]']['selected_features']),\n",
    "        len(lasso_results['HNAC [1/mL]']['selected_features'])\n",
    "    ],\n",
    "    'Lasso_R2_Score': [\n",
    "        lasso_results['ICC [1/mL]']['lasso_scores']['r2_score'],\n",
    "        lasso_results['HNAC [1/mL]']['lasso_scores']['r2_score']\n",
    "    ],\n",
    "    'Lasso_RMSE': [\n",
    "        lasso_results['ICC [1/mL]']['lasso_scores']['rmse'],\n",
    "        lasso_results['HNAC [1/mL]']['lasso_scores']['rmse']\n",
    "    ],\n",
    "    'Lasso_Alpha': [\n",
    "        lasso_results['ICC [1/mL]']['lasso_scores']['optimal_alpha'],\n",
    "        lasso_results['HNAC [1/mL]']['lasso_scores']['optimal_alpha']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"COMPARISON: BACKWARD FEATURE SELECTION vs LASSO\")\n",
    "print(\"=\"*100)\n",
    "print(comparison_results.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature overlap between BFS and Lasso methods\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FEATURE OVERLAP ANALYSIS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for target in ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    bfs_features = set(bfs_results[target]['selected_features'])\n",
    "    lasso_features = set(lasso_results[target]['selected_features'])\n",
    "    \n",
    "    overlap = bfs_features.intersection(lasso_features)\n",
    "    bfs_only = bfs_features - lasso_features\n",
    "    lasso_only = lasso_features - bfs_features\n",
    "    \n",
    "    print(f\"BFS selected features ({len(bfs_features)}): {sorted(list(bfs_features))}\")\n",
    "    print(f\"Lasso selected features ({len(lasso_features)}): {sorted(list(lasso_features))}\")\n",
    "    print(f\"\\nOverlapping features ({len(overlap)}): {sorted(list(overlap))}\")\n",
    "    print(f\"BFS only ({len(bfs_only)}): {sorted(list(bfs_only))}\")\n",
    "    print(f\"Lasso only ({len(lasso_only)}): {sorted(list(lasso_only))}\")\n",
    "    \n",
    "    # Calculate overlap percentage\n",
    "    if len(bfs_features) > 0 and len(lasso_features) > 0:\n",
    "        overlap_pct_bfs = len(overlap) / len(bfs_features) * 100\n",
    "        overlap_pct_lasso = len(overlap) / len(lasso_features) * 100\n",
    "        print(f\"\\nOverlap percentage (relative to BFS): {overlap_pct_bfs:.1f}%\")\n",
    "        print(f\"Overlap percentage (relative to Lasso): {overlap_pct_lasso:.1f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary DataFrame with all information\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"CREATING COMPREHENSIVE SUMMARY DATAFRAME\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Initialize summary data\n",
    "summary_data = []\n",
    "\n",
    "for target in ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "    # Get BFS results\n",
    "    bfs_features = bfs_results[target]['selected_features']\n",
    "    bfs_aic = bfs_results[target]['aic_scores']['final']['aic']\n",
    "    bfs_n_features = len(bfs_features)\n",
    "    \n",
    "    # Get Lasso results\n",
    "    lasso_features = lasso_results[target]['selected_features']\n",
    "    lasso_scores = lasso_results[target]['lasso_scores']\n",
    "    lasso_n_features = len(lasso_features)\n",
    "    \n",
    "    # Calculate overlap\n",
    "    bfs_set = set(bfs_features)\n",
    "    lasso_set = set(lasso_features)\n",
    "    overlap = bfs_set.intersection(lasso_set)\n",
    "    overlap_count = len(overlap)\n",
    "    overlap_pct_bfs = (overlap_count / bfs_n_features * 100) if bfs_n_features > 0 else 0\n",
    "    overlap_pct_lasso = (overlap_count / lasso_n_features * 100) if lasso_n_features > 0 else 0\n",
    "    \n",
    "    # Feature categories\n",
    "    bfs_only = bfs_set - lasso_set\n",
    "    lasso_only = lasso_set - bfs_set\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Target_Variable': target,\n",
    "        'BFS_Features_Count': bfs_n_features,\n",
    "        'BFS_Final_AIC': round(bfs_aic, 4),\n",
    "        'BFS_Selected_Features': '; '.join(sorted(bfs_features)),\n",
    "        'Lasso_Features_Count': lasso_n_features,\n",
    "        'Lasso_Optimal_Alpha': round(lasso_scores['optimal_alpha'], 6),\n",
    "        'Lasso_R2_Score': round(lasso_scores['r2_score'], 6),\n",
    "        'Lasso_RMSE': round(lasso_scores['rmse'], 4),\n",
    "        'Lasso_Selected_Features': '; '.join(sorted(lasso_features)),\n",
    "        'Overlap_Count': overlap_count,\n",
    "        'Overlap_Pct_vs_BFS': round(overlap_pct_bfs, 1),\n",
    "        'Overlap_Pct_vs_Lasso': round(overlap_pct_lasso, 1),\n",
    "        'Common_Features': '; '.join(sorted(overlap)) if overlap else 'None',\n",
    "        \n",
    "        'BFS_Only_Features': '; '.join(sorted(bfs_only)) if bfs_only else 'None',\n",
    "        'Lasso_Only_Features': '; '.join(sorted(lasso_only)) if lasso_only else 'None'\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "comprehensive_summary = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"Comprehensive summary DataFrame created successfully!\")\n",
    "print(f\"Shape: {comprehensive_summary.shape}\")\n",
    "print(\"\\nColumns included:\")\n",
    "for i, col in enumerate(comprehensive_summary.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "comprehensive_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed feature-level analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING DETAILED FEATURE-LEVEL ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get all unique features from both methods\n",
    "all_features_set = set()\n",
    "for target in ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "    all_features_set.update(bfs_results[target]['selected_features'])\n",
    "    all_features_set.update(lasso_results[target]['selected_features'])\n",
    "\n",
    "all_features_list = sorted(list(all_features_set))\n",
    "\n",
    "# Create feature-level summary\n",
    "feature_summary_data = []\n",
    "\n",
    "for feature in all_features_list:\n",
    "    feature_info = {'Feature_Name': feature}\n",
    "    \n",
    "    # Determine feature type and base variable\n",
    "    if '_lag' in feature:\n",
    "        base_var = feature.split('_lag')[0]\n",
    "        lag_num = feature.split('_lag')[1]\n",
    "        feature_type = f\"Lagged ({lag_num})\"\n",
    "    else:\n",
    "        base_var = feature\n",
    "        feature_type = \"Original\"\n",
    "    \n",
    "    feature_info['Base_Variable'] = base_var\n",
    "    feature_info['Feature_Type'] = feature_type\n",
    "    \n",
    "    # Check selection by each method for each target\n",
    "    for target in ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "        target_short = target.replace(' [1/mL]', '').replace(' ', '_')\n",
    "        \n",
    "        # BFS selection\n",
    "        bfs_selected = feature in bfs_results[target]['selected_features']\n",
    "        feature_info[f'{target_short}_BFS_Selected'] = 'Yes' if bfs_selected else 'No'\n",
    "        \n",
    "        # Lasso selection and coefficient\n",
    "        lasso_selected = feature in lasso_results[target]['selected_features']\n",
    "        feature_info[f'{target_short}_Lasso_Selected'] = 'Yes' if lasso_selected else 'No'\n",
    "        \n",
    "        if lasso_selected:\n",
    "            # Get coefficient value\n",
    "            lasso_features = lasso_results[target]['lasso_scores']['selected_features']\n",
    "            lasso_coefs = lasso_results[target]['lasso_scores']['selected_coefficients']\n",
    "            if feature in lasso_features:\n",
    "                coef_idx = lasso_features.index(feature)\n",
    "                feature_info[f'{target_short}_Lasso_Coefficient'] = round(lasso_coefs[coef_idx], 6)\n",
    "            else:\n",
    "                feature_info[f'{target_short}_Lasso_Coefficient'] = 0.0\n",
    "        else:\n",
    "            feature_info[f'{target_short}_Lasso_Coefficient'] = 0.0\n",
    "    \n",
    "    # Summary statistics\n",
    "    total_selections = sum([\n",
    "        1 if feature_info[f'{target.replace(\" [1/mL]\", \"\").replace(\" \", \"_\")}_BFS_Selected'] == 'Yes' else 0\n",
    "        for target in ['ICC [1/mL]', 'HNAC [1/mL]']\n",
    "    ]) + sum([\n",
    "        1 if feature_info[f'{target.replace(\" [1/mL]\", \"\").replace(\" \", \"_\")}_Lasso_Selected'] == 'Yes' else 0\n",
    "        for target in ['ICC [1/mL]', 'HNAC [1/mL]']\n",
    "    ])\n",
    "    \n",
    "    feature_info['Total_Selections'] = total_selections\n",
    "    feature_info['Selection_Consistency'] = 'High' if total_selections >= 3 else 'Medium' if total_selections == 2 else 'Low'\n",
    "    \n",
    "    feature_summary_data.append(feature_info)\n",
    "\n",
    "# Create detailed feature DataFrame\n",
    "detailed_feature_summary = pd.DataFrame(feature_summary_data)\n",
    "\n",
    "print(f\"Detailed feature summary created with {len(detailed_feature_summary)} features\")\n",
    "print(\"\\nFeature selection consistency summary:\")\n",
    "consistency_counts = detailed_feature_summary['Selection_Consistency'].value_counts()\n",
    "for consistency, count in consistency_counts.items():\n",
    "    print(f\"  {consistency} consistency: {count} features\")\n",
    "\n",
    "detailed_feature_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Save all summary data to Excel files\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS TO EXCEL FILES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create output filename with timestamp\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_filename = f\"feature_selection_results_{timestamp}.xlsx\"\n",
    "\n",
    "try:\n",
    "    with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
    "        # Save comprehensive summary\n",
    "        comprehensive_summary.to_excel(writer, sheet_name='Summary_by_Target', index=False)\n",
    "        \n",
    "        # Save detailed feature analysis\n",
    "        detailed_feature_summary.to_excel(writer, sheet_name='Detailed_Feature_Analysis', index=False)\n",
    "        \n",
    "        # Save BFS specific results\n",
    "        bfs_only_summary = pd.DataFrame([\n",
    "            {\n",
    "                'Target': target,\n",
    "                'Selected_Features': '; '.join(bfs_results[target]['selected_features']),\n",
    "                'Feature_Count': len(bfs_results[target]['selected_features']),\n",
    "                'Final_AIC': bfs_results[target]['aic_scores']['final']['aic'],\n",
    "                'Iterations': len([k for k in bfs_results[target]['aic_scores'].keys() if k.startswith('iteration')])\n",
    "            }\n",
    "            for target in ['ICC [1/mL]', 'HNAC [1/mL]']\n",
    "        ])\n",
    "        bfs_only_summary.to_excel(writer, sheet_name='BFS_Results', index=False)\n",
    "        \n",
    "        # Save Lasso specific results\n",
    "        lasso_only_summary = pd.DataFrame([\n",
    "            {\n",
    "                'Target': target,\n",
    "                'Selected_Features': '; '.join(lasso_results[target]['selected_features']),\n",
    "                'Feature_Count': len(lasso_results[target]['selected_features']),\n",
    "                'Optimal_Alpha': lasso_results[target]['lasso_scores']['optimal_alpha'],\n",
    "                'R2_Score': lasso_results[target]['lasso_scores']['r2_score'],\n",
    "                'RMSE': lasso_results[target]['lasso_scores']['rmse']\n",
    "            }\n",
    "            for target in ['ICC [1/mL]', 'HNAC [1/mL]']\n",
    "        ])\n",
    "        lasso_only_summary.to_excel(writer, sheet_name='Lasso_Results', index=False)\n",
    "        \n",
    "    print(f\"✓ Results saved to: {output_filename}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error saving to Excel: {e}\")\n",
    "    print(\"Continuing with in-memory analysis...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split Analysis\n",
    "\n",
    "Now we perform the same feature selection analysis with a proper train-test split (60-40) to evaluate model generalization performance. The process follows these steps:\n",
    "\n",
    "1. **Data Splitting**: 60% training, 40% testing\n",
    "2. **Scaling**: Fit on training set, apply to test set\n",
    "3. **Granger Causality**: Performed on training set only\n",
    "4. **Backward Feature Selection**: Uses both train and test sets for model fitting\n",
    "5. **Lasso**: Cross-validation on training set, evaluation on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Data Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets (60-40)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate split index for time series (chronological split)\n",
    "n_samples = len(copy_df)\n",
    "train_size = int(0.6 * n_samples)\n",
    "\n",
    "# Chronological split (important for time series data)\n",
    "train_df = copy_df.iloc[:train_size].copy()\n",
    "test_df = copy_df.iloc[train_size:].copy()\n",
    "\n",
    "print(f\"Original dataset size: {n_samples}\")\n",
    "print(f\"Training set size: {len(train_df)} ({len(train_df)/n_samples*100:.1f}%)\")\n",
    "print(f\"Test set size: {len(test_df)} ({len(test_df)/n_samples*100:.1f}%)\")\n",
    "\n",
    "# Display date ranges if available\n",
    "if 'date' in copy_df.columns or any('date' in col.lower() for col in copy_df.columns):\n",
    "    print(f\"Training period: {train_df.index[0]} to {train_df.index[-1]}\")\n",
    "    print(f\"Test period: {test_df.index[0]} to {test_df.index[-1]}\")\n",
    "else:\n",
    "    print(f\"Training indices: {train_df.index[0]} to {train_df.index[-1]}\")\n",
    "    print(f\"Test indices: {test_df.index[0]} to {test_df.index[-1]}\")\n",
    "\n",
    "print(f\"\\nTarget variables statistics:\")\n",
    "for target in target_variables:\n",
    "    train_mean = train_df[target].mean()\n",
    "    test_mean = test_df[target].mean()\n",
    "    train_std = train_df[target].std()\n",
    "    test_std = test_df[target].std()\n",
    "    \n",
    "    print(f\"  {target}:\")\n",
    "    print(f\"    Train: μ={train_mean:.4f}, σ={train_std:.4f}\")\n",
    "    print(f\"    Test:  μ={test_mean:.4f}, σ={test_std:.4f}\")\n",
    "    print(f\"    Difference in means: {abs(train_mean - test_mean):.4f}\")\n",
    "\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Granger Causality on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Granger causality test on training set only\n",
    "granger_results_train_df = pd.DataFrame(\n",
    "    index=input_variables,\n",
    "    columns=['ICC [1/mL]', 'HNAC [1/mL]']\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GRANGER CAUSALITY TEST - TRAINING SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for input_variable in input_variables:\n",
    "    \n",
    "    # Use a safe default maxlag value\n",
    "    maxlag = 5  # Default reasonable lag for Granger causality test\n",
    "    \n",
    "    for target_variable in ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "        print(f\"\\nTesting {input_variable} -> {target_variable} (max lag: {maxlag})\")\n",
    "        \n",
    "        try:\n",
    "            test_results = grangercausalitytests(\n",
    "                x=train_df[[target_variable, input_variable]], \n",
    "                maxlag=maxlag,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Get significant lags (p < 0.05)\n",
    "            significant_lags = [key for key in test_results.keys() \n",
    "                              if test_results[key][0]['ssr_ftest'][1] < 0.05]\n",
    "            \n",
    "            granger_results_train_df.loc[input_variable, target_variable] = significant_lags\n",
    "            \n",
    "            if significant_lags:\n",
    "                p_values = [test_results[key][0]['ssr_ftest'][1] for key in significant_lags]\n",
    "                print(f\"  ✓ Significant lags: {significant_lags}\")\n",
    "                print(f\"  ✓ P-values: {[f'{p:.4f}' for p in p_values]}\")\n",
    "            else:\n",
    "                print(f\"  ✗ No significant Granger causality\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠ Error testing {input_variable} -> {target_variable}: {e}\")\n",
    "            granger_results_train_df.loc[input_variable, target_variable] = []\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"GRANGER CAUSALITY RESULTS - TRAINING SET\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Granger causality results for training set\n",
    "print(granger_results_train_df)\n",
    "\n",
    "# Filter input variables based on Granger causality results from training set\n",
    "input_variables_train = []\n",
    "for var in input_variables:\n",
    "    has_causality = False\n",
    "    for target in ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "        if len(granger_results_train_df.loc[var, target]) > 0:\n",
    "            has_causality = True\n",
    "            break\n",
    "    if has_causality:\n",
    "        input_variables_train.append(var)\n",
    "\n",
    "print(f\"\\nVariables with Granger causality (training set): {len(input_variables_train)}\")\n",
    "print(f\"Selected variables: {input_variables_train}\")\n",
    "\n",
    "# Variables removed due to no Granger causality\n",
    "removed_vars = [var for var in input_variables if var not in input_variables_train]\n",
    "if removed_vars:\n",
    "    print(f\"Removed variables (no Granger causality): {removed_vars}\")\n",
    "else:\n",
    "    print(\"All variables show Granger causality relationship\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Backward Feature Selection with Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_feature_selection_train_test(train_df, test_df, target_variable, input_variables_list, ar_order=2):\n",
    "    \"\"\"\n",
    "    Perform backward feature selection using only the training set, then evaluate on test set.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_df: Training DataFrame\n",
    "    - test_df: Test DataFrame  \n",
    "    - target_variable: String, name of the target variable\n",
    "    - input_variables_list: List of input variable names (without lags)\n",
    "    - ar_order: Integer, AR order for the target variable\n",
    "    \n",
    "    Returns:\n",
    "    - selected_features: List of selected feature names\n",
    "    - results: Dictionary with results and performance metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all lagged features for input variables\n",
    "    all_input_features = []\n",
    "    for var in input_variables_list:\n",
    "        all_input_features.extend([col for col in train_df.columns if var in col and col != var])\n",
    "        all_input_features.append(var)  # Include the original variable too\n",
    "    \n",
    "    # Get lagged features for target variable (autoregressive terms)\n",
    "    target_features = [col for col in train_df.columns if target_variable in col and col != target_variable]\n",
    "    \n",
    "    # All features to consider\n",
    "    current_features = all_input_features + target_features\n",
    "    current_features = list(set(current_features))  # Remove duplicates\n",
    "    \n",
    "    # Initialize results\n",
    "    aic_scores = {}\n",
    "    iteration = 0\n",
    "    \n",
    "    print(f\"\\\\n=== Backward Feature Selection for {target_variable} (Train-Only) ===\")\n",
    "    print(f\"Training set: {len(train_df)} samples\")\n",
    "    print(f\"Test set: {len(test_df)} samples\")\n",
    "    print(f\"Starting with {len(current_features)} features\")\n",
    "    print(\"Feature selection performed on training set only\")\n",
    "    \n",
    "    while len(current_features) > 1:\n",
    "        # Fit model with current features on training dataset only\n",
    "        exog_df = train_df[current_features].copy()\n",
    "        exog_df = sm.add_constant(exog_df)\n",
    "        \n",
    "        try:\n",
    "            model = OLS(endog=train_df[target_variable], exog=exog_df)\n",
    "            results = model.fit()\n",
    "            current_aic = results.aic\n",
    "            \n",
    "            print(f\"\\\\nIteration {iteration}: AIC = {current_aic:.4f} with {len(current_features)} features\")\n",
    "            aic_scores[f\"iteration_{iteration}\"] = {\n",
    "                'features': current_features.copy(),\n",
    "                'aic': current_aic,\n",
    "                'n_features': len(current_features)\n",
    "            }\n",
    "            \n",
    "            # Try removing each feature and calculate AIC\n",
    "            best_aic = current_aic\n",
    "            feature_to_remove = None\n",
    "            \n",
    "            for feature in current_features:\n",
    "                temp_features = [f for f in current_features if f != feature]\n",
    "                \n",
    "                if len(temp_features) > 0:\n",
    "                    temp_exog = train_df[temp_features].copy()\n",
    "                    temp_exog = sm.add_constant(temp_exog)\n",
    "                    \n",
    "                    try:\n",
    "                        temp_model = OLS(endog=train_df[target_variable], exog=temp_exog)\n",
    "                        temp_results = temp_model.fit()\n",
    "                        temp_aic = temp_results.aic\n",
    "                        \n",
    "                        # If removing this feature improves (decreases) AIC, mark it for removal\n",
    "                        if temp_aic < best_aic:\n",
    "                            best_aic = temp_aic\n",
    "                            feature_to_remove = feature\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"Warning: Could not fit model without {feature}: {e}\")\n",
    "                        continue\n",
    "            \n",
    "            # If we found a feature to remove that improves AIC, remove it\n",
    "            if feature_to_remove is not None:\n",
    "                current_features.remove(feature_to_remove)\n",
    "                print(f\"Removed {feature_to_remove}, new AIC: {best_aic:.4f}\")\n",
    "            else:\n",
    "                print(\"No feature removal improves AIC. Stopping.\")\n",
    "                break\n",
    "                \n",
    "            iteration += 1\n",
    "            \n",
    "            # Safety check to avoid infinite loops\n",
    "            if iteration > 50:\n",
    "                print(\"Reached maximum iterations (50). Stopping.\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in iteration {iteration}: {e}\")\n",
    "            break\n",
    "    \n",
    "    # Final model evaluation on train and test separately\n",
    "    if len(current_features) > 0:\n",
    "        # Train set evaluation\n",
    "        final_exog_train = train_df[current_features].copy()\n",
    "        final_exog_train = sm.add_constant(final_exog_train)\n",
    "        \n",
    "        # Test set evaluation  \n",
    "        final_exog_test = test_df[current_features].copy()\n",
    "        final_exog_test = sm.add_constant(final_exog_test)\n",
    "        \n",
    "        try:\n",
    "            # Train model\n",
    "            train_model = OLS(endog=train_df[target_variable], exog=final_exog_train)\n",
    "            train_results = train_model.fit()\n",
    "            train_pred = train_results.predict(final_exog_train)\n",
    "            train_aic = train_results.aic\n",
    "            \n",
    "            # Test predictions using train model\n",
    "            test_pred = train_results.predict(final_exog_test)\n",
    "            test_mse = mean_squared_error(test_df[target_variable], test_pred)\n",
    "            test_r2 = r2_score(test_df[target_variable], test_pred)\n",
    "            \n",
    "            results_dict = {\n",
    "                'selected_features': current_features.copy(),\n",
    "                'train_aic': train_aic,\n",
    "                'test_mse': test_mse,\n",
    "                'test_r2': test_r2,\n",
    "                'test_rmse': np.sqrt(test_mse),\n",
    "                'aic_progression': aic_scores,\n",
    "                'train_model': train_results\n",
    "            }\n",
    "            \n",
    "            print(f\"\\\\nFinal model performance:\")\n",
    "            print(f\"  Train AIC: {train_aic:.4f}\")\n",
    "            print(f\"  Test R²: {test_r2:.6f}\")\n",
    "            print(f\"  Test RMSE: {np.sqrt(test_mse):.6f}\")\n",
    "            print(f\"  Selected features ({len(current_features)}): {current_features}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fitting final model: {e}\")\n",
    "            results_dict = {\n",
    "                'selected_features': current_features.copy(),\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    return current_features, results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply backward feature selection with train-test split\n",
    "bfs_train_test_results = {}\n",
    "\n",
    "# Use original input_variables list for consistency\n",
    "input_vars_to_use = input_variables  # Use all original variables for now\n",
    "\n",
    "# For ICC [1/mL]\n",
    "print(\"Starting backward feature selection for ICC [1/mL] (Train-Test)...\")\n",
    "selected_features_icc_tt, bfs_scores_icc_tt = backward_feature_selection_train_test(\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    target_variable='ICC [1/mL]', \n",
    "    input_variables_list=input_vars_to_use,\n",
    "    ar_order=2\n",
    ")\n",
    "\n",
    "bfs_train_test_results['ICC [1/mL]'] = {\n",
    "    'selected_features': selected_features_icc_tt,\n",
    "    'results': bfs_scores_icc_tt\n",
    "}\n",
    "\n",
    "# For HNAC [1/mL]\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Starting backward feature selection for HNAC [1/mL] (Train-Test)...\")\n",
    "selected_features_hnac_tt, bfs_scores_hnac_tt = backward_feature_selection_train_test(\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    target_variable='HNAC [1/mL]', \n",
    "    input_variables_list=input_vars_to_use,\n",
    "    ar_order=2\n",
    ")\n",
    "\n",
    "bfs_train_test_results['HNAC [1/mL]'] = {\n",
    "    'selected_features': selected_features_hnac_tt,\n",
    "    'results': bfs_scores_hnac_tt\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Lasso with Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required for this function\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def lasso_feature_selection_train_test(train_df, test_df, target_variable, input_variables_list, alpha_values=None, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Perform Lasso feature selection with proper train-test split.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_df: Training DataFrame\n",
    "    - test_df: Test DataFrame\n",
    "    - target_variable: String, name of the target variable\n",
    "    - input_variables_list: List of input variable names (without lags)\n",
    "    - alpha_values: List of alpha values for cross-validation. If None, uses default range\n",
    "    - cv_folds: Number of cross-validation folds\n",
    "    \n",
    "    Returns:\n",
    "    - selected_features: List of selected feature names\n",
    "    - lasso_results: Dictionary with Lasso results and performance metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all lagged features for input variables\n",
    "    all_input_features = []\n",
    "    for var in input_variables_list:\n",
    "        all_input_features.extend([col for col in train_df.columns if var in col and col != var])\n",
    "        all_input_features.append(var)  # Include the original variable too\n",
    "    \n",
    "    # Get lagged features for target variable (autoregressive terms)\n",
    "    target_features = [col for col in train_df.columns if target_variable in col and col != target_variable]\n",
    "    \n",
    "    # All features to consider\n",
    "    all_features = all_input_features + target_features\n",
    "    all_features = list(set(all_features))  # Remove duplicates\n",
    "    \n",
    "    # Prepare training data\n",
    "    X_train = train_df[all_features].copy()\n",
    "    y_train = train_df[target_variable].copy()\n",
    "    \n",
    "    # Prepare test data\n",
    "    X_test = test_df[all_features].copy()\n",
    "    y_test = test_df[target_variable].copy()\n",
    "    \n",
    "    # Remove any rows with NaN values\n",
    "    train_mask = ~(X_train.isnull().any(axis=1) | y_train.isnull())\n",
    "    X_train = X_train[train_mask]\n",
    "    y_train = y_train[train_mask]\n",
    "    \n",
    "    test_mask = ~(X_test.isnull().any(axis=1) | y_test.isnull())\n",
    "    X_test = X_test[test_mask]\n",
    "    y_test = y_test[test_mask]\n",
    "    \n",
    "    print(f\"\\\\n=== Lasso Feature Selection for {target_variable} (Train-Test) ===\")\n",
    "    print(f\"Training set shape: {X_train.shape}\")\n",
    "    print(f\"Test set shape: {X_test.shape}\")\n",
    "    print(f\"Starting with {X_train.shape[1]} features\")\n",
    "    \n",
    "    # Fit scaler on training data only\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)  # Apply same scaling to test set\n",
    "    \n",
    "    # Set alpha values for cross-validation if not provided\n",
    "    if alpha_values is None:\n",
    "        alpha_values = np.logspace(-4, 2, 50)\n",
    "    \n",
    "    # Perform cross-validation on training set only\n",
    "    print(\"Performing cross-validation on training set to find optimal alpha...\")\n",
    "    lasso_cv = LassoCV(alphas=alpha_values, cv=cv_folds, random_state=42, max_iter=10000)\n",
    "    lasso_cv.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    optimal_alpha = lasso_cv.alpha_\n",
    "    print(f\"Optimal alpha: {optimal_alpha:.6f}\")\n",
    "    \n",
    "    # Fit Lasso with optimal alpha on training data\n",
    "    lasso = Lasso(alpha=optimal_alpha, random_state=42, max_iter=10000)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Get selected features (non-zero coefficients)\n",
    "    selected_mask = lasso.coef_ != 0\n",
    "    selected_features = [all_features[i] for i in range(len(all_features)) if selected_mask[i]]\n",
    "    selected_coefficients = lasso.coef_[selected_mask]\n",
    "    \n",
    "    print(f\"Number of selected features: {len(selected_features)}\")\n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    # Training performance\n",
    "    y_train_pred = lasso.predict(X_train_scaled)\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    \n",
    "    # Test performance\n",
    "    y_test_pred = lasso.predict(X_test_scaled)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"\\\\nModel Performance:\")\n",
    "    print(f\"  Training R²: {train_r2:.6f}\")\n",
    "    print(f\"  Training RMSE: {np.sqrt(train_mse):.6f}\")\n",
    "    print(f\"  Test R²: {test_r2:.6f}\")\n",
    "    print(f\"  Test RMSE: {np.sqrt(test_mse):.6f}\")\n",
    "    \n",
    "    # Create results dictionary\n",
    "    lasso_results = {\n",
    "        'optimal_alpha': optimal_alpha,\n",
    "        'selected_features': selected_features,\n",
    "        'selected_coefficients': selected_coefficients,\n",
    "        'feature_names': all_features,\n",
    "        'all_coefficients': lasso.coef_,\n",
    "        'train_r2': train_r2,\n",
    "        'train_mse': train_mse,\n",
    "        'train_rmse': np.sqrt(train_mse),\n",
    "        'test_r2': test_r2,\n",
    "        'test_mse': test_mse,\n",
    "        'test_rmse': np.sqrt(test_mse),\n",
    "        'cv_scores': lasso_cv.mse_path_.mean(axis=1),\n",
    "        'alpha_values': alpha_values,\n",
    "        'scaler': scaler,\n",
    "        'model': lasso,\n",
    "        'train_predictions': y_train_pred,\n",
    "        'test_predictions': y_test_pred\n",
    "    }\n",
    "    \n",
    "    return selected_features, lasso_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Lasso feature selection with train-test split\n",
    "lasso_train_test_results = {}\n",
    "\n",
    "# For ICC [1/mL]\n",
    "print(\"Starting Lasso feature selection for ICC [1/mL] (Train-Test)...\")\n",
    "selected_features_icc_lasso_tt, lasso_scores_icc_tt = lasso_feature_selection_train_test(\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    target_variable='ICC [1/mL]', \n",
    "    input_variables_list=input_vars_to_use,\n",
    "    cv_folds=5\n",
    ")\n",
    "\n",
    "lasso_train_test_results['ICC [1/mL]'] = {\n",
    "    'selected_features': selected_features_icc_lasso_tt,\n",
    "    'lasso_scores': lasso_scores_icc_tt\n",
    "}\n",
    "\n",
    "# For HNAC [1/mL]\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Starting Lasso feature selection for HNAC [1/mL] (Train-Test)...\")\n",
    "selected_features_hnac_lasso_tt, lasso_scores_hnac_tt = lasso_feature_selection_train_test(\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    target_variable='HNAC [1/mL]', \n",
    "    input_variables_list=input_vars_to_use,\n",
    "    cv_folds=5\n",
    ")\n",
    "\n",
    "lasso_train_test_results['HNAC [1/mL]'] = {\n",
    "    'selected_features': selected_features_hnac_lasso_tt,\n",
    "    'lasso_scores': lasso_scores_hnac_tt\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Lasso results summary for train-test split\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"LASSO FEATURE SELECTION RESULTS SUMMARY (TRAIN-TEST SPLIT)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for target in ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    selected_features = lasso_train_test_results[target]['selected_features']\n",
    "    lasso_scores = lasso_train_test_results[target]['lasso_scores']\n",
    "    \n",
    "    print(f\"Number of selected features: {len(selected_features)}\")\n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "    print(f\"Optimal alpha: {lasso_scores['optimal_alpha']:.6f}\")\n",
    "    print(f\"Train R² Score: {lasso_scores['train_r2']:.6f}\")\n",
    "    print(f\"Test R² Score: {lasso_scores['test_r2']:.6f}\")\n",
    "    print(f\"Train RMSE: {lasso_scores['train_rmse']:.6f}\")\n",
    "    print(f\"Test RMSE: {lasso_scores['test_rmse']:.6f}\")\n",
    "    \n",
    "    # Display selected features with their coefficients\n",
    "    print(f\"\\nSelected Features and Coefficients:\")\n",
    "    for i, (feature, coef) in enumerate(zip(selected_features, lasso_scores['selected_coefficients'])):\n",
    "        print(f\"  {i+1:2d}. {feature:30s} = {coef:10.6f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cross-validation results for alpha selection\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "for i, target in enumerate(['ICC [1/mL]', 'HNAC [1/mL]']):\n",
    "    lasso_scores = lasso_train_test_results[target]['lasso_scores']\n",
    "    \n",
    "    # Plot CV scores vs alpha\n",
    "    axes[i].semilogx(lasso_scores['alpha_values'], lasso_scores['cv_scores'])\n",
    "    axes[i].axvline(x=lasso_scores['optimal_alpha'], color='red', linestyle='--', \n",
    "                   label=f'Optimal α = {lasso_scores[\"optimal_alpha\"]:.6f}')\n",
    "    axes[i].set_xlabel('Alpha (Regularization Parameter)')\n",
    "    axes[i].set_ylabel('Cross-Validation MSE')\n",
    "    axes[i].set_title(f'Lasso CV Results (Train-Test) - {target}')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FINAL SUMMARY (TRAIN-TEST SPLIT)\")\n",
    "print(\"=\"*100)\n",
    "print(\"The Lasso feature selection with train-test split provides a more robust\")\n",
    "print(\"evaluation of model performance by testing on unseen data.\")\n",
    "print(\"\\nKey advantages of Lasso with train-test split:\")\n",
    "print(\"- Better assessment of model generalization\")\n",
    "print(\"- More reliable feature selection through cross-validation\")\n",
    "print(\"- Clear separation between training and test performance\")\n",
    "print(\"- Helps identify potential overfitting\")\n",
    "print(\"\\nThe train-test approach provides more confidence in the selected features\")\n",
    "print(\"and their predictive power on new data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Train-Test Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison between full dataset and train-test split approaches\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"COMPREHENSIVE COMPARISON: FULL DATASET vs TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "for target in ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "    target_short = target.replace(' [1/mL]', '')\n",
    "    \n",
    "    # Full dataset results\n",
    "    bfs_full_features = len(bfs_results[target]['selected_features'])\n",
    "    bfs_full_aic = bfs_results[target]['aic_scores']['final']['aic']\n",
    "    \n",
    "    lasso_full_features = len(lasso_results[target]['selected_features'])\n",
    "    lasso_full_r2 = lasso_results[target]['lasso_scores']['r2_score']\n",
    "    \n",
    "    # Train-test results\n",
    "    bfs_tt_features = len(bfs_train_test_results[target]['selected_features'])\n",
    "    bfs_tt_test_r2 = bfs_train_test_results[target]['results']['test_r2']\n",
    "    bfs_tt_test_rmse = bfs_train_test_results[target]['results']['test_rmse']\n",
    "    \n",
    "    lasso_tt_features = len(lasso_train_test_results[target]['selected_features'])\n",
    "    lasso_tt_train_r2 = lasso_train_test_results[target]['lasso_scores']['train_r2']\n",
    "    lasso_tt_test_r2 = lasso_train_test_results[target]['lasso_scores']['test_r2']\n",
    "    lasso_tt_test_rmse = lasso_train_test_results[target]['lasso_scores']['test_rmse']\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Target': target_short,\n",
    "        'BFS_Full_Features': bfs_full_features,\n",
    "        'BFS_Full_AIC': round(bfs_full_aic, 4),\n",
    "        'BFS_TT_Features': bfs_tt_features,\n",
    "        'BFS_TT_Test_R2': round(bfs_tt_test_r2, 6),\n",
    "        'BFS_TT_Test_RMSE': round(bfs_tt_test_rmse, 4),\n",
    "        'Lasso_Full_Features': lasso_full_features,\n",
    "        'Lasso_Full_R2': round(lasso_full_r2, 6),\n",
    "        'Lasso_TT_Features': lasso_tt_features,\n",
    "        'Lasso_TT_Train_R2': round(lasso_tt_train_r2, 6),\n",
    "        'Lasso_TT_Test_R2': round(lasso_tt_test_r2, 6),\n",
    "        'Lasso_TT_Test_RMSE': round(lasso_tt_test_rmse, 4)\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Feature overlap analysis between methods and approaches\n",
    "print(\"\\n\\n\" + \"=\"*100)\n",
    "print(\"FEATURE OVERLAP ANALYSIS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for target in ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Get feature sets\n",
    "    bfs_full = set(bfs_results[target]['selected_features'])\n",
    "    bfs_tt = set(bfs_train_test_results[target]['selected_features'])\n",
    "    lasso_full = set(lasso_results[target]['selected_features'])\n",
    "    lasso_tt = set(lasso_train_test_results[target]['selected_features'])\n",
    "    \n",
    "    # Calculate overlaps\n",
    "    bfs_overlap = bfs_full.intersection(bfs_tt)\n",
    "    lasso_overlap = lasso_full.intersection(lasso_tt)\n",
    "    all_methods_overlap = bfs_full.intersection(bfs_tt).intersection(lasso_full).intersection(lasso_tt)\n",
    "    \n",
    "    print(f\"BFS Full Dataset ({len(bfs_full)}): {sorted(list(bfs_full))}\")\n",
    "    print(f\"BFS Train-Test ({len(bfs_tt)}): {sorted(list(bfs_tt))}\")\n",
    "    print(f\"BFS Overlap: {len(bfs_overlap)}/{min(len(bfs_full), len(bfs_tt))} ({len(bfs_overlap)/min(len(bfs_full), len(bfs_tt))*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\\\nLasso Full Dataset ({len(lasso_full)}): {sorted(list(lasso_full))}\")\n",
    "    print(f\"Lasso Train-Test ({len(lasso_tt)}): {sorted(list(lasso_tt))}\")\n",
    "    print(f\"Lasso Overlap: {len(lasso_overlap)}/{min(len(lasso_full), len(lasso_tt))} ({len(lasso_overlap)/min(len(lasso_full), len(lasso_tt))*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\\\nConsistent across ALL methods ({len(all_methods_overlap)}): {sorted(list(all_methods_overlap))}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# avoid to run this cell\n",
    "\n",
    "\n",
    "# Save train-test results and create final summary\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SAVING TRAIN-TEST RESULTS AND FINAL SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Create train-test summary DataFrame\n",
    "train_test_summary = pd.DataFrame([\n",
    "    {\n",
    "        'Target_Variable': target,\n",
    "        'BFS_TT_Features_Count': len(bfs_train_test_results[target]['selected_features']),\n",
    "        'BFS_TT_Test_R2': round(bfs_train_test_results[target]['results']['test_r2'], 6),\n",
    "        'BFS_TT_Test_RMSE': round(bfs_train_test_results[target]['results']['test_rmse'], 4),\n",
    "        'BFS_TT_Selected_Features': '; '.join(sorted(bfs_train_test_results[target]['selected_features'])),\n",
    "        'Lasso_TT_Features_Count': len(lasso_train_test_results[target]['selected_features']),\n",
    "        'Lasso_TT_Train_R2': round(lasso_train_test_results[target]['lasso_scores']['train_r2'], 6),\n",
    "        'Lasso_TT_Test_R2': round(lasso_train_test_results[target]['lasso_scores']['test_r2'], 6),\n",
    "        'Lasso_TT_Test_RMSE': round(lasso_train_test_results[target]['lasso_scores']['test_rmse'], 4),\n",
    "        'Lasso_TT_Optimal_Alpha': round(lasso_train_test_results[target]['lasso_scores']['optimal_alpha'], 6),\n",
    "        'Lasso_TT_Selected_Features': '; '.join(sorted(lasso_train_test_results[target]['selected_features']))\n",
    "    }\n",
    "    for target in ['ICC [1/mL]', 'HNAC [1/mL]']\n",
    "])\n",
    "\n",
    "# Save to Excel with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "train_test_filename = f\"feature_selection_train_test_results_{timestamp}.xlsx\"\n",
    "\n",
    "try:\n",
    "    with pd.ExcelWriter(train_test_filename, engine='openpyxl') as writer:\n",
    "        # Save train-test specific results\n",
    "        train_test_summary.to_excel(writer, sheet_name='Train_Test_Summary', index=False)\n",
    "        \n",
    "        # Save comparison between full and train-test\n",
    "        comparison_df.to_excel(writer, sheet_name='Full_vs_TrainTest_Comparison', index=False)\n",
    "        \n",
    "        # Save detailed BFS train-test results\n",
    "        bfs_tt_detailed = pd.DataFrame([\n",
    "            {\n",
    "                'Target': target,\n",
    "                'Selected_Features': '; '.join(bfs_train_test_results[target]['selected_features']),\n",
    "                'Feature_Count': len(bfs_train_test_results[target]['selected_features']),\n",
    "\n",
    "                'Train_AIC': bfs_train_test_results[target]['results']['train_aic'],\n",
    "                'Test_R2': bfs_train_test_results[target]['results']['test_r2'],\n",
    "                'Test_RMSE': bfs_train_test_results[target]['results']['test_rmse']\n",
    "            }\n",
    "            for target in ['ICC [1/mL]', 'HNAC [1/mL]']\n",
    "        ])\n",
    "        bfs_tt_detailed.to_excel(writer, sheet_name='BFS_TrainTest_Detailed', index=False)\n",
    "        \n",
    "        # Save detailed Lasso train-test results\n",
    "        lasso_tt_detailed = pd.DataFrame([\n",
    "            {\n",
    "                'Target': target,\n",
    "                'Selected_Features': '; '.join(lasso_train_test_results[target]['selected_features']),\n",
    "                'Feature_Count': len(lasso_train_test_results[target]['selected_features']),\n",
    "                'Optimal_Alpha': lasso_train_test_results[target]['lasso_scores']['optimal_alpha'],\n",
    "                'Train_R2': lasso_train_test_results[target]['lasso_scores']['train_r2'],\n",
    "                'Train_RMSE': lasso_train_test_results[target]['lasso_scores']['train_rmse'],\n",
    "                'Test_R2': lasso_train_test_results[target]['lasso_scores']['test_r2'],\n",
    "                'Test_RMSE': lasso_train_test_results[target]['lasso_scores']['test_rmse']\n",
    "            }\n",
    "            for target in ['ICC [1/mL]', 'HNAC [1/mL]']\n",
    "        ])\n",
    "        lasso_tt_detailed.to_excel(writer, sheet_name='Lasso_TrainTest_Detailed', index=False)\n",
    "    \n",
    "    print(f\"✓ Train-test results saved to: {train_test_filename}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error saving train-test results: {e}\")\n",
    "\n",
    "# Final recommendations\n",
    "print(f\"\\n\\n📊 FINAL RECOMMENDATIONS\")\n",
    "print(\"=\"*50)\n",
    "print(\"Based on the train-test split analysis:\")\n",
    "print(\"\\\\n1. MODEL GENERALIZATION:\")\n",
    "print(\"   - Use test R² scores to assess true model performance\")\n",
    "print(\"   - Compare train vs test performance to detect overfitting\")\n",
    "print(\"\\\\n2. FEATURE SELECTION RELIABILITY:\")\n",
    "print(\"   - Features selected consistently across full and train-test approaches are most reliable\")\n",
    "print(\"   - Consider features that appear in multiple methods for robustness\")\n",
    "print(\"\\\\n3. METHOD COMPARISON:\")\n",
    "print(\"   - Lasso provides both train and test performance metrics\")\n",
    "print(\"   - BFS with train-test gives better generalization estimates\")\n",
    "print(\"\\\\n4. NEXT STEPS:\")\n",
    "print(\"   - Use the most consistent features for final model development\")\n",
    "print(\"   - Consider ensemble approaches combining selected features\")\n",
    "print(\"   - Validate on additional external datasets if available\")\n",
    "\n",
    "print(f\"\\n📁 All results saved to:\")\n",
    "print(f\"   - Full dataset analysis: feature_selection_results_[timestamp].xlsx\")\n",
    "print(f\"   - Train-test analysis: {train_test_filename}\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final consolidated summary display\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FINAL CONSOLIDATED SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Display key metrics side by side\n",
    "print(\"\\n1. OVERVIEW COMPARISON\")\n",
    "print(\"-\" * 50)\n",
    "overview_df = comprehensive_summary[['Target_Variable', 'BFS_Features_Count', 'BFS_Final_AIC', \n",
    "                                   'Lasso_Features_Count', 'Lasso_R2_Score', 'Overlap_Count', \n",
    "                                   'Overlap_Pct_vs_BFS']].copy()\n",
    "overview_df.columns = ['Target', 'BFS_Count', 'BFS_AIC', 'Lasso_Count', 'Lasso_R2', 'Overlap', 'Overlap_%']\n",
    "print(overview_df.to_string(index=False))\n",
    "\n",
    "# Most consistently selected features\n",
    "print(\"\\n\\n2. MOST CONSISTENTLY SELECTED FEATURES\")\n",
    "print(\"-\" * 50)\n",
    "high_consistency = detailed_feature_summary[detailed_feature_summary['Selection_Consistency'] == 'High']\n",
    "if not high_consistency.empty:\n",
    "    print(f\"Features selected by both methods for both targets ({len(high_consistency)} features):\")\n",
    "    for _, row in high_consistency.iterrows():\n",
    "        print(f\"  • {row['Feature_Name']} ({row['Base_Variable']} - {row['Feature_Type']})\")\n",
    "else:\n",
    "    print(\"No features were selected by both methods for both targets.\")\n",
    "\n",
    "# Medium consistency features\n",
    "medium_consistency = detailed_feature_summary[detailed_feature_summary['Selection_Consistency'] == 'Medium']\n",
    "if not medium_consistency.empty:\n",
    "    print(f\"\\nMedium consistency features ({len(medium_consistency)} features):\")\n",
    "    for _, row in medium_consistency.iterrows():\n",
    "        print(f\"  • {row['Feature_Name']} ({row['Base_Variable']} - {row['Feature_Type']})\")\n",
    "\n",
    "# Top features by absolute Lasso coefficients\n",
    "print(\"\\n\\n3. TOP FEATURES BY LASSO COEFFICIENT MAGNITUDE\")\n",
    "print(\"-\" * 50)\n",
    "for target in ['ICC [1/mL]', 'HNAC [1/mL]']:\n",
    "    target_short = target.replace(' [1/mL]', '').replace(' ', '_')\n",
    "    coef_col = f'{target_short}_Lasso_Coefficient'\n",
    "    \n",
    "    target_features = detailed_feature_summary[detailed_feature_summary[coef_col] != 0].copy()\n",
    "    if not target_features.empty:\n",
    "        target_features['abs_coef'] = abs(target_features[coef_col])\n",
    "        target_features = target_features.sort_values('abs_coef', ascending=False).head(5)\n",
    "        \n",
    "        print(f\"\\n{target} - Top 5 by coefficient magnitude:\")\n",
    "        for _, row in target_features.iterrows():\n",
    "            coef_val = row[coef_col]\n",
    "            print(f\"  • {row['Feature_Name']:30s} = {coef_val:8.4f}\")\n",
    "\n",
    "# Feature type analysis\n",
    "print(\"\\n\\n4. FEATURE TYPE ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "feature_type_summary = detailed_feature_summary.groupby(['Base_Variable', 'Feature_Type']).agg({\n",
    "    'Total_Selections': 'sum',\n",
    "    'Feature_Name': 'count'\n",
    "}).rename(columns={'Feature_Name': 'Count'}).reset_index()\n",
    "\n",
    "base_var_summary = feature_type_summary.groupby('Base_Variable').agg({\n",
    "    'Total_Selections': 'sum',\n",
    "    'Count': 'sum'\n",
    "}).sort_values('Total_Selections', ascending=False)\n",
    "\n",
    "print(\"Variable importance by total selections across all methods and targets:\")\n",
    "for var, data in base_var_summary.head(10).iterrows():\n",
    "    print(f\"  • {var:25s}: {data['Total_Selections']:2d} selections ({data['Count']:2d} features)\")\n",
    "\n",
    "print(f\"\\n\\n📊 SUMMARY STATISTICS:\")\n",
    "print(f\"   Total unique features analyzed: {len(detailed_feature_summary)}\")\n",
    "print(f\"   Features with high consistency: {len(high_consistency)}\")\n",
    "print(f\"   Features with medium consistency: {len(medium_consistency)}\")\n",
    "print(f\"   Average BFS features per target: {comprehensive_summary['BFS_Features_Count'].mean():.1f}\")\n",
    "print(f\"   Average Lasso features per target: {comprehensive_summary['Lasso_Features_Count'].mean():.1f}\")\n",
    "print(f\"   Average overlap percentage: {comprehensive_summary['Overlap_Pct_vs_BFS'].mean():.1f}%\")\n",
    "\n",
    "print(f\"\\n📁 Data saved to Excel file: {output_filename}\")\n",
    "print(\"   Contains 4 sheets: Summary_by_Target, Detailed_Feature_Analysis, BFS_Results, Lasso_Results\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safecrew-3OLHM_8n-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
