{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feltre Sensor Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_folder = os.path.join(\"..\", \"..\", \"utils\")\n",
    "\n",
    "with open(os.path.join(utils_folder, \"onedrive.txt\"), \"r\") as f:\n",
    "    cloud_data_folder = os.path.join(f.readline().strip(), \"Centrali\")\n",
    "\n",
    "sensor_folder = os.path.join(cloud_data_folder, \"Sensori\")\n",
    "feltre_folder = os.path.join(sensor_folder, \"Feltre\")\n",
    "probe_folder = os.path.join(feltre_folder, \"Sonde\")\n",
    "cytometer_folder = os.path.join(probe_folder, \"Citometro\")\n",
    "multiparam_folder = os.path.join(probe_folder, \"Multiparametrica\")\n",
    "\n",
    "local_data_folder = os.path.join(\"..\", \"..\", \"data\")\n",
    "clean_data_folder = os.path.join(local_data_folder, \"Clean Data\")\n",
    "plot_data_folder = os.path.join(local_data_folder, \"Plots\", \"Feltre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cytometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cytometer data\n",
    "\n",
    "cytometer_files = [f for f in os.listdir(cytometer_folder) if f.endswith(\".xlsx\")]\n",
    "\n",
    "auto_cytometer_df = pd.DataFrame()\n",
    "error_cytometer_df = pd.DataFrame()\n",
    "\n",
    "for cytometer_file in cytometer_files:\n",
    "    \n",
    "    if \"auto\" in cytometer_file:\n",
    "        if auto_cytometer_df.empty:\n",
    "            auto_cytometer_df = pd.read_excel(os.path.join(cytometer_folder, cytometer_file))\n",
    "        else:\n",
    "            auto_cytometer_df = pd.concat([auto_cytometer_df, pd.read_excel(os.path.join(cytometer_folder, cytometer_file))])\n",
    "        \n",
    "    elif \"error\" in cytometer_file:\n",
    "        if error_cytometer_df.empty:\n",
    "            error_cytometer_df = pd.read_excel(os.path.join(cytometer_folder, cytometer_file))\n",
    "        else:\n",
    "            error_cytometer_df = pd.concat([error_cytometer_df, pd.read_excel(os.path.join(cytometer_folder, cytometer_file))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_cytometer_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_cytometer_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are common dates between the two dataframes\n",
    "common_dates = np.intersect1d(auto_cytometer_df[\"Date [local]\"], error_cytometer_df[\"Date [local]\"])\n",
    "common_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no common dates, so the error dataframe is not useful as the auto dataframe already removes the errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiparam_files = [f for f in os.listdir(multiparam_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "param_df = pd.DataFrame()\n",
    "spectro_df = pd.DataFrame()\n",
    "\n",
    "for multiparam_file in multiparam_files:\n",
    "\n",
    "    if 'par' in multiparam_file:\n",
    "        if param_df.empty:\n",
    "            param_df = pd.read_csv(os.path.join(multiparam_folder, multiparam_file), sep=\";\", header=1)\n",
    "        else:\n",
    "            param_df = pd.concat([param_df, pd.read_csv(os.path.join(multiparam_folder, multiparam_file), sep=\";\", header=1)])\n",
    "            \n",
    "    elif 'spec' in multiparam_file:\n",
    "        if spectro_df.empty:\n",
    "            spectro_df = pd.read_csv(os.path.join(multiparam_folder, multiparam_file), sep=\";\", header=1)\n",
    "        else:\n",
    "            spectro_df = pd.concat([spectro_df, pd.read_csv(os.path.join(multiparam_folder, multiparam_file), sep=\";\", header=1)])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cytometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyto_df = auto_cytometer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyto_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyto_df.drop(\n",
    "    columns=[\n",
    "        'Timestamp',\n",
    "        'Date [local]',\n",
    "        'Date [GMT]',\n",
    "        'Instrument Name',\n",
    "        'Instrument SN',\n",
    "        'Mode',\n",
    "        'Name',\n",
    "        'Protocol',\n",
    "        'TCC [1/mL]',\n",
    "        'GATE+ [1/mL]',\n",
    "        'ACC [1/mL]',\n",
    "        'HACC [1/mL]',\n",
    "        'LACC [1/mL]',\n",
    "        'HACP [%]',\n",
    "        'Cartridge Fill',\n",
    "    ],\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyto_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyto_df.rename(\n",
    "    columns={\n",
    "        'Sampling Date [local]': 'DateTime',\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to keep just the measured values as we would build online soft sensors for them\n",
    "params_columns_to_drop = [col for col in param_df.columns if 'Clean' in col]\n",
    "params_columns_to_drop.append('Status')\n",
    "params_columns_to_drop.append('Temperature - Measured value [Â°C] (Limit:0.00-45.00_Coefs:0.00 0.00 0.00 0.00)')\n",
    "\n",
    "# remove all the wavelenghts that are not the 254nm one\n",
    "spectro_columns_to_drop = [col for col in spectro_df.columns if '254' not in col]\n",
    "spectro_columns_to_drop.remove('Measurement interval=900[sec] (Export-Aggregation disabled)')\n",
    "spectro_columns_to_drop.append('Status (Source:0)')\n",
    "\n",
    "param_df.drop(columns=params_columns_to_drop, inplace=True)\n",
    "spectro_df.drop(columns=spectro_columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the columns with all NaN values and a small amount of valid values\n",
    "param_df.drop(\n",
    "    columns=[\n",
    "        'Total Chlorine - Measured value [mg/l] (Limit:0.00-2.00_Coefs:0.00 1.00 0.00 0.00)',\n",
    "        'pH - Measured value (Limit:0.00-14.00_Coefs:-2.40 0.97 0.00 0.00)',\n",
    "    ],\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df.drop(\n",
    "    columns=[\n",
    "        'Temperature - Measured value [C] (Limit:-5.00-100.00_Coefs:-0.40 1.00 0.00 0.00)',\n",
    "        'Status [Temperature - Measured value].1',\n",
    "        'Status [Temperature - Measured value].2',\n",
    "        'Status [Total Chlorine - Measured value]'\n",
    "    ],\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cytometer\n",
    "\n",
    "* BactoSense: misurazioni di:\n",
    "    * ICC [1/mL]: concentrazione di cellule intatte\n",
    "    * HNAC [1/mL]: concentrazione di cellule ad alto contenuto di acido nucleico\n",
    "    * LNAC [1/mL]: concentrazione di cellule a basso contenuto di acido nucleico\n",
    "    * HNAP [%]: frazione di ICC costituita da cellule ad alto contenuto di acido nucleico\n",
    "    * TCC [1/mL] (no valori)\n",
    "    * GATE+ [1/mL] (no valori)\n",
    "    * ACC [1/mL] (no valori)\n",
    "    * HACC [1/mL] (no valori)\n",
    "    * LACC [1/mL] (no valori)\n",
    "    * HACP [%] (no valori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_columns = [\n",
    "    'ICC [1/mL]',\n",
    "    'HNAC [1/mL]',\n",
    "    'LNAC [1/mL]',\n",
    "    'HNAP [%]',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in measurement_columns:\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=cyto_df[\"DateTime\"],\n",
    "            y=cyto_df[col],\n",
    "            mode='lines',\n",
    "            name=col,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    warning_df = cyto_df[cyto_df['Warnings'].notna()]\n",
    "    \n",
    "    if not warning_df.empty:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=warning_df[\"DateTime\"],\n",
    "                y=warning_df[col],\n",
    "                mode='markers',\n",
    "                marker=dict(color='red'),\n",
    "                name='Warnings',\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=col,\n",
    "        xaxis_title=\"DateTime\",\n",
    "        yaxis_title=col,\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove first samples as BactoSense was not yet calibrated\n",
    "cyto_df = cyto_df[cyto_df['DateTime'] >= '2024-11-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ICC measurements above 70k as they are not reliable\n",
    "cyto_df.loc[cyto_df['ICC [1/mL]'] > 70000, 'ICC [1/mL]'] = np.nan\n",
    "\n",
    "# Remove HNAC measurements above 70k as they are not reliable\n",
    "cyto_df.loc[cyto_df['HNAC [1/mL]'] > 70000, 'HNAC [1/mL]'] = np.nan\n",
    "\n",
    "# Remove measurements == 0 as they are not reliable\n",
    "cyto_df.loc[cyto_df['ICC [1/mL]'] == 0, 'ICC [1/mL]'] = np.nan\n",
    "cyto_df.loc[cyto_df['HNAC [1/mL]'] == 0, 'HNAC [1/mL]'] = np.nan\n",
    "cyto_df.loc[cyto_df['LNAC [1/mL]'] == 0, 'LNAC [1/mL]'] = np.nan\n",
    "cyto_df.loc[cyto_df['HNAP [%]'] == 0, 'HNAP [%]'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove measurements of 18-02 as the instrument was turning on\n",
    "\n",
    "condition = (cyto_df['DateTime'].dt.date == datetime.strptime('2025-02-18', '%Y-%m-%d').date())\n",
    "parameters = cyto_df.columns.difference(['DateTime', 'Warnings'])\n",
    "\n",
    "cyto_df.loc[condition, parameters] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values with time interpolation\n",
    "cyto_df.set_index('DateTime', inplace=True)\n",
    "cyto_df.interpolate(method='time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyto_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in measurement_columns:\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=cyto_df[\"DateTime\"],\n",
    "            y=cyto_df[col],\n",
    "            mode='lines',\n",
    "            name=col,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    warning_df = cyto_df[cyto_df['Warnings'].notna()]\n",
    "    \n",
    "    if not warning_df.empty:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=warning_df[\"DateTime\"],\n",
    "                y=warning_df[col],\n",
    "                mode='markers',\n",
    "                marker=dict(color='red'),\n",
    "                name='Warnings',\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=col,\n",
    "        xaxis_title=\"DateTime\",\n",
    "        yaxis_title=col,\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df.rename(\n",
    "    columns={\n",
    "        'Measurement interval=900[sec] (Export-Aggregation disabled)': 'DateTime',\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df['DateTime'] = pd.to_datetime(param_df['DateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df.sort_values(by='DateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(columns):\n",
    "    \n",
    "    new_columns = [col.split(']')[0] + ']' for col in columns]\n",
    "    \n",
    "    new_columns = [col.split('(')[0] if 'Limit' in col else col for col in new_columns]\n",
    "    \n",
    "    for col in new_columns:\n",
    "        if 'Result' in col:\n",
    "            new_columns[new_columns.index(col)] = col.replace(' - Result', '')\n",
    "        \n",
    "        if ' - Measured value' in col:\n",
    "            new_columns[new_columns.index(col)] = col.replace(' - Measured value', '')\n",
    "            \n",
    "    for col in new_columns:\n",
    "        if col == 'pH ':\n",
    "            new_columns[new_columns.index(col)] = 'pH'\n",
    "        \n",
    "        # TODO add unit of measure to the column name\n",
    "        if col == 'UV254 ':\n",
    "            new_columns[new_columns.index(col)] = 'UV254'\n",
    "        \n",
    "        if col == 'nitrati ':\n",
    "            new_columns[new_columns.index(col)] = 'nitrati'\n",
    "        \n",
    "        if col == 'nitriti ':\n",
    "            new_columns[new_columns.index(col)] = 'nitriti'\n",
    "        \n",
    "    return new_columns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_column = param_df['DateTime']\n",
    "param_df.drop(columns='DateTime', inplace=True)\n",
    "\n",
    "param_df.columns = rename_columns(param_df.columns)\n",
    "\n",
    "param_df['DateTime'] = dt_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in param_df.columns:\n",
    "    \n",
    "    if  (column == 'DateTime') or ('Status' in column):\n",
    "        continue\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=param_df[\"DateTime\"],\n",
    "            y=param_df[column],\n",
    "            mode='lines',\n",
    "            name=column,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # make the NaN values red\n",
    "    nan_df = param_df[param_df[column].isna()]\n",
    "    \n",
    "    # make error values brown\n",
    "    \n",
    "    # TODO provvisorio, da sistemare dopo aver capito le unitÃ  di misura\n",
    "    \n",
    "    \n",
    "    status_col = 'Status [' + column.split(' [')[0] + ']'\n",
    "    error_df = param_df[param_df[status_col].str.contains('Error', na=False)]\n",
    "    \n",
    "    if not error_df.empty:\n",
    "        for index, row in error_df.iterrows():\n",
    "            fig.add_vline(x=row['DateTime'], line=dict(color='yellow', width=0.5))\n",
    "            \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[None],\n",
    "                y=[None],\n",
    "                mode='lines',\n",
    "                marker=dict(color='yellow'),\n",
    "                name='Error',\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    if not nan_df.empty:\n",
    "        for index, row in nan_df.iterrows():\n",
    "            fig.add_vline(x=row['DateTime'], line=dict(color='red', width=0.5))\n",
    "            \n",
    "        # add a legend for the NaN values\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[None],\n",
    "                y=[None],\n",
    "                mode='lines',\n",
    "                marker=dict(color='red'),\n",
    "                name='NaN',\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=column,\n",
    "        xaxis_title=\"DateTime\",\n",
    "        yaxis_title=column,\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop pH-mV and nitriti columns as they are not useful\n",
    "param_df.drop(columns=['pH-mV [mV]', 'nitriti'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro_df.rename(\n",
    "    columns={\n",
    "        'Measurement interval=900[sec] (Export-Aggregation disabled)': 'DateTime',\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "spectro_df.sort_values(by='DateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=spectro_df[\"DateTime\"],\n",
    "        y=spectro_df['254 nm'],\n",
    "        mode='lines',\n",
    "        name='Spectro',\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=param_df[\"DateTime\"],\n",
    "        y=param_df['UV254'],\n",
    "        mode='lines',\n",
    "        name='Multiparam',\n",
    "    )\n",
    ")\n",
    "    \n",
    "fig.update_layout(\n",
    "    title='254 nm',\n",
    "    xaxis_title=\"DateTime\",\n",
    "    yaxis_title='254 nm',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same exact values, so the spectro data is not useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something happened around 25-09-2024, let's check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each parameter, print the dates that have NaN values\n",
    "for column in param_df.columns:\n",
    "    \n",
    "    if  (column == 'DateTime') or ('Status' in column):\n",
    "        continue\n",
    "    \n",
    "    nan_df = param_df[param_df[column].isna()]\n",
    "    \n",
    "    if not nan_df.empty:\n",
    "        print('='*50)\n",
    "        print(column)\n",
    "        print('='*50)\n",
    "        print()\n",
    "        print('NaN values dates:')\n",
    "        print(nan_df['DateTime'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems that the before the July NaN values most of the measurements come from a different distribution\n",
    "# The same happens for the September anomalies\n",
    "\n",
    "for column in param_df.columns:\n",
    "    \n",
    "    if  (column == 'DateTime') or ('Status' in column):\n",
    "        continue\n",
    "    \n",
    "    df = param_df[['DateTime', column]]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # pre July\n",
    "    pre_july_df = df[df['DateTime'] < '2024-07-03']\n",
    "    \n",
    "    # between July and September\n",
    "    between_july_sept_df = df[(df['DateTime'] >= '2024-07-03') & (df['DateTime'] < '2024-09-22')]\n",
    "    \n",
    "    # post September\n",
    "    post_sept_df = df[df['DateTime'] >= '2024-09-30']\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Box(\n",
    "            y=pre_july_df[column],\n",
    "            name='Pre July',\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Box(\n",
    "            y=between_july_sept_df[column],\n",
    "            name='Between July and September',\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Box(\n",
    "            y=post_sept_df[column],\n",
    "            name='Post September',\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=column,\n",
    "        yaxis_title=column,\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Dates\n",
    "\n",
    "* BactoSense: misurazioni di:\n",
    "    * ICC [1/mL]: concentrazione di cellule intatte\n",
    "    * HNAC [1/mL]: concentrazione di cellule ad alto contenuto di acido nucleico\n",
    "    * LNAC [1/mL]: concentrazione di cellule a basso contenuto di acido nucleico\n",
    "    * HNAP [%]: frazione di ICC costituita da cellule ad alto contenuto di acido nucleico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the range of dates of the cyto_df\n",
    "min_date = cyto_df['DateTime'].min()\n",
    "max_date = cyto_df['DateTime'].max()\n",
    "\n",
    "# get only the rows of the param_df that are in the range of the cyto_df\n",
    "param_df = param_df[(param_df['DateTime'] >= min_date) & (param_df['DateTime'] <= max_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyto_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    \"Pressione [atm]\": \"Pressure (atm)\",\n",
    "    \"pH\": \"pH\",\n",
    "    \"Conductivity [uS/cm]\": \"Conductivity (uS/cm)\",\n",
    "    \"Temperature [Â°C]\": \"Temperature (Â°C)\",\n",
    "    \"UV254\": \"UVA254 (1/cm)\",\n",
    "    \"nitrati\": \"Nitrate (mg/l)\",\n",
    "    \"Turbidity [FTU]\": \"Turbidity (NTU)\",\n",
    "    \"TOCeq [mg/l]\": \"TOC (mg/l)\",\n",
    "    \"DOCeq [mg/l]\": \"DOC (mg/l)\",\n",
    "    \"Free Chlorine [mg/l]\": \"Free Chlorine (mg/l)\",\n",
    "    \"ICC [1/mL]\": \"ICC (1/mL)\",\n",
    "    \"HNAC [1/mL]\": \"HNAC (1/mL)\",\n",
    "    \"LNAC [1/mL]\": \"LNAC (1/mL)\",\n",
    "    \"HNAP [%]\": \"HNAP (%)\",\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_plot_data_folder = os.path.join(plot_data_folder, \"Dec_24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in param_df.columns:\n",
    "    \n",
    "    if  (column == 'DateTime') or ('Status' in column):\n",
    "        continue\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=param_df[param_df['DateTime'] >= pd.Timestamp('29-11-2024')][\"DateTime\"],\n",
    "            y=param_df[param_df['DateTime'] >= pd.Timestamp('29-11-2024')][column],\n",
    "            mode='lines',\n",
    "            name=column_mapping[column],\n",
    "            line=dict(color='green'),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=column_mapping[column],\n",
    "        margin=dict(l=0, r=10, t=30,b=0),\n",
    "    )\n",
    "    \n",
    "    # update overall font size\n",
    "    fig.update_layout(\n",
    "        font=dict(\n",
    "            size=17,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    column_ = column.replace('/', '_')\n",
    "    \n",
    "    fig.write_image(\n",
    "        os.path.join(dec_plot_data_folder, f\"{column_}.png\"),\n",
    "        scale=3\n",
    "    )\n",
    "    \n",
    "\n",
    "for col in measurement_columns:\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=cyto_df[cyto_df['DateTime'] >= pd.Timestamp('29-11-2024')][\"DateTime\"],\n",
    "            y=cyto_df[cyto_df['DateTime'] >= pd.Timestamp('29-11-2024')][col],\n",
    "            mode='lines',\n",
    "            name=column_mapping[col],\n",
    "            line=dict(color='blue'),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=column_mapping[col],\n",
    "        margin=dict(l=0, r=10, t=30, b=0),\n",
    "    )\n",
    "    \n",
    "    # update overall font size\n",
    "    fig.update_layout(\n",
    "        font=dict(\n",
    "            size=17,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    col_ = col.replace('/', '_')\n",
    "    \n",
    "    fig.write_image(\n",
    "        os.path.join(dec_plot_data_folder, f\"{col_}.png\"),\n",
    "        scale=3\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove status columns from the param_df\n",
    "status_columns = [col for col in param_df.columns if 'Status' in col]\n",
    "\n",
    "param_df.drop(columns=status_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df.set_index('DateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df = param_df.resample('15min').mean().interpolate(method='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyto_df.drop(columns=['Warnings', 'Alarms'], inplace=True)\n",
    "cyto_df.set_index('DateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to resample the cyto_df as it has a different frequency, we choose to resample it to 15 minutes to match the param_df and avoid losing information\n",
    "cyto_df = cyto_df.resample('15min').median().interpolate(method='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyto_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two dataframes\n",
    "merged_df = pd.merge(cyto_df, param_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.rename(\n",
    "    columns={\n",
    "        'nitrati': 'Nitrate [mg/l]',\n",
    "        'UV254': 'UV254 [1/m]',\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data Cleaning\n",
    "\n",
    "Since there is a big gap in output variables, I decided to split the dataset into two different ones and build two different models for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something happened on 26-02-2025, we are going to remove the data in that date for the following columns:\n",
    "# - UVA254\n",
    "# - Nitrate\n",
    "# - Turbidity\n",
    "# - TOC\n",
    "# - DOC\n",
    "\n",
    "columns_to_remove = [\n",
    "    'UV254 [1/m]',\n",
    "    'Nitrate [mg/l]',\n",
    "    'Turbidity [FTU]',\n",
    "    'TOCeq [mg/l]',\n",
    "    'DOCeq [mg/l]',\n",
    "]\n",
    "\n",
    "merged_df.loc[merged_df.index.date == pd.Timestamp('2025-02-26').date(), columns_to_remove] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.interpolate(method='time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_to_remove:\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=merged_df[merged_df.index >= pd.Timestamp('29-11-2024')].index,\n",
    "            y=merged_df[merged_df.index >= pd.Timestamp('29-11-2024')][column],\n",
    "            mode='lines',\n",
    "            name=column,\n",
    "            line=dict(color='green'),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=column,\n",
    "        margin=dict(l=0, r=10, t=30, b=0),\n",
    "    )\n",
    "    \n",
    "    # update overall font size\n",
    "    fig.update_layout(\n",
    "        font=dict(\n",
    "            size=17,\n",
    "        )\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_merged_df = merged_df[merged_df.index <= pd.Timestamp('2024-12-22')]\n",
    "second_merged_df = merged_df[merged_df.index >= pd.Timestamp('2025-02-19')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_merged_df.to_excel(os.path.join(clean_data_folder, \"Feltre\", \"first_part.xlsx\"))\n",
    "second_merged_df.to_excel(os.path.join(clean_data_folder, \"Feltre\", \"second_part.xlsx\")) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safecrew-3OLHM_8n-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
