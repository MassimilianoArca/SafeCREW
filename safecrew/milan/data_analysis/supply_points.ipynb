{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supply Points Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "from pathvalidate import sanitize_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/massimilianoarca/Documents/PoliMi/Research Grant/SafeCREW/Data/Milano\"\n",
    "root_folder_path = \"/Users/massimilianoarca/Library/CloudStorage/OneDrive-PolitecnicodiMilano/SafeCREW/soft_sensors/Soft Sensor CS2Milan\"\n",
    "\n",
    "dir_temporary_results_path = os.path.join(data_path, \"temporary results\")\n",
    "raw_grab_samples_path = os.path.join(\n",
    "    dir_temporary_results_path, \"raw_grab_samples_supply_points.xlsx\"\n",
    ")\n",
    "house_codes_path = os.path.join(data_path, \"Case-Codici.xlsx\")\n",
    "sensor_data_folder_path = os.path.join(\n",
    "    root_folder_path, \"Case dell'acqua - Sensori\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_values(series):\n",
    "    num_nans = series.isna().sum()\n",
    "    strings = series[\n",
    "        series.astype(str).str.contains(\"|\".join([\"<\", \"\\*\", \">\", \"[a-zA-Z]\"]))\n",
    "    ].count()\n",
    "    num_numbers = series[\n",
    "        series.apply(lambda x: isinstance(x, (int, float)))\n",
    "    ].count()\n",
    "    return pd.Series(\n",
    "        [num_nans, strings, num_numbers], index=[\"NaN\", \"Strings\", \"numbers\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def convert_string_values(s):\n",
    "    if isinstance(s, (int, float)):\n",
    "        return s\n",
    "    elif pd.isna(s):\n",
    "        return None\n",
    "    else:\n",
    "        if \",\" in s:\n",
    "            s = s.replace(\",\", \".\")\n",
    "        if \"<\" in s:\n",
    "            number = re.findall(r\"\\d+\\.?\\d*\", s)\n",
    "            return float(number[0]) / 2 if number else None\n",
    "        elif \">\" in s:\n",
    "            number = re.findall(r\"\\d+\\.?\\d*\", s)\n",
    "            return float(number[0]) if number else None\n",
    "        elif \"*\" in s or re.search(\"[a-zA-Z]\", s):\n",
    "            number = re.findall(r\"\\d+\\.?\\d*\", s)\n",
    "            return float(number[0]) if number else None\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_grab_samples_df = pd.read_excel(raw_grab_samples_path, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_grab_samples_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = raw_grab_samples_df.columns[7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Case dell'Acqua - Overall Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN vs Strings vs Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram = raw_grab_samples_df[columns].apply(count_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram.loc[\"Total\"] = histogram.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see Strings add 'Strings' to the list below\n",
    "ax = histogram.T[[\"NaN\", \"numbers\"]].plot.bar(figsize=(30, 10))\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.02))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert String Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_grab_samples_df[columns] = raw_grab_samples_df[columns].applymap(\n",
    "    convert_string_values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "for column in columns:\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    hist = raw_grab_samples_df[column].where(\n",
    "        raw_grab_samples_df[column].apply(lambda x: isinstance(x, (int, float)))\n",
    "    )\n",
    "    count, bins, patches = plt.hist(\n",
    "        hist.dropna(), bins=30, edgecolor=\"black\", linewidth=1.2\n",
    "    )\n",
    "    plt.title(\n",
    "        column\n",
    "        + \" - Count: \"\n",
    "        + str(hist.count())\n",
    "        + \" / \"\n",
    "        + str(raw_grab_samples_df.shape[0])\n",
    "    )\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    # Set x-ticks to bin edges and x-tick labels to intervals\n",
    "    plt.xticks(\n",
    "        bins[:-1],\n",
    "        [f\"{bins[i]:.2f}-{bins[i+1]:.2f}\" for i in range(len(bins) - 1)],\n",
    "        rotation=\"vertical\",\n",
    "        fontsize=8,\n",
    "    )\n",
    "\n",
    "    # Add count for every bar\n",
    "    for p in patches:\n",
    "        plt.annotate(\n",
    "            str(int(p.get_height())), (p.get_x() * 1.005, p.get_height() * 1.02)\n",
    "        )\n",
    "\n",
    "    # directory = os.path.join(dir_temporary_results_path, \"histograms_all\")\n",
    "    # if not os.path.exists(directory):\n",
    "    #     os.makedirs(directory)\n",
    "\n",
    "    # plt.savefig(\n",
    "    #     os.path.join(\n",
    "    #         directory,\n",
    "    #         sanitize_filename(column) + \".png\",\n",
    "    #     ),\n",
    "    #     dpi=300,\n",
    "    # )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "for col in columns:\n",
    "    sanitized_col = sanitize_filename(col)\n",
    "    # Extract unit of measure from column name\n",
    "    raw_grab_samples_df.plot(\n",
    "        x=\"Data di prelievo\",\n",
    "        y=col,\n",
    "        legend=False,\n",
    "        title=f\"{sanitized_col}\",\n",
    "        fontsize=8,\n",
    "        figsize=(40, 10),\n",
    "    )\n",
    "    # directory = f\"/Users/massimilianoarca/Documents/PoliMi/Research Grant/SafeCREW/Data/Milano/Grab samples data plots/{sanitized_col}\"\n",
    "    # if not os.path.exists(directory):\n",
    "    #     os.makedirs(directory)\n",
    "    # plt.savefig(f\"{directory}/{sanitized_col}.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Case dell'Acqua - Overall Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Codes Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_code_df = pd.read_excel(house_codes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_code_df[\"Casa dell'acqua\"][7] = houses_code_df[\"Casa dell'acqua\"][\n",
    "    7\n",
    "].rstrip()\n",
    "\n",
    "houses_code_df.loc[4] = [\"Chiostergi\", \"HOUSE_CHIOSTERGI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_code_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Overall Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep just rows of raw_grab_samples_df that have a Codice punto di prelievo\n",
    "# that is contained in the houses_code_df Codice Punto di Prelievo\n",
    "grab_samples_df = raw_grab_samples_df.merge(\n",
    "    houses_code_df,\n",
    "    left_on=\"Codice punto di prelievo\",\n",
    "    right_on=\"Codice Punto di Prelievo\",\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "grab_samples_df.drop(\n",
    "    columns=[\"Casa dell'acqua\", \"Codice Punto di Prelievo\"], inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_samples_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN vs Strings vs Numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram = grab_samples_df[columns].apply(count_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram.loc[\"Total\"] = histogram.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = histogram.T[[\"NaN\", \"numbers\"]].plot.bar(figsize=(30, 10))\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.02))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Distributions Divergence to Exploit More Data (All vs Selected Overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m w_distances \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# For each feature in the DataFrame\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcolumns\u001b[49m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# # Compute the probability distribution of the feature in each DataFrame\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# pdist_raw = np.histogram(raw_grab_samples_df[feature].dropna(), bins=100, density=True)[0]\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# pdist_grab = np.histogram(grab_samples_df[feature].dropna(), bins=100, density=True)[0]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# # Add a small constant to avoid division by zero\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# pdist_raw = pdist_raw + np.finfo(np.float64).eps\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# pdist_grab = pdist_grab + np.finfo(np.float64).eps\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m         raw_grab_samples_df[feature]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mempty\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m grab_samples_df[feature]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mempty\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(grab_samples_df[feature]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39munique()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     21\u001b[0m     ):\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'columns' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store the KL divergence for each feature\n",
    "kl_divergences = {}\n",
    "js_divergences = {}\n",
    "tv_distances = {}\n",
    "w_distances = {}\n",
    "\n",
    "# For each feature in the DataFrame\n",
    "for feature in columns:\n",
    "    # # Compute the probability distribution of the feature in each DataFrame\n",
    "    # pdist_raw = np.histogram(raw_grab_samples_df[feature].dropna(), bins=100, density=True)[0]\n",
    "    # pdist_grab = np.histogram(grab_samples_df[feature].dropna(), bins=100, density=True)[0]\n",
    "\n",
    "    # # Add a small constant to avoid division by zero\n",
    "    # pdist_raw = pdist_raw + np.finfo(np.float64).eps\n",
    "    # pdist_grab = pdist_grab + np.finfo(np.float64).eps\n",
    "\n",
    "    if (\n",
    "        raw_grab_samples_df[feature].dropna().empty\n",
    "        or grab_samples_df[feature].dropna().empty\n",
    "        or len(grab_samples_df[feature].dropna().unique()) == 1\n",
    "    ):\n",
    "        continue\n",
    "\n",
    "    kde_raw = gaussian_kde(raw_grab_samples_df[feature].dropna())\n",
    "    kde_grab = gaussian_kde(grab_samples_df[feature].dropna())\n",
    "\n",
    "    # Evaluate the KDEs on a range of values\n",
    "    x = np.linspace(\n",
    "        min(raw_grab_samples_df[feature].min(), grab_samples_df[feature].min()),\n",
    "        max(raw_grab_samples_df[feature].max(), grab_samples_df[feature].max()),\n",
    "        100,\n",
    "    )\n",
    "    pdist_raw = kde_raw(x)\n",
    "    pdist_grab = kde_grab(x)\n",
    "\n",
    "    # Compute the KL divergence and store it in the dictionary\n",
    "    kl_divergences[feature] = stats.entropy(pdist_raw, pdist_grab)\n",
    "    js_divergences[feature] = jensenshannon(pdist_raw, pdist_grab)\n",
    "    tv_distances[feature] = np.sum(np.abs(pdist_raw - pdist_grab)) / 2\n",
    "    w_distances[feature] = wasserstein_distance(pdist_raw, pdist_grab)\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "kl_divergences_df = pd.DataFrame.from_dict(\n",
    "    kl_divergences, orient=\"index\", columns=[\"KL Divergence\"]\n",
    ")\n",
    "js_divergences_df = pd.DataFrame.from_dict(\n",
    "    js_divergences, orient=\"index\", columns=[\"JS Divergence\"]\n",
    ")\n",
    "tv_distances_df = pd.DataFrame.from_dict(\n",
    "    tv_distances, orient=\"index\", columns=[\"TV Distance\"]\n",
    ")\n",
    "w_distances_df = pd.DataFrame.from_dict(\n",
    "    w_distances, orient=\"index\", columns=[\"Wasserstein Distance\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Case dell'Acqua - One by One Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN vs Strings vs Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in grab_samples_df[\"Codice punto di prelievo\"].unique():\n",
    "    histogram = grab_samples_df[\n",
    "        grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "    ][columns].apply(count_values)\n",
    "    histogram.loc[\"Total\"] = histogram.sum()\n",
    "    ax = histogram.T[[\"NaN\", \"numbers\"]].plot.bar(figsize=(30, 10))\n",
    "    ax.set_title(code)\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(\n",
    "            str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.02)\n",
    "        )\n",
    "\n",
    "    directory = os.path.join(dir_temporary_results_path, \"histograms_by_house\")\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    plt.savefig(\n",
    "        os.path.join(\n",
    "            directory,\n",
    "            sanitize_filename(code) + \".png\",\n",
    "        ),\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "for code in grab_samples_df[\"Codice punto di prelievo\"].unique():\n",
    "    for column in columns:\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        hist = grab_samples_df[\n",
    "            grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "        ][column].where(\n",
    "            grab_samples_df[\n",
    "                grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "            ][column].apply(lambda x: isinstance(x, (int, float)))\n",
    "        )\n",
    "        count, bins, patches = plt.hist(\n",
    "            hist.dropna(), bins=30, edgecolor=\"black\", linewidth=1.2\n",
    "        )\n",
    "        plt.title(\n",
    "            code\n",
    "            + \" - \"\n",
    "            + column\n",
    "            + \" - Count: \"\n",
    "            + str(hist.count())\n",
    "            + \" / \"\n",
    "            + str(\n",
    "                grab_samples_df[\n",
    "                    grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "                ].shape[0]\n",
    "            )\n",
    "        )\n",
    "        plt.ylabel(\"Frequency\")\n",
    "\n",
    "        # Set x-ticks to bin edges and x-tick labels to intervals\n",
    "        plt.xticks(\n",
    "            bins[:-1],\n",
    "            [f\"{bins[i]:.2f}-{bins[i+1]:.2f}\" for i in range(len(bins) - 1)],\n",
    "            rotation=\"vertical\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "\n",
    "        # Add count for every bar\n",
    "        for p in patches:\n",
    "            plt.annotate(\n",
    "                str(int(p.get_height())),\n",
    "                (p.get_x() * 1.005, p.get_height() * 1.02),\n",
    "            )\n",
    "\n",
    "        # directory = os.path.join(dir_temporary_results_path, \"histograms_filtered\")\n",
    "        # if not os.path.exists(directory):\n",
    "        #     os.makedirs(directory)\n",
    "\n",
    "        # plt.savefig(\n",
    "        #     os.path.join(\n",
    "        #         directory,\n",
    "        #         sanitize_filename(code + ' - ' + column) + \".png\",\n",
    "        #     ),\n",
    "        #     dpi=300,\n",
    "        # )\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_divergences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_distances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_distances_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "for punto in grab_samples_df[\"Codice punto di prelievo\"].unique():\n",
    "    for col in columns:\n",
    "        grab_samples_df[\n",
    "            grab_samples_df[\"Codice punto di prelievo\"] == punto\n",
    "        ].plot(\n",
    "            x=\"Data di prelievo\",\n",
    "            y=col,\n",
    "            legend=False,\n",
    "            title=f\"{punto} - {col}\",\n",
    "            fontsize=8,\n",
    "            figsize=(40, 10),\n",
    "        )\n",
    "        directory = f\"/Users/massimilianoarca/Documents/PoliMi/Research Grant/SafeCREW/Data/Milano/Grab samples data plots/{punto}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        filename = sanitize_filename(f\"{col}.png\")\n",
    "        plt.savefig(os.path.join(directory, filename), dpi=300)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Distributions Divergence to Exploit More Data (All vs Selected One by One)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergences = {}\n",
    "js_divergences = {}\n",
    "tv_distances = {}\n",
    "w_distances = {}\n",
    "\n",
    "\n",
    "codes = grab_samples_df[\"Codice punto di prelievo\"].unique()\n",
    "\n",
    "for code in codes:\n",
    "    kl_divergences[code] = {}\n",
    "    js_divergences[code] = {}\n",
    "    tv_distances[code] = {}\n",
    "    w_distances[code] = {}\n",
    "\n",
    "    for feature in columns:\n",
    "        # # Compute the probability distribution of the feature in each DataFrame\n",
    "        # pdist_raw = np.histogram(raw_grab_samples_df[feature].dropna(), bins=100, density=True)[0]\n",
    "        # pdist_grab = np.histogram(grab_samples_df[feature].dropna(), bins=100, density=True)[0]\n",
    "\n",
    "        # # Add a small constant to avoid division by zero\n",
    "        # pdist_raw = pdist_raw + np.finfo(np.float64).eps\n",
    "        # pdist_grab = pdist_grab + np.finfo(np.float64).eps\n",
    "\n",
    "        if (\n",
    "            raw_grab_samples_df[feature].dropna().empty\n",
    "            or grab_samples_df[\n",
    "                grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "            ][feature]\n",
    "            .dropna()\n",
    "            .empty\n",
    "            or len(\n",
    "                grab_samples_df[\n",
    "                    grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "                ][feature]\n",
    "                .dropna()\n",
    "                .unique()\n",
    "            )\n",
    "            == 1\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        kde_raw = gaussian_kde(raw_grab_samples_df[feature].dropna())\n",
    "        kde_grab = gaussian_kde(\n",
    "            grab_samples_df[\n",
    "                grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "            ][feature].dropna()\n",
    "        )\n",
    "\n",
    "        # Evaluate the KDEs on a range of values\n",
    "        x = np.linspace(\n",
    "            min(\n",
    "                raw_grab_samples_df[feature].min(),\n",
    "                grab_samples_df[\n",
    "                    grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "                ][feature].min(),\n",
    "            ),\n",
    "            max(\n",
    "                raw_grab_samples_df[feature].max(),\n",
    "                grab_samples_df[\n",
    "                    grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "                ][feature].max(),\n",
    "            ),\n",
    "            100,\n",
    "        )\n",
    "        pdist_raw = kde_raw(x)\n",
    "        pdist_grab = kde_grab(x)\n",
    "\n",
    "        # Compute the KL divergence and store it in the dictionary\n",
    "        kl_divergences[code][feature] = stats.entropy(pdist_raw, pdist_grab)\n",
    "        js_divergences[code][feature] = jensenshannon(pdist_raw, pdist_grab)\n",
    "        tv_distances[code][feature] = np.sum(np.abs(pdist_raw - pdist_grab)) / 2\n",
    "        w_distances[code][feature] = wasserstein_distance(pdist_raw, pdist_grab)\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "kl_divergences_df = pd.DataFrame.from_dict(kl_divergences, orient=\"index\")\n",
    "js_divergences_df = pd.DataFrame.from_dict(js_divergences, orient=\"index\")\n",
    "tv_distances_df = pd.DataFrame.from_dict(tv_distances, orient=\"index\")\n",
    "w_distances_df = pd.DataFrame.from_dict(w_distances, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_divergences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_distances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_distances_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save wasserstein distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_distances_df.to_excel(\n",
    "    \"/Users/massimilianoarca/Documents/PoliMi/Research Grant/SafeCREW/Data/Milano/wasserstein_distances.xlsx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Range for each Casa dell'Acqua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = {}\n",
    "\n",
    "\n",
    "codes = grab_samples_df[\"Codice punto di prelievo\"].unique()\n",
    "\n",
    "for code in codes:\n",
    "    time_range[code] = {}\n",
    "\n",
    "    for feature in columns:\n",
    "        # # Compute the probability distribution of the feature in each DataFrame\n",
    "        # pdist_raw = np.histogram(raw_grab_samples_df[feature].dropna(), bins=100, density=True)[0]\n",
    "        # pdist_grab = np.histogram(grab_samples_df[feature].dropna(), bins=100, density=True)[0]\n",
    "\n",
    "        # # Add a small constant to avoid division by zero\n",
    "        # pdist_raw = pdist_raw + np.finfo(np.float64).eps\n",
    "        # pdist_grab = pdist_grab + np.finfo(np.float64).eps\n",
    "\n",
    "        temp_df = grab_samples_df[\n",
    "            grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "        ][[\"Data di prelievo\", feature]]\n",
    "        temp_df.dropna(inplace=True)\n",
    "\n",
    "        min_time = temp_df[\"Data di prelievo\"].min()\n",
    "        max_time = temp_df[\"Data di prelievo\"].max()\n",
    "        length = temp_df.shape[0]\n",
    "\n",
    "        time_range[code][feature] = {\n",
    "            \"start_time\": min_time,\n",
    "            \"end_time\": max_time,\n",
    "            \"n_samples\": length,\n",
    "        }\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "time_range_df = pd.DataFrame.from_dict(time_range, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensor Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for file in os.listdir(sensor_data_folder_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        temp_df = pd.read_csv(\n",
    "            os.path.join(sensor_data_folder_path, file), header=1, sep=\";\"\n",
    "        )\n",
    "        location_name = file.split(\"_\")[0]\n",
    "        temp_df.insert(0, \"Location\", location_name)\n",
    "        code = houses_code_df[\n",
    "            houses_code_df[\"Casa dell'acqua\"] == location_name\n",
    "        ][\"Codice Punto di Prelievo\"].values[0]\n",
    "        temp_df.insert(1, \"Codice Punto di Prelievo\", code)\n",
    "        df_list.append(temp_df)\n",
    "\n",
    "raw_sensor_data_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sensor_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Location',\n",
       " 'Codice Punto di Prelievo',\n",
       " 'Measurement interval=900[sec] (Export-Aggregation disabled)',\n",
       " 'Tag',\n",
       " 'COLORtrue - Measured value [Hazen-eq.] (Limit:0.00-300.00)',\n",
       " 'TOCeq - Measured value [mg/l] (Limit:0.00-22.00)',\n",
       " 'NO3eq - Measured value [mg/l] (Limit:0.00-88.00)',\n",
       " 'UV254t - Measured value [Abs/m] (Limit:0.00-71.00)',\n",
       " 'Turbidity - Measured value [FTUeq] (Limit:0.00-170.00)',\n",
       " 'DOCeq - Measured value [mg/l] (Limit:0.00-17.00)',\n",
       " 'pH - Measured value (Limit:0.00-14.00)',\n",
       " 'Temperature - Measured value [C] (Limit:-5.00-100.00)',\n",
       " 'ORP - Measured value [mV] (Limit:-2000.00-2000.00)',\n",
       " 'Conductivity - Measured value [uS/cm] (Limit:0.10-600000.00)',\n",
       " 'Free Chlorine - Measured value [mg/l] (Limit:0.00-2.00)',\n",
       " 'Flow - Measured value (Limit:0.00-1.00)',\n",
       " 'Free Chlorine - Clean value [mg/l] (Limit:0.00-2.00)']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get columns that do not contain the string 'Status'\n",
    "sensor_columns = raw_sensor_data_df.columns[\n",
    "    ~raw_sensor_data_df.columns.str.contains(\"Status\")\n",
    "]\n",
    "sensor_columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN vs Strings vs Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in raw_sensor_data_df[\"Codice Punto di Prelievo\"].unique():\n",
    "    histogram = raw_sensor_data_df[\n",
    "        raw_sensor_data_df[\"Codice Punto di Prelievo\"] == code\n",
    "    ][sensor_columns.to_list()[4:]].apply(count_values)\n",
    "    histogram.loc[\"Total\"] = histogram.sum()\n",
    "    ax = histogram.T[[\"NaN\", \"numbers\"]].plot.bar(figsize=(30, 10))\n",
    "    ax.set_title(code)\n",
    "\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(\n",
    "            str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.02)\n",
    "        )\n",
    "\n",
    "    directory = os.path.join(\n",
    "        dir_temporary_results_path, \"NaNvsNumbers_sensor_data\"\n",
    "    )\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    plt.savefig(\n",
    "        os.path.join(\n",
    "            directory,\n",
    "            sanitize_filename(code) + \".png\",\n",
    "        ),\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histrogram Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in raw_sensor_data_df[\"Codice Punto di Prelievo\"].unique():\n",
    "    for column in sensor_columns.to_list()[4:]:\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        hist = raw_sensor_data_df[\n",
    "            raw_sensor_data_df[\"Codice Punto di Prelievo\"] == code\n",
    "        ][column].where(\n",
    "            raw_sensor_data_df[\n",
    "                raw_sensor_data_df[\"Codice Punto di Prelievo\"] == code\n",
    "            ][column].apply(lambda x: isinstance(x, (int, float)))\n",
    "        )\n",
    "        count, bins, patches = plt.hist(\n",
    "            hist.dropna(), bins=30, edgecolor=\"black\", linewidth=1.2\n",
    "        )\n",
    "        plt.title(\n",
    "            code\n",
    "            + \" - \"\n",
    "            + column\n",
    "            + \" - Count: \"\n",
    "            + str(hist.count())\n",
    "            + \" / \"\n",
    "            + str(\n",
    "                raw_sensor_data_df[\n",
    "                    raw_sensor_data_df[\"Codice Punto di Prelievo\"] == code\n",
    "                ].shape[0]\n",
    "            )\n",
    "        )\n",
    "        plt.ylabel(\"Frequency\")\n",
    "\n",
    "        # Set x-ticks to bin edges and x-tick labels to intervals\n",
    "        plt.xticks(\n",
    "            bins[:-1],\n",
    "            [f\"{bins[i]:.2f}-{bins[i+1]:.2f}\" for i in range(len(bins) - 1)],\n",
    "            rotation=\"vertical\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "\n",
    "        # Add count for every bar\n",
    "        for p in patches:\n",
    "            plt.annotate(\n",
    "                str(int(p.get_height())),\n",
    "                (p.get_x() * 1.005, p.get_height() * 1.02),\n",
    "            )\n",
    "\n",
    "        directory = os.path.join(\n",
    "            dir_temporary_results_path, \"histograms_sensor_data\"\n",
    "        )\n",
    "        # if not os.path.exists(directory):\n",
    "        #     os.makedirs(directory)\n",
    "\n",
    "        # plt.savefig(\n",
    "        #     os.path.join(\n",
    "        #         directory,\n",
    "        #         sanitize_filename(code + ' - ' + column) + \".png\",\n",
    "        #     ),\n",
    "        #     dpi=300,\n",
    "        # )\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "# group by codice punto di prelievo and plot every column\n",
    "for punto in raw_sensor_data_df[\"Codice Punto di Prelievo\"].unique():\n",
    "    for col in raw_sensor_data_df.columns:\n",
    "        # check if column belongs to float type\n",
    "        if raw_sensor_data_df[col].dtype == float:\n",
    "            sanitized_col = col.split(\"-\")[0].rstrip()\n",
    "            # Extract unit of measure from column name\n",
    "            unit_of_measure = (\n",
    "                col.split(\"[\")[1].split(\"]\")[0] if \"[\" in col else \"\"\n",
    "            )\n",
    "            raw_sensor_data_df[\n",
    "                raw_sensor_data_df[\"Codice Punto di Prelievo\"] == punto\n",
    "            ].plot(\n",
    "                x=\"Measurement interval=900[sec] (Export-Aggregation disabled)\",\n",
    "                y=col,\n",
    "                legend=False,\n",
    "                title=f\"{punto} - {sanitized_col} [{unit_of_measure}]\",\n",
    "                fontsize=8,\n",
    "                figsize=(40, 10),\n",
    "            )\n",
    "            # directory = f\"/Users/massimilianoarca/Documents/PoliMi/Research Grant/SafeCREW/Data/Milano/Sensor data plots/{punto}\"\n",
    "            # if not os.path.exists(directory):\n",
    "            #     os.makedirs(directory)\n",
    "            # plt.savefig(f\"{directory}/{sanitized_col}.png\", dpi=300)\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_df = raw_sensor_data_df.copy()\n",
    "grab_df = raw_grab_samples_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_columns = grab_df.columns[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_df[\n",
    "    \"Measurement interval=900[sec] (Export-Aggregation disabled)\"\n",
    "] = pd.to_datetime(\n",
    "    sensor_df[\"Measurement interval=900[sec] (Export-Aggregation disabled)\"],\n",
    "    format=\"%d/%m/%Y %H:%M\",\n",
    ")\n",
    "grab_df[\"Data di prelievo\"] = pd.to_datetime(grab_df[\"Data di prelievo\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Common Columns between the two dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For the moment the common columns are taken manually\n",
    "\"\"\"\n",
    "\n",
    "column_mapping = {\n",
    "    \"Data di prelievo\": \"Measurement interval=900[sec] (Export-Aggregation disabled)\",\n",
    "    \"Colore (CU)\": \"COLORtrue - Measured value [Hazen-eq.] (Limit:0.00-300.00)\",\n",
    "    \"TOC - carbonio organico totale (mg/L di C)\": \"TOCeq - Measured value [mg/l] (Limit:0.00-22.00)\",\n",
    "    \"Conduttività a 20°C (µS/cm)\": \"Conductivity - Measured value [uS/cm] (Limit:0.10-600000.00)\",\n",
    "    \"Cloro residuo libero (mg/L di Cl2)\": \"Free Chlorine - Measured value [mg/l] (Limit:0.00-2.00)\",\n",
    "    \"Concentr. ioni idrogeno al prelievo (unità pH)\": \"pH - Measured value (Limit:0.00-14.00)\",\n",
    "    \"Temperatura - °C\": \"Temperature - Measured value [C] (Limit:-5.00-100.00)\",\n",
    "    \"Codice punto di prelievo\": \"Codice Punto di Prelievo\",\n",
    "}\n",
    "\n",
    "inverse_column_mapping = {v: k for k, v in column_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with grab_columns\n",
    "grabs = pd.DataFrame(data=grab_columns, columns=[\"grab_columns\"])\n",
    "\n",
    "# create dataframe with sensor_columns\n",
    "sensors = pd.DataFrame(data=sensor_columns, columns=[\"sensor_columns\"])\n",
    "\n",
    "grabs.to_excel(\n",
    "    \"/Users/massimilianoarca/Documents/PoliMi/Research Grant/SafeCREW/Data/Milano/grab_columns.xlsx\"\n",
    ")\n",
    "sensors.to_excel(\n",
    "    \"/Users/massimilianoarca/Documents/PoliMi/Research Grant/SafeCREW/Data/Milano/sensor_columns.xlsx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns = pd.DataFrame(\n",
    "    column_mapping.items(), columns=[\"Grab\", \"Sensor\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns.to_excel(\n",
    "    \"/Users/massimilianoarca/Documents/PoliMi/Research Grant/SafeCREW/Data/Milano/common_columns.xlsx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename sensor df columns with grab df columns\n",
    "\n",
    "sensor_df.rename(columns=inverse_column_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create unique df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_df[\"Source\"] = \"sensor\"\n",
    "grab_df[\"Source\"] = \"grab\"\n",
    "\n",
    "result_df = grab_df.merge(\n",
    "    sensor_df,\n",
    "    on=[\"Data di prelievo\"],\n",
    "    how=\"outer\",\n",
    ")\n",
    "\n",
    "for column in list(column_mapping.keys())[1:]:\n",
    "    result_df[column + \"_x\"] = result_df[column + \"_x\"].fillna(\n",
    "        result_df[column + \"_y\"]\n",
    "    )\n",
    "    result_df[column] = result_df[column + \"_x\"]\n",
    "    result_df.drop(columns=[column + \"_x\", column + \"_y\"], inplace=True)\n",
    "\n",
    "result_df[\"Source_x\"] = result_df[\"Source_x\"].fillna(result_df[\"Source_y\"])\n",
    "result_df[\"Source\"] = result_df[\"Source_x\"]\n",
    "result_df.drop(columns=[\"Source_x\", \"Source_y\"], inplace=True)\n",
    "\n",
    "# drop columns not in column_mapping and different from 'source'\n",
    "result_df.drop(\n",
    "    columns=[\n",
    "        column\n",
    "        for column in result_df.columns\n",
    "        if column not in list(column_mapping.keys()) + [\"Source\"]\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "plot_data_df = result_df.copy()\n",
    "plot_data_df.rename(columns={\"Data di prelievo\": \"Date\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"{plot_data_df[plot_data_df['Source'] == 'sensor']['Date'].min()} + ' - ' + {plot_data_df[plot_data_df['Source'] == 'sensor']['Date'].max()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"{plot_data_df[plot_data_df['Source'] == 'grab']['Date'].min()} + ' - ' + {plot_data_df[plot_data_df['Source'] == 'grab']['Date'].max()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with all NaN values\n",
    "plot_data_df.dropna(\n",
    "    subset=list(column_mapping.keys())[1:-1], how=\"all\", inplace=True\n",
    ")\n",
    "plot_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_df[\n",
    "    (plot_data_df[\"Source\"] == \"grab\")\n",
    "    & (plot_data_df[\"Codice punto di prelievo\"].isin(codes))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Plots for each selected Casa dell'Acqua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "codes = plot_data_df[plot_data_df[\"Source\"] == \"sensor\"][\n",
    "    \"Codice punto di prelievo\"\n",
    "].unique()\n",
    "\n",
    "for code in codes:\n",
    "    for column in list(column_mapping.keys())[1:-1]:\n",
    "        plt.figure(figsize=(40, 10))\n",
    "\n",
    "        # Filter the dataframe for rows where Source is 'sensor'\n",
    "\n",
    "        # Melt the dataframe to have 'Date', 'Codice punto di prelievo', 'Source' and 'value' columns\n",
    "        sensor_data_df = plot_data_df[\n",
    "            (plot_data_df[\"Codice punto di prelievo\"] == code)\n",
    "            & (plot_data_df[\"Source\"] == \"sensor\")\n",
    "        ]\n",
    "\n",
    "        # if we want to exploit more data\n",
    "        # grab_sample_df = plot_data_df[plot_data_df[\"Source\"] == \"grab\"]\n",
    "\n",
    "        grab_sample_df = plot_data_df[\n",
    "            (plot_data_df[\"Codice punto di prelievo\"] == code)\n",
    "            & (plot_data_df[\"Source\"] == \"grab\")\n",
    "        ]\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=sensor_data_df, x=\"Date\", y=column, color=\"red\", errorbar=None\n",
    "        )\n",
    "        sns.lineplot(\n",
    "            data=grab_sample_df, x=\"Date\", y=column, color=\"blue\", errorbar=None\n",
    "        )\n",
    "        # sns.scatterplot(data=grab_sample_df, x=\"Date\", y=column, color=\"blue\", marker=\"x\")\n",
    "\n",
    "        plt.title(code, fontsize=20)\n",
    "        plt.xlabel(\"Time\", fontsize=20)\n",
    "        plt.ylabel(column, fontsize=20)\n",
    "\n",
    "        custom_lines = [\n",
    "            Line2D([0], [0], color=\"red\", lw=4),\n",
    "            Line2D([0], [0], color=\"blue\", lw=4),\n",
    "        ]\n",
    "        plt.legend(custom_lines, [\"Sensor\", \"Grab\"])\n",
    "\n",
    "        directory = f\"/Users/massimilianoarca/Documents/PoliMi/Research Grant/SafeCREW/Data/Milano/Comparison Plots/{code}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        filename = sanitize_filename(f\"{column}.png\")\n",
    "        plt.savefig(os.path.join(directory, filename), dpi=300)\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a table for each index summarizing the time_range_df by showing the number of samples, the start time and the end time for each feature in each house\n",
    "for code in raw_sensor_data_df[\"Codice Punto di Prelievo\"].unique():\n",
    "    with pd.ExcelWriter(\n",
    "        f\"/Users/massimilianoarca/Documents/PoliMi/Research Grant/SafeCREW/Data/Milano/Metadata/{code}.xlsx\"\n",
    "    ) as writer:\n",
    "        df = pd.DataFrame()\n",
    "        for column in list(column_mapping.keys())[1:-1]:\n",
    "            row = time_range_df.loc[code, column]\n",
    "            if isinstance(row, dict):\n",
    "                temp_df = pd.DataFrame(\n",
    "                    index=list(row.keys()),\n",
    "                    data=list(row.values()),\n",
    "                    columns=[column],\n",
    "                )\n",
    "                df = pd.concat([df, temp_df], axis=1)\n",
    "                # df.to_excel(writer, sheet_name=sanitize_filename(column))\n",
    "            else:\n",
    "                continue\n",
    "        min_time = pd.to_datetime(\n",
    "            raw_sensor_data_df[\n",
    "                raw_sensor_data_df[\"Codice Punto di Prelievo\"] == code\n",
    "            ][\"Measurement interval=900[sec] (Export-Aggregation disabled)\"],\n",
    "            format=\"mixed\",\n",
    "            dayfirst=True,\n",
    "        ).min()\n",
    "        max_time = pd.to_datetime(\n",
    "            raw_sensor_data_df[\n",
    "                raw_sensor_data_df[\"Codice Punto di Prelievo\"] == code\n",
    "            ][\"Measurement interval=900[sec] (Export-Aggregation disabled)\"],\n",
    "            format=\"mixed\",\n",
    "            dayfirst=True,\n",
    "        ).max()\n",
    "        sens_df = pd.DataFrame(\n",
    "            index=[\"start_time\", \"end_time\"],\n",
    "            data=[min_time, max_time],\n",
    "            columns=[\"sensor\"],\n",
    "        )\n",
    "        df = pd.concat([df, sens_df], axis=1)\n",
    "        df.to_excel(writer, sheet_name=code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common time interval between sensor and grab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = plot_data_df[plot_data_df[\"Source\"] == \"sensor\"][\n",
    "    \"Codice punto di prelievo\"\n",
    "].unique()\n",
    "\n",
    "for code in codes:\n",
    "    # Filter the dataframe for rows where Source is 'sensor'\n",
    "\n",
    "    # Melt the dataframe to have 'Date', 'Codice punto di prelievo', 'Source' and 'value' columns\n",
    "    sensor_data_df = plot_data_df[\n",
    "        (plot_data_df[\"Codice punto di prelievo\"] == code)\n",
    "        & (plot_data_df[\"Source\"] == \"sensor\")\n",
    "    ]\n",
    "    grab_sample_df = plot_data_df[\n",
    "        (plot_data_df[\"Codice punto di prelievo\"] == code)\n",
    "        & (plot_data_df[\"Source\"] == \"grab\")\n",
    "    ]\n",
    "    # if we want to exploit more data\n",
    "    # grab_sample_df = plot_data_df[plot_data_df[\"Source\"] == \"grab\"]\n",
    "\n",
    "    print(f\"==== {code} ====\")\n",
    "    print(\n",
    "        \"Sensor: \"\n",
    "        + str(sensor_data_df[\"Date\"].min())\n",
    "        + \" - \"\n",
    "        + str(sensor_data_df[\"Date\"].max())\n",
    "    )\n",
    "    print(\n",
    "        \"Grab: \"\n",
    "        + str(grab_sample_df[\"Date\"].min())\n",
    "        + \" - \"\n",
    "        + str(grab_sample_df[\"Date\"].max())\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    if code == \"HOUSE_CERMENATE\":\n",
    "        pass\n",
    "\n",
    "    # get samples that are in the common time range\n",
    "    grab_common_time_range_df = grab_sample_df[\n",
    "        (grab_sample_df[\"Date\"] >= sensor_data_df[\"Date\"].min())\n",
    "        & (grab_sample_df[\"Date\"] <= sensor_data_df[\"Date\"].max())\n",
    "    ]\n",
    "\n",
    "    grab_common_time_range_df.dropna(inplace=True)\n",
    "\n",
    "    sensor_common_time_range_df = sensor_data_df[\n",
    "        (sensor_data_df[\"Date\"] >= grab_sample_df[\"Date\"].min())\n",
    "        & (sensor_data_df[\"Date\"] <= grab_sample_df[\"Date\"].max())\n",
    "    ]\n",
    "\n",
    "    common_time_range_df = pd.concat(\n",
    "        [grab_common_time_range_df, sensor_common_time_range_df],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    sensor_time_range_df = common_time_range_df[\n",
    "        common_time_range_df[\"Source\"] == \"sensor\"\n",
    "    ]\n",
    "\n",
    "    grab_time_range_df = common_time_range_df[\n",
    "        common_time_range_df[\"Source\"] == \"grab\"\n",
    "    ]\n",
    "\n",
    "    # plot the samples in the common time range for each feature with different colors\n",
    "    for column in list(column_mapping.keys())[1:-1]:\n",
    "        plt.figure(figsize=(40, 10))\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=sensor_time_range_df,\n",
    "            x=\"Date\",\n",
    "            y=column,\n",
    "            color=\"red\",\n",
    "            errorbar=None,\n",
    "        )\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=grab_time_range_df,\n",
    "            x=\"Date\",\n",
    "            y=column,\n",
    "            color=\"blue\",\n",
    "            errorbar=None,\n",
    "        )\n",
    "\n",
    "        sns.scatterplot(\n",
    "            data=grab_time_range_df,\n",
    "            x=\"Date\",\n",
    "            y=column,\n",
    "            color=\"blue\",\n",
    "        )\n",
    "\n",
    "        plt.title(code, fontsize=20)\n",
    "        plt.xlabel(\"Time\", fontsize=20)\n",
    "        plt.ylabel(column, fontsize=20)\n",
    "\n",
    "        custom_lines = [\n",
    "            Line2D([0], [0], color=\"red\", lw=4),\n",
    "            Line2D([0], [0], color=\"blue\", lw=4),\n",
    "        ]\n",
    "        plt.legend(custom_lines, [\"Sensor\", \"Grab\"])\n",
    "\n",
    "        # directory = f\"/Users/massimilianoarca/Documents/PoliMi/Research Grant/SafeCREW/Data/Milano/Common Time Range/{code}\"\n",
    "        # if not os.path.exists(directory):\n",
    "        #     os.makedirs(directory)\n",
    "        # filename = sanitize_filename(f\"{column}.png\")\n",
    "        # plt.savefig(os.path.join(directory, filename), dpi=300)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safecrew-3OLHM_8n-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
