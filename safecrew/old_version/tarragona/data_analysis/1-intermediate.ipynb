{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Sensor and Lab samples Intermediate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "from utils.functions.normalize_string import normalize_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(\"..\", \"data\")\n",
    "utils_folder = os.path.join(\"..\", \"utils\")\n",
    "\n",
    "interm_data_folder = os.path.join(data_folder, \"Intermediate Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import feature mappings\n",
    "with open(\n",
    "    os.path.join(utils_folder, \"mappings\", \"eb0_features_mapping.json\")\n",
    ") as f:\n",
    "    eb0_features_mapping = json.load(f)\n",
    "\n",
    "with open(\n",
    "    os.path.join(utils_folder, \"mappings\", \"eb1_features_mapping.json\")\n",
    ") as f:\n",
    "    eb1_features_mapping = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_lab_df = pd.read_excel(\n",
    "    os.path.join(interm_data_folder, \"EB0_Features_Lab.xlsx\")\n",
    ")\n",
    "\n",
    "eb0_targets_lab_df = pd.read_excel(\n",
    "    os.path.join(interm_data_folder, \"EB0_Targets_Lab.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df = pd.read_excel(\n",
    "    os.path.join(interm_data_folder, \"EB1_Features_Lab.xlsx\")\n",
    ")\n",
    "\n",
    "eb1_targets_lab_df = pd.read_excel(\n",
    "    os.path.join(interm_data_folder, \"EB1_Targets_Lab.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_sensor_df = pd.read_excel(\n",
    "    os.path.join(interm_data_folder, \"EB0_Sensor.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_sensor_df = pd.read_excel(\n",
    "    os.path.join(interm_data_folder, \"EB1_Sensor.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thms_df = pd.read_excel(os.path.join(interm_data_folder, \"THMs.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab vs Sensor Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EB0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_lab_df.columns = [\n",
    "    normalize_string(c) for c in eb0_features_lab_df.columns\n",
    "]\n",
    "\n",
    "eb0_features_mapping = {\n",
    "    normalize_string(k): v for k, v in eb0_features_mapping.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab_key, sensor_key in eb0_features_mapping.items():\n",
    "    lab_key = normalize_string(lab_key)\n",
    "    lab_df = eb0_features_lab_df[lab_key]\n",
    "    sensor_df = eb0_sensor_df[sensor_key]\n",
    "\n",
    "    # remove 0 values from sensor data\n",
    "    # sensor_df = sensor_df[sensor_df != 0]\n",
    "\n",
    "    if not lab_df.empty and not sensor_df.empty:\n",
    "        plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "        sns.histplot(\n",
    "            data=sensor_df,\n",
    "            kde=True,\n",
    "            bins=100,\n",
    "            alpha=0.5,\n",
    "            stat=\"probability\",\n",
    "            label=\"Sensor Data\",\n",
    "        )\n",
    "\n",
    "        sns.histplot(\n",
    "            data=lab_df,\n",
    "            kde=True,\n",
    "            bins=100,\n",
    "            stat=\"probability\",\n",
    "            label=\"Lab Data\",\n",
    "        )\n",
    "\n",
    "        plt.title(lab_key)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # The y-axis of a histplot with stat=\"probability\" corresponds\n",
    "        # to the probability that a value belongs to a certain bar.\n",
    "        # The sum of the bar heights must be 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axs = plt.subplots(1, len(eb0_features_mapping), figsize=(20, 10))\n",
    "\n",
    "for lab_key, sensor_key in eb0_features_mapping.items():\n",
    "    lab_key = normalize_string(lab_key)\n",
    "    lab_df = eb0_features_lab_df[lab_key]\n",
    "    sensor_df = eb0_sensor_df[sensor_key]\n",
    "\n",
    "    # remove 0 values from sensor data\n",
    "    sensor_df = sensor_df[sensor_df != 0]\n",
    "\n",
    "    title = lab_key\n",
    "\n",
    "    if lab_key == \"Conductivitat a 20oC\":\n",
    "        title = \"Conductivity at 20Â°C\"\n",
    "\n",
    "    elif lab_key == \"Temperatura\":\n",
    "        title = \"Water Temperature\"\n",
    "\n",
    "    elif lab_key == \"Terbolesa\":\n",
    "        title = \"Turbidity\"\n",
    "        lab_df = lab_df[lab_df < 100]\n",
    "\n",
    "    if not lab_df.empty and not sensor_df.empty:\n",
    "        lab_df.name = \"Lab\"\n",
    "        sensor_df.name = \"Sensor\"\n",
    "\n",
    "        sns.boxplot(\n",
    "            data=[lab_df, sensor_df],\n",
    "            palette=\"Set3\",\n",
    "            ax=axs[list(eb0_features_mapping.keys()).index(lab_key)],\n",
    "        )\n",
    "\n",
    "        axs[list(eb0_features_mapping.keys()).index(lab_key)].set_title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab_key, sensor_key in eb0_features_mapping.items():\n",
    "    lab_key = normalize_string(lab_key)\n",
    "    lab_df = eb0_features_lab_df[[\"DateTime\", lab_key]]\n",
    "    sensor_df = eb0_sensor_df[[\"DateTime\", sensor_key]]\n",
    "\n",
    "    # remove 0 values from sensor data\n",
    "    sensor_df = sensor_df[sensor_df != 0]\n",
    "\n",
    "    # print date range for both lab and sensor data\n",
    "    print(\n",
    "        f\"Lab {lab_key} Date Range: {lab_df['DateTime'].min()} - {lab_df['DateTime'].max()}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Sensor {sensor_key} Date Range: {sensor_df['DateTime'].min()} - {sensor_df['DateTime'].max()}\"\n",
    "    )\n",
    "    print()\n",
    "    # print count of values for both lab and sensor data\n",
    "    print(f\"Lab {lab_key} Count: {lab_df[lab_key].count()}\")\n",
    "    print(f\"Sensor {sensor_key} Count: {sensor_df[sensor_key].count()}\")\n",
    "    print()\n",
    "\n",
    "    # print % missing values for both lab and sensor data\n",
    "    print(\n",
    "        f\"Lab {lab_key} % Missing: {lab_df[lab_key].isna().sum() / lab_df[lab_key].shape[0] * 100:.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Sensor {sensor_key} % Missing: {sensor_df[sensor_key].isna().sum() / sensor_df[sensor_key].shape[0] * 100:.2f}%\"\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    if not lab_df.empty and not sensor_df.empty:\n",
    "        plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "        sns.lineplot(\n",
    "            x=\"DateTime\",\n",
    "            y=lab_key,\n",
    "            data=lab_df,\n",
    "            color=\"blue\",\n",
    "            label=\"Lab Data\",\n",
    "        )\n",
    "\n",
    "        sns.lineplot(\n",
    "            x=\"DateTime\",\n",
    "            y=sensor_key,\n",
    "            data=sensor_df,\n",
    "            color=\"red\",\n",
    "            label=\"Sensor Data\",\n",
    "        )\n",
    "\n",
    "        plt.title(lab_key)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve Common Time Range data + Hypothesis Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.metrics import dtw\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "\n",
    "ks_hypothesis_tests = {}\n",
    "t_hypothesis_tests = {}\n",
    "u_hypothesis_tests = {}\n",
    "dwt_distances = {}\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# get common time range samples for lab and sensor data\n",
    "for lab_key, sensor_key in eb0_features_mapping.items():\n",
    "    lab_key = normalize_string(lab_key)\n",
    "    lab_df = eb0_features_lab_df[[\"DateTime\", lab_key]]\n",
    "    sensor_df = eb0_sensor_df[[\"DateTime\", sensor_key]]\n",
    "\n",
    "    # remove 0 values from sensor data\n",
    "    sensor_df = sensor_df[sensor_df != 0]\n",
    "\n",
    "    if not lab_df.empty and not sensor_df.empty:\n",
    "        lab_time_range_df = lab_df[\n",
    "            (lab_df[\"DateTime\"] >= sensor_df[\"DateTime\"].min())\n",
    "            & (lab_df[\"DateTime\"] <= sensor_df[\"DateTime\"].max())\n",
    "        ]\n",
    "\n",
    "        sensor_time_range_df = sensor_df[\n",
    "            (sensor_df[\"DateTime\"] >= lab_df[\"DateTime\"].min())\n",
    "            & (sensor_df[\"DateTime\"] <= lab_df[\"DateTime\"].max())\n",
    "        ]\n",
    "\n",
    "        # plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "        # sns.lineplot(\n",
    "        #     x=\"DateTime\",\n",
    "        #     y=lab_key,\n",
    "        #     data=lab_time_range_df,\n",
    "        #     color=\"blue\",\n",
    "        #     label=\"Lab Data\",\n",
    "        # )\n",
    "\n",
    "        # sns.lineplot(\n",
    "        #     x=\"DateTime\",\n",
    "        #     y=sensor_key,\n",
    "        #     data=sensor_time_range_df,\n",
    "        #     color=\"red\",\n",
    "        #     label=\"Sensor Data\",\n",
    "        # )\n",
    "\n",
    "        # two sample KS test\n",
    "        ks_result, ks_p_value = stats.ks_2samp(\n",
    "            lab_df[lab_key], sensor_df[sensor_key]\n",
    "        )\n",
    "        t_result, t_p_value = stats.ttest_ind(\n",
    "            lab_df[lab_key].dropna(), sensor_df[sensor_key].dropna()\n",
    "        )\n",
    "        u_result, u_p_value = stats.mannwhitneyu(\n",
    "            lab_df[lab_key].dropna(), sensor_df[sensor_key].dropna()\n",
    "        )\n",
    "\n",
    "        ks_hypothesis_tests[lab_key] = {\n",
    "            \"ks_test\": ks_result,\n",
    "            \"p_value\": ks_p_value,\n",
    "        }\n",
    "\n",
    "        t_hypothesis_tests[lab_key] = {\"t_test\": t_result, \"p_value\": t_p_value}\n",
    "\n",
    "        u_hypothesis_tests[lab_key] = {\"u_test\": u_result, \"p_value\": u_p_value}\n",
    "\n",
    "        scaled_lab = pd.DataFrame(\n",
    "            scaler.fit_transform(lab_df[lab_key].dropna().values.reshape(-1, 1))\n",
    "        )\n",
    "        scaled_sensor = pd.DataFrame(\n",
    "            scaler.fit_transform(\n",
    "                sensor_df[sensor_key].dropna().values.reshape(-1, 1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # print date range for both lab and sensor data\n",
    "        print(\n",
    "            f\"Lab {lab_key} Date Range: {lab_time_range_df['DateTime'].min()} - {lab_time_range_df['DateTime'].max()}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Sensor {sensor_key} Date Range: {sensor_time_range_df['DateTime'].min()} - {sensor_time_range_df['DateTime'].max()}\"\n",
    "        )\n",
    "        print()\n",
    "        # print count of values for both lab and sensor data\n",
    "        print(f\"Lab {lab_key} Count: {lab_time_range_df[lab_key].count()}\")\n",
    "        print(\n",
    "            f\"Sensor {sensor_key} Count: {sensor_time_range_df[sensor_key].count()}\"\n",
    "        )\n",
    "        print()\n",
    "\n",
    "        # print % missing values for both lab and sensor data\n",
    "        print(\n",
    "            f\"Lab {lab_key} % Missing: {lab_time_range_df[lab_key].isna().sum() / lab_time_range_df[lab_key].shape[0] * 100:.2f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Sensor {sensor_key} % Missing: {sensor_time_range_df[sensor_key].isna().sum() / sensor_time_range_df[sensor_key].shape[0] * 100:.2f}%\"\n",
    "        )\n",
    "        print()\n",
    "\n",
    "        dwt_distance = dtw(\n",
    "            scaled_lab,\n",
    "            scaled_sensor,\n",
    "        )\n",
    "\n",
    "        dwt_distances[lab_key] = dwt_distance\n",
    "\n",
    "        # plt.title(lab_key)\n",
    "        # plt.grid(True)\n",
    "        # plt.legend()\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dwt_distances, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ks_hypothesis_tests).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(t_hypothesis_tests).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(u_hypothesis_tests).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributions Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divs = {}\n",
    "js_divs = {}\n",
    "tv_dists = {}\n",
    "w_dists = {}\n",
    "\n",
    "for lab_key, sensor_key in eb0_features_mapping.items():\n",
    "    # Compute the probability distribution of the feature in each DataFrame\n",
    "    lab_df = eb0_features_lab_df[lab_key]\n",
    "    sensor_df = eb0_sensor_df[sensor_key]\n",
    "\n",
    "    lab_pdist = np.histogram(lab_df.dropna(), bins=100, density=True)[0]\n",
    "    sensor_pdist = np.histogram(sensor_df.dropna(), bins=100, density=True)[0]\n",
    "\n",
    "    # Add a small constant to avoid division by zero\n",
    "    lab_pdist = lab_pdist + np.finfo(np.float64).eps\n",
    "    sensor_pdist = sensor_pdist + np.finfo(np.float64).eps\n",
    "\n",
    "    # Compute divergence metrics\n",
    "    kl_div = stats.entropy(lab_pdist, sensor_pdist)\n",
    "    js_div = jensenshannon(lab_pdist, sensor_pdist)\n",
    "    tv_dist = np.sum(np.abs(lab_pdist - sensor_pdist)) / 2\n",
    "    w_dist = wasserstein_distance(lab_pdist, sensor_pdist)\n",
    "\n",
    "    kl_divs[lab_key] = kl_div\n",
    "    js_divs[lab_key] = js_div\n",
    "    tv_dists[lab_key] = tv_dist\n",
    "    w_dists[lab_key] = w_dist\n",
    "\n",
    "\n",
    "kl_divs = pd.Series(kl_divs)\n",
    "js_divs = pd.Series(js_divs)\n",
    "tv_dists = pd.Series(tv_dists)\n",
    "w_dists = pd.Series(w_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EB1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df.columns = [\n",
    "    normalize_string(c) for c in eb1_features_lab_df.columns\n",
    "]\n",
    "\n",
    "eb1_features_mapping = {\n",
    "    normalize_string(k): v for k, v in eb1_features_mapping.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab_key, sensor_key in eb1_features_mapping.items():\n",
    "    lab_key = normalize_string(lab_key)\n",
    "    lab_df = eb1_features_lab_df[lab_key]\n",
    "    sensor_df = eb1_sensor_df[sensor_key]\n",
    "\n",
    "    # remove 0 values from sensor data\n",
    "    sensor_df = sensor_df[sensor_df != 0]\n",
    "\n",
    "    if not lab_df.empty and not sensor_df.empty:\n",
    "        plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "        # counts, bins, patches = plt.hist(\n",
    "        #     lab_df,\n",
    "        #     bins=100,\n",
    "        #     color=\"blue\",\n",
    "        #     alpha=0.5,\n",
    "        #     label=\"Lab\",\n",
    "        #     density=True,\n",
    "        # )\n",
    "        # # # Add counts as annotations\n",
    "        # # for count, bin in zip(counts, bins):\n",
    "        # #     plt.text(bin, count, str(int(count)))\n",
    "\n",
    "        # plt.hist(\n",
    "        #     sensor_df,\n",
    "        #     bins=100,\n",
    "        #     color=\"red\",\n",
    "        #     alpha=0.5,\n",
    "        #     label=\"Sensor\",\n",
    "        #     density=True,\n",
    "        # )\n",
    "\n",
    "        sns.histplot(\n",
    "            data=sensor_df,\n",
    "            kde=True,\n",
    "            bins=100,\n",
    "            alpha=0.5,\n",
    "            stat=\"probability\",\n",
    "            label=\"Sensor Data\",\n",
    "        )\n",
    "\n",
    "        sns.histplot(\n",
    "            data=lab_df,\n",
    "            kde=True,\n",
    "            bins=100,\n",
    "            stat=\"probability\",\n",
    "            label=\"Lab Data\",\n",
    "        )\n",
    "\n",
    "        plt.title(lab_key)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # The y-axis of a histplot with stat=\"probability\" corresponds\n",
    "        # to the probability that a value belongs to a certain bar.\n",
    "        # The sum of the bar heights must be 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_mapping.pop(\"Quantitat meÌs abundant de partiÌcules\")\n",
    "eb1_features_mapping.pop(\"IÌndex UV\")\n",
    "eb1_features_mapping.pop(\"Clor lliure residual\")\n",
    "eb1_features_mapping.pop(\"Carboni OrgaÌnic Total Tractament\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axs = plt.subplots(1, len(eb1_features_mapping), figsize=(20, 10))\n",
    "\n",
    "for lab_key, sensor_key in eb1_features_mapping.items():\n",
    "    lab_key = normalize_string(lab_key)\n",
    "    lab_df = eb1_features_lab_df[lab_key]\n",
    "    sensor_df = eb1_sensor_df[sensor_key]\n",
    "\n",
    "    # remove 0 values from sensor data\n",
    "    sensor_df = sensor_df[sensor_df != 0]\n",
    "\n",
    "    title = lab_key\n",
    "\n",
    "    if lab_key == \"Conductivitat a 20oC\":\n",
    "        title = \"Conductivity at 20Â°C\"\n",
    "\n",
    "        sensor_df = sensor_df[sensor_df < 15000]\n",
    "\n",
    "    elif lab_key == \"Temperatura\":\n",
    "        title = \"Water Temperature\"\n",
    "\n",
    "    elif lab_key == \"Terbolesa\":\n",
    "        title = \"Turbidity\"\n",
    "        sensor_df = sensor_df[sensor_df < 0.75]\n",
    "\n",
    "    elif lab_key == \"Color\":\n",
    "        sensor_df = sensor_df[sensor_df < 20]\n",
    "\n",
    "    if not lab_df.empty and not sensor_df.empty:\n",
    "        lab_df.name = \"Lab\"\n",
    "        sensor_df.name = \"Sensor\"\n",
    "\n",
    "        sns.boxplot(\n",
    "            data=[lab_df, sensor_df],\n",
    "            palette=\"Set3\",\n",
    "            ax=axs[list(eb1_features_mapping.keys()).index(lab_key)],\n",
    "        )\n",
    "\n",
    "        axs[list(eb0_features_mapping.keys()).index(lab_key)].set_title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab_key, sensor_key in eb1_features_mapping.items():\n",
    "    lab_key = normalize_string(lab_key)\n",
    "    lab_df = eb1_features_lab_df[[\"DateTime\", lab_key]]\n",
    "    sensor_df = eb1_sensor_df[[\"DateTime\", sensor_key]]\n",
    "\n",
    "    # remove 0 values from sensor data\n",
    "    sensor_df = sensor_df[sensor_df != 0]\n",
    "\n",
    "    # print date range for both lab and sensor data\n",
    "    print(\n",
    "        f\"Lab {lab_key} Date Range: {lab_df['DateTime'].min()} - {lab_df['DateTime'].max()}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Sensor {sensor_key} Date Range: {sensor_df['DateTime'].min()} - {sensor_df['DateTime'].max()}\"\n",
    "    )\n",
    "    print()\n",
    "    # print count of values for both lab and sensor data\n",
    "    print(f\"Lab {lab_key} Count: {lab_df[lab_key].count()}\")\n",
    "    print(f\"Sensor {sensor_key} Count: {sensor_df[sensor_key].count()}\")\n",
    "    print()\n",
    "\n",
    "    # print % missing values for both lab and sensor data\n",
    "    print(\n",
    "        f\"Lab {lab_key} % Missing: {lab_df[lab_key].isna().sum() / lab_df[lab_key].shape[0] * 100:.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Sensor {sensor_key} % Missing: {sensor_df[sensor_key].isna().sum() / sensor_df[sensor_key].shape[0] * 100:.2f}%\"\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    if not lab_df.empty and not sensor_df.empty:\n",
    "        plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "        sns.lineplot(\n",
    "            x=\"DateTime\",\n",
    "            y=lab_key,\n",
    "            data=lab_df,\n",
    "            color=\"blue\",\n",
    "            label=\"Lab Data\",\n",
    "        )\n",
    "\n",
    "        sns.lineplot(\n",
    "            x=\"DateTime\",\n",
    "            y=sensor_key,\n",
    "            data=sensor_df,\n",
    "            color=\"red\",\n",
    "            label=\"Sensor Data\",\n",
    "        )\n",
    "\n",
    "        plt.title(lab_key)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve Common Time Range data + Hypothesis Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_hypothesis_tests = {}\n",
    "t_hypothesis_tests = {}\n",
    "u_hypothesis_tests = {}\n",
    "\n",
    "# get common time range samples for lab and sensor data\n",
    "for lab_key, sensor_key in eb1_features_mapping.items():\n",
    "    lab_key = normalize_string(lab_key)\n",
    "    lab_df = eb1_features_lab_df[[\"DateTime\", lab_key]]\n",
    "    sensor_df = eb1_sensor_df[[\"DateTime\", sensor_key]]\n",
    "\n",
    "    # remove 0 values from sensor data\n",
    "    if lab_key == \"Color\":\n",
    "        sensor_df[sensor_key] = sensor_df[sensor_key][\n",
    "            sensor_df[sensor_key] < 20\n",
    "        ]\n",
    "\n",
    "    if not lab_df.empty and not sensor_df.empty:\n",
    "        lab_time_range_df = lab_df[\n",
    "            (lab_df[\"DateTime\"] >= sensor_df[\"DateTime\"].min())\n",
    "            & (lab_df[\"DateTime\"] <= sensor_df[\"DateTime\"].max())\n",
    "        ]\n",
    "\n",
    "        sensor_time_range_df = sensor_df[\n",
    "            (sensor_df[\"DateTime\"] >= lab_df[\"DateTime\"].min())\n",
    "            & (sensor_df[\"DateTime\"] <= lab_df[\"DateTime\"].max())\n",
    "        ]\n",
    "\n",
    "        plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "        sns.lineplot(\n",
    "            x=\"DateTime\",\n",
    "            y=lab_key,\n",
    "            data=lab_time_range_df,\n",
    "            color=\"blue\",\n",
    "            label=\"Lab Data\",\n",
    "        )\n",
    "\n",
    "        sns.lineplot(\n",
    "            x=\"DateTime\",\n",
    "            y=sensor_key,\n",
    "            data=sensor_time_range_df,\n",
    "            color=\"red\",\n",
    "            label=\"Sensor Data\",\n",
    "        )\n",
    "\n",
    "        # # two sample KS test\n",
    "        # ks_result, ks_p_value = stats.ks_2samp(\n",
    "        #     lab_df[lab_key].dropna(), sensor_df[sensor_key].dropna()\n",
    "        # )\n",
    "        # t_result, t_p_value = stats.ttest_ind(\n",
    "        #     lab_df[lab_key].dropna(), sensor_df[sensor_key].dropna()\n",
    "        # )\n",
    "        # u_result, u_p_value = stats.mannwhitneyu(\n",
    "        #     lab_df[lab_key].dropna(), sensor_df[sensor_key].dropna()\n",
    "        # )\n",
    "\n",
    "        # ks_hypothesis_tests[lab_key] = {\n",
    "        #     \"ks_test\": ks_result,\n",
    "        #     \"p_value\": ks_p_value,\n",
    "        # }\n",
    "\n",
    "        # t_hypothesis_tests[lab_key] = {\"t_test\": t_result, \"p_value\": t_p_value}\n",
    "\n",
    "        # u_hypothesis_tests[lab_key] = {\"u_test\": u_result, \"p_value\": u_p_value}\n",
    "\n",
    "        # # print date range for both lab and sensor data\n",
    "        # print(f\"Lab {lab_key} Date Range: {lab_time_range_df['DateTime'].min()} - {lab_time_range_df['DateTime'].max()}\")\n",
    "        # print(f\"Sensor {sensor_key} Date Range: {sensor_time_range_df['DateTime'].min()} - {sensor_time_range_df['DateTime'].max()}\")\n",
    "        # print()\n",
    "        # # print count of values for both lab and sensor data\n",
    "        # print(f\"Lab {lab_key} Count: {lab_time_range_df[lab_key].count()}\")\n",
    "        # print(f\"Sensor {sensor_key} Count: {sensor_time_range_df[sensor_key].count()}\")\n",
    "        # print()\n",
    "\n",
    "        # # print % missing values for both lab and sensor data\n",
    "        # print(f\"Lab {lab_key} % Missing: {lab_time_range_df[lab_key].isna().sum() / lab_time_range_df[lab_key].shape[0] * 100:.2f}%\")\n",
    "        # print(f\"Sensor {sensor_key} % Missing: {sensor_time_range_df[sensor_key].isna().sum() / sensor_time_range_df[sensor_key].shape[0] * 100:.2f}%\")\n",
    "        # print()\n",
    "\n",
    "        plt.title(lab_key)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ks_hypothesis_tests).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(t_hypothesis_tests).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(u_hypothesis_tests).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributions Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divs = {}\n",
    "js_divs = {}\n",
    "tv_dists = {}\n",
    "w_dists = {}\n",
    "\n",
    "for lab_key, sensor_key in eb1_features_mapping.items():\n",
    "    # Compute the probability distribution of the feature in each DataFrame\n",
    "    lab_df = eb1_features_lab_df[lab_key]\n",
    "    sensor_df = eb1_sensor_df[sensor_key]\n",
    "\n",
    "    lab_pdist = np.histogram(lab_df.dropna(), bins=100, density=True)[0]\n",
    "    sensor_pdist = np.histogram(sensor_df.dropna(), bins=100, density=True)[0]\n",
    "\n",
    "    # Add a small constant to avoid division by zero\n",
    "    lab_pdist = lab_pdist + np.finfo(np.float64).eps\n",
    "    sensor_pdist = sensor_pdist + np.finfo(np.float64).eps\n",
    "\n",
    "    # Compute divergence metrics\n",
    "    kl_div = stats.entropy(lab_pdist, sensor_pdist)\n",
    "    js_div = jensenshannon(lab_pdist, sensor_pdist)\n",
    "    tv_dist = np.sum(np.abs(lab_pdist - sensor_pdist)) / 2\n",
    "    w_dist = wasserstein_distance(lab_pdist, sensor_pdist)\n",
    "\n",
    "    kl_divs[lab_key] = kl_div\n",
    "    js_divs[lab_key] = js_div\n",
    "    tv_dists[lab_key] = tv_dist\n",
    "    w_dists[lab_key] = w_dist\n",
    "\n",
    "\n",
    "kl_divs = pd.Series(kl_divs)\n",
    "js_divs = pd.Series(js_divs)\n",
    "tv_dists = pd.Series(tv_dists)\n",
    "w_dists = pd.Series(w_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show info about the targets\n",
    "\n",
    "for column in eb1_targets_lab_df.columns.difference([\"DateTime\"]):\n",
    "    print(f\"Column: {column}\")\n",
    "    print()\n",
    "\n",
    "    # common time range with eb1 features\n",
    "    common_time_range_df = eb1_targets_lab_df[\n",
    "        (\n",
    "            eb1_targets_lab_df[\"DateTime\"]\n",
    "            >= eb1_features_lab_df[\"DateTime\"].min()\n",
    "        )\n",
    "        & (\n",
    "            eb1_targets_lab_df[\"DateTime\"]\n",
    "            <= eb1_features_lab_df[\"DateTime\"].max()\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    print(\n",
    "        f\"Date Range: {common_time_range_df['DateTime'].min()} - {common_time_range_df['DateTime'].max()}\"\n",
    "    )\n",
    "\n",
    "    print(f\"Count: {common_time_range_df[column].count()}\")\n",
    "    print(\n",
    "        f\"% Missing: {common_time_range_df[column].isna().sum() / common_time_range_df[column].shape[0] * 100:.2f}%\"\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Data Feature-Target Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trihalometh_columns = [\n",
    "    \"Cloroform\",\n",
    "    \"BromodiclorometÃ \",\n",
    "    \"DibromoclorometÃ \",\n",
    "    \"Bromoform\",\n",
    "]\n",
    "\n",
    "acid_columns = [\n",
    "    \"Ã cid bromocloroacÃ¨tic\",\n",
    "    \"Ã cid dibromoacÃ¨tic\",\n",
    "    \"Ã cid dicloroacÃ¨tic\",\n",
    "    \"Ã cid monobromoacÃ¨tic\",\n",
    "    \"Ã cid monocloroacÃ¨tic\",\n",
    "]\n",
    "\n",
    "other_columns = [\n",
    "    \"Clorat\",\n",
    "    \"Clorit\",\n",
    "]\n",
    "\n",
    "trihalometh_mapping = {\n",
    "    \"Cloroform\": \"TCM\",\n",
    "    \"BromodiclorometÃ \": \"DCBM\",\n",
    "    \"DibromoclorometÃ \": \"CDBM\",\n",
    "    \"Bromoform\": \"TBM\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EB1 - THMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eb1_key, thm_key in trihalometh_mapping.items():\n",
    "    plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "    lab_df = eb1_targets_lab_df[[\"DateTime\", eb1_key]]\n",
    "    lab_df = lab_df[lab_df != 0]\n",
    "\n",
    "    thms = thms_df[[\"DateTime\", thm_key]]\n",
    "\n",
    "    sns.lineplot(\n",
    "        x=\"DateTime\", y=eb1_key, data=lab_df, color=\"blue\", label=\"Lab Data\"\n",
    "    )\n",
    "\n",
    "    sns.lineplot(x=\"DateTime\", y=thm_key, data=thms, color=\"red\", label=\"THMs\")\n",
    "\n",
    "    plt.title(eb1_key)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join on same day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_targets_lab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df[\"Date\"] = eb1_features_lab_df[\"DateTime\"].dt.date\n",
    "thms_df[\"Date\"] = thms_df[\"DateTime\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df[\"Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thms_df[\"Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(eb1_features_lab_df, thms_df, on=\"Date\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thms_df[\"Date\"] = thms_df[\"Date\"] + pd.DateOffset(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(eb1_features_lab_df, thms_df, on=\"Date\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the datasets based on the date without considering the time\n",
    "\n",
    "eb1_features_lab_df[\"Date\"] = eb1_features_lab_df[\"DateTime\"].dt.date\n",
    "eb1_targets_lab_df[\"Date\"] = eb1_targets_lab_df[\"DateTime\"].dt.date\n",
    "\n",
    "\n",
    "# change to DateTime if you want to consider also the time\n",
    "eb1_lab_df = pd.merge(\n",
    "    eb1_features_lab_df, eb1_targets_lab_df, on=\"Date\", how=\"inner\"\n",
    ")\n",
    "\n",
    "eb1_features_lab_df.drop(columns=[\"Date\"], inplace=True)\n",
    "eb1_targets_lab_df.drop(columns=[\"Date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_lab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_lab_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_lab_df.drop(columns=[\"Date\", \"DateTime_y\"], inplace=True)\n",
    "eb1_lab_df.rename(columns={\"DateTime_x\": \"DateTime\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_lab_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of rows that have no missing values\n",
    "eb1_lab_df.dropna().shape[0]\n",
    "\n",
    "# count number of rows that have at least one missing value\n",
    "eb1_lab_df.shape[0] - eb1_lab_df.dropna().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join on previous day EB(t-1) -> THMs(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df[\"Date\"] = eb1_features_lab_df[\"DateTime\"].dt.date\n",
    "eb1_targets_lab_df[\"Date\"] = (\n",
    "    eb1_targets_lab_df[\"DateTime\"] - pd.Timedelta(days=1)\n",
    ").dt.date\n",
    "\n",
    "eb1_lab_df = pd.merge(\n",
    "    eb1_features_lab_df, eb1_targets_lab_df, on=\"Date\", how=\"inner\"\n",
    ")\n",
    "\n",
    "eb1_features_lab_df.drop(columns=[\"Date\"], inplace=True)\n",
    "eb1_targets_lab_df.drop(columns=[\"Date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_lab_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Tests Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safecrew-3OLHM_8n-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
