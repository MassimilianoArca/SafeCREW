{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling of Outliers and NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import wasserstein_distance\n",
    "from copy import deepcopy\n",
    "\n",
    "from utils.functions.normalize_string import normalize_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(\"..\", \"data\")\n",
    "utils_folder = os.path.join(\"..\", \"utils\")\n",
    "\n",
    "interm_data_folder = os.path.join(data_folder, \"Intermediate Data\")\n",
    "clean_data_folder = os.path.join(data_folder, \"Clean Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_lab_df = pd.read_excel(\n",
    "    os.path.join(interm_data_folder, \"EB0_Features_Lab.xlsx\")\n",
    ")\n",
    "\n",
    "eb0_targets_lab_df = pd.read_excel(\n",
    "    os.path.join(interm_data_folder, \"EB0_Targets_Lab.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df = pd.read_excel(\n",
    "    os.path.join(interm_data_folder, \"EB1_Features_Lab.xlsx\")\n",
    ")\n",
    "\n",
    "eb1_targets_lab_df = pd.read_excel(\n",
    "    os.path.join(interm_data_folder, \"EB1_Targets_Lab.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_sensor_df = pd.read_excel(\n",
    "    os.path.join(interm_data_folder, \"EB0_Sensor.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_sensor_df = pd.read_excel(\n",
    "    os.path.join(interm_data_folder, \"EB1_Sensor.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thms_df = pd.read_excel(os.path.join(interm_data_folder, \"THMs.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import feature mappings\n",
    "with open(\n",
    "    os.path.join(utils_folder, \"mappings\", \"eb0_features_mapping.json\")\n",
    ") as f:\n",
    "    eb0_features_mapping = json.load(f)\n",
    "\n",
    "with open(\n",
    "    os.path.join(utils_folder, \"mappings\", \"eb1_features_mapping.json\")\n",
    ") as f:\n",
    "    eb1_features_mapping = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Per quanto riguarda outliers e missing values, ho deciso prima di rimuovere gli outliers\n",
    "dato che per gestire i missing values utilizzo data imputation con KNN, che è molto sensibile\n",
    "agli outliers.\n",
    "Inoltre, prima di rimuovere gli outliers dai sensori, vengono prima rimossi i sample\n",
    "che hanno un valore di ALARMA ESPECTRAL >= 3, e vengono rimossi anche quei valori = 0\n",
    "per alcune variabili per le quali non è appurato che si tratta di un errore di misurazione.\n",
    "Queste feature sono: index UV, Sulfats, Particules, pH, color, conductivity.\n",
    " \n",
    "Data imputation viene fatta solo sulle features e non sulle variabili target in quanto\n",
    "imputare i valori di target potrebbe portare ad avere molto bias e quindi a risultati non realistici.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Check-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_lab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_targets_lab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_targets_lab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_sensor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_sensor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_sensor_df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "eb1_sensor_df.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ouliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_lab_df.columns = [\n",
    "    normalize_string(c) for c in eb0_features_lab_df.columns\n",
    "]\n",
    "\n",
    "eb0_features_mapping = {\n",
    "    normalize_string(k): v for k, v in eb0_features_mapping.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per feature\n",
    "print(eb0_features_lab_df.isna().sum() / len(eb0_features_lab_df) * 100)\n",
    "print()\n",
    "print(\"Total number of samples: \", len(eb0_features_lab_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per sample\n",
    "eb0_features_lab_df.isna().sum(axis=1).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of the samples with zero NaNs\n",
    "(eb0_features_lab_df.isna().sum(axis=1) == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Try combinations with and without zeros\n",
    "# Outliers are removed using the IQR method with 0.05 and 0.95 quantiles,\n",
    "# since the lab dataset is small and not much noisy\n",
    "\n",
    "for lab_key in eb0_features_mapping.keys():\n",
    "    quartile1, quartile3 = eb0_features_lab_df[lab_key].quantile([0.05, 0.95])\n",
    "    iqr = quartile3 - quartile1\n",
    "    lower_bound = quartile1 - (1.5 * iqr)\n",
    "    upper_bound = quartile3 + (1.5 * iqr)\n",
    "\n",
    "    # Create a temporary DataFrame with the column values before and after the IQR operation\n",
    "    temp_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Before IQR\": eb0_features_lab_df[lab_key],\n",
    "            \"After IQR\": eb0_features_lab_df[lab_key].apply(\n",
    "                lambda x: x if (x > lower_bound and x < upper_bound) else None\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Plot the temporary DataFrame\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(20, 10))\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=temp_df,\n",
    "        palette=\"Set2\",\n",
    "        saturation=0.5,\n",
    "        whis=1.5,\n",
    "        fliersize=3,\n",
    "        ax=axs[0],\n",
    "    )\n",
    "\n",
    "    sns.histplot(\n",
    "        data=temp_df, palette=\"Set2\", kde=True, stat=\"density\", ax=axs[1]\n",
    "    )\n",
    "\n",
    "    plt.title(lab_key)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# No outliers removal since the dataset is small and not much noisy\n",
    "\n",
    "# Remove outliers\n",
    "for lab_key in eb0_features_mapping.keys():\n",
    "\n",
    "    quartile1, quartile3 = eb0_features_lab_df[lab_key].quantile([0.05, 0.95])\n",
    "    iqr = quartile3 - quartile1\n",
    "    lower_bound = quartile1 - (1.5 * iqr)\n",
    "    upper_bound = quartile3 + (1.5 * iqr)\n",
    "\n",
    "    eb0_features_lab_df[lab_key] = eb0_features_lab_df[lab_key].apply(\n",
    "        lambda x: x if (x > lower_bound and x < upper_bound) else None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per feature\n",
    "print(eb0_features_lab_df.isna().sum() / len(eb0_features_lab_df) * 100)\n",
    "print()\n",
    "print(\"Total number of samples: \", len(eb0_features_lab_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per sample\n",
    "eb0_features_lab_df.isna().sum(axis=1).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of the samples with zero NaNs\n",
    "(eb0_features_lab_df.isna().sum(axis=1) == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df.columns = [\n",
    "    normalize_string(c) for c in eb1_features_lab_df.columns\n",
    "]\n",
    "\n",
    "eb1_features_mapping = {\n",
    "    normalize_string(k): v for k, v in eb1_features_mapping.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per feature\n",
    "print(eb1_features_lab_df.isna().sum() / len(eb1_features_lab_df) * 100)\n",
    "print()\n",
    "print(\"Total number of samples: \", len(eb1_features_lab_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per sample\n",
    "eb1_features_lab_df.isna().sum(axis=1).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of the samples with zero NaNs\n",
    "(eb1_features_lab_df.isna().sum(axis=1) == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Try combinations with and without zeros\n",
    "# Outliers are removed using the IQR method\n",
    "\n",
    "for lab_key in eb1_features_mapping.keys():\n",
    "    quartile1, quartile3 = eb1_features_lab_df[lab_key].quantile([0.05, 0.95])\n",
    "    iqr = quartile3 - quartile1\n",
    "    lower_bound = quartile1 - (1.5 * iqr)\n",
    "    upper_bound = quartile3 + (1.5 * iqr)\n",
    "\n",
    "    # Create a temporary DataFrame with the column values before and after the IQR operation\n",
    "    temp_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Before IQR\": eb1_features_lab_df[lab_key],\n",
    "            \"After IQR\": eb1_features_lab_df[lab_key].apply(\n",
    "                lambda x: x if (x > lower_bound and x < upper_bound) else None\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Plot the temporary DataFrame\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(20, 10))\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=temp_df,\n",
    "        palette=\"Set2\",\n",
    "        saturation=0.5,\n",
    "        whis=1.5,\n",
    "        fliersize=3,\n",
    "        ax=axs[0],\n",
    "    )\n",
    "\n",
    "    sns.histplot(\n",
    "        data=temp_df, palette=\"Set2\", kde=True, stat=\"density\", ax=axs[1]\n",
    "    )\n",
    "\n",
    "    plt.title(lab_key)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# No outliers removal since the dataset is small and not much noisy\n",
    "\n",
    "# Remove outliers\n",
    "for lab_key in eb1_features_mapping.keys():\n",
    "\n",
    "    quartile1, quartile3 = eb1_features_lab_df[lab_key].quantile([0.05, 0.95])\n",
    "    iqr = quartile3 - quartile1\n",
    "    lower_bound = quartile1 - (1.5 * iqr)\n",
    "    upper_bound = quartile3 + (1.5 * iqr)\n",
    "\n",
    "    eb1_features_lab_df[lab_key] = eb1_features_lab_df[lab_key].apply(\n",
    "        lambda x: x if (x > lower_bound and x < upper_bound) else None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per feature\n",
    "print(eb1_features_lab_df.isna().sum() / len(eb1_features_lab_df) * 100)\n",
    "print()\n",
    "print(\"Total number of samples: \", len(eb1_features_lab_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per sample\n",
    "eb1_features_lab_df.isna().sum(axis=1).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of the samples with zero NaNs\n",
    "(eb1_features_lab_df.isna().sum(axis=1) == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EB0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove invalid samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_sensor_df = eb0_sensor_df[eb0_sensor_df[\"ALARMA ESPECTRAL\"] < 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try combinations with and without zeros\n",
    "\n",
    "# Outliers are removed using the IQR method\n",
    "# NaNs are filled with the capped values\n",
    "\n",
    "for lab_key, sensor_key in eb0_features_mapping.items():\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    quartile1, quartile3 = eb0_sensor_df[sensor_key].quantile([0.25, 0.75])\n",
    "    iqr = quartile3 - quartile1\n",
    "    lower_bound = quartile1 - (1.5 * iqr)\n",
    "    upper_bound = quartile3 + (1.5 * iqr)\n",
    "\n",
    "    eb0_without_zeros = eb0_sensor_df[sensor_key][\n",
    "        eb0_sensor_df[sensor_key] != 0\n",
    "    ]\n",
    "\n",
    "    # Create a temporary DataFrame with the column values before and after the IQR operation\n",
    "    temp_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Lab\": eb0_features_lab_df[lab_key],\n",
    "            \"Before IQR\": eb0_sensor_df[sensor_key],\n",
    "            \"Before IQR w/o zeros\": eb0_without_zeros,\n",
    "            \"After IQR\": eb0_sensor_df[sensor_key].apply(\n",
    "                lambda x: x if (x > lower_bound and x < upper_bound) else None\n",
    "            ),\n",
    "            \"After IQR w/o zeros\": eb0_without_zeros.apply(\n",
    "                lambda x: x if (x > lower_bound and x < upper_bound) else None\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ...\n",
    "\n",
    "    fig = plt.figure(figsize=(40, 20))\n",
    "\n",
    "    gs0 = gridspec.GridSpec(1, 2, figure=fig)\n",
    "\n",
    "    gs00 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=gs0[0])\n",
    "\n",
    "    # Plot the temporary DataFrame\n",
    "    sns.boxplot(\n",
    "        data=temp_df,\n",
    "        palette=\"Set2\",\n",
    "        saturation=0.5,\n",
    "        whis=1.5,\n",
    "        fliersize=3,\n",
    "        ax=fig.add_subplot(gs00[0]),\n",
    "    )\n",
    "\n",
    "    gs01 = gridspec.GridSpecFromSubplotSpec(2, 2, subplot_spec=gs0[1])\n",
    "\n",
    "    # Plot a histogram for each column\n",
    "    for i, column in enumerate(temp_df.columns[1:], start=1):\n",
    "        sns.histplot(\n",
    "            data=temp_df[column],\n",
    "            kde=True,\n",
    "            stat=\"density\",\n",
    "            ax=fig.add_subplot(gs01[i - 1]),\n",
    "            label=column,\n",
    "        )\n",
    "\n",
    "    plt.suptitle(lab_key)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(eb0_features_mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers are removed using the IQR method w/o zeros\n",
    "# The features that can have 0 values are: RATIO_HG, TERBOLESA\n",
    "\n",
    "for sensor_key in eb0_features_mapping.values():\n",
    "    if sensor_key not in [\"RATIO_HG\", \"TERBOLESA\"]:\n",
    "        eb0_sensor_df = eb0_sensor_df[eb0_sensor_df[sensor_key] > 0]\n",
    "\n",
    "    quartile1, quartile3 = eb0_sensor_df[sensor_key].quantile([0.25, 0.75])\n",
    "    iqr = quartile3 - quartile1\n",
    "    lower_bound = quartile1 - (1.5 * iqr)\n",
    "    upper_bound = quartile3 + (1.5 * iqr)\n",
    "\n",
    "    eb0_sensor_df[sensor_key] = eb0_sensor_df[sensor_key].apply(\n",
    "        lambda x: x if (x > lower_bound and x < upper_bound) else None\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EB1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove invalid samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_sensor_df = eb1_sensor_df[\n",
    "    (eb1_sensor_df[\"ALARMA SPECTRAL\"] < 3)\n",
    "    | (eb1_sensor_df[\"ALARMA SPECTRAL\"].isna())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Si potrebbe pensare di utilizzare come lower e upper bound per rimuovere gli outliers\n",
    "dai samples dei sensori i valori di 0.25 e 0.75 dei samples da laboratorio\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try combinations with and without zeros\n",
    "\n",
    "# Outliers are removed using the IQR method\n",
    "# NaNs are filled with the capped values\n",
    "\n",
    "for lab_key, sensor_key in eb1_features_mapping.items():\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    quartile1, quartile3 = eb1_sensor_df[sensor_key].quantile([0.25, 0.75])\n",
    "    iqr = quartile3 - quartile1\n",
    "    lower_bound = quartile1 - (1.5 * iqr)\n",
    "    upper_bound = quartile3 + (1.5 * iqr)\n",
    "\n",
    "    eb1_without_zeros = eb1_sensor_df[sensor_key][eb1_sensor_df[sensor_key] > 0]\n",
    "\n",
    "    # Create a temporary DataFrame with the column values before and after the IQR operation\n",
    "    temp_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Lab\": eb1_features_lab_df[lab_key],\n",
    "            \"Before IQR\": eb1_sensor_df[sensor_key],\n",
    "            \"Before IQR w/o zeros\": eb1_without_zeros,\n",
    "            \"After IQR\": eb1_sensor_df[sensor_key].apply(\n",
    "                lambda x: x if (x > lower_bound and x < upper_bound) else None\n",
    "            ),\n",
    "            \"After IQR w/o zeros\": eb1_without_zeros.apply(\n",
    "                lambda x: x if (x > lower_bound and x < upper_bound) else None\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    fig = plt.figure(figsize=(40, 20))\n",
    "\n",
    "    gs0 = gridspec.GridSpec(1, 2, figure=fig)\n",
    "\n",
    "    gs00 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=gs0[0])\n",
    "\n",
    "    # Plot the temporary DataFrame\n",
    "    sns.boxplot(\n",
    "        data=temp_df,\n",
    "        palette=\"Set2\",\n",
    "        saturation=0.5,\n",
    "        whis=1.5,\n",
    "        fliersize=3,\n",
    "        ax=fig.add_subplot(gs00[0]),\n",
    "    )\n",
    "\n",
    "    gs01 = gridspec.GridSpecFromSubplotSpec(2, 2, subplot_spec=gs0[1])\n",
    "\n",
    "    # Plot a histogram for each column\n",
    "    for i, column in enumerate(temp_df.columns[1:], start=1):\n",
    "        sns.histplot(\n",
    "            data=temp_df[column],\n",
    "            kde=True,\n",
    "            stat=\"density\",\n",
    "            ax=fig.add_subplot(gs01[i - 1]),\n",
    "            label=column,\n",
    "        )\n",
    "\n",
    "    plt.suptitle(lab_key)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(eb1_features_mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers are removed using the IQR method w/o zeros\n",
    "for sensor_key in eb1_features_mapping.values():\n",
    "    eb1_sensor_df = eb1_sensor_df[\n",
    "        (eb1_sensor_df[sensor_key] > 0) | (eb1_sensor_df[sensor_key].isna())\n",
    "    ]\n",
    "\n",
    "    quartile1, quartile3 = eb1_sensor_df[sensor_key].quantile([0.25, 0.75])\n",
    "    iqr = quartile3 - quartile1\n",
    "    lower_bound = quartile1 - (1.5 * iqr)\n",
    "    upper_bound = quartile3 + (1.5 * iqr)\n",
    "\n",
    "    eb1_sensor_df[sensor_key] = eb1_sensor_df[sensor_key].apply(\n",
    "        lambda x: x if (x > lower_bound and x < upper_bound) else None\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per feature\n",
    "print(eb0_features_lab_df.isna().sum() / len(eb0_features_lab_df) * 100)\n",
    "print()\n",
    "print(\"Total number of samples: \", len(eb0_features_lab_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per sample\n",
    "eb0_features_lab_df.isna().sum(axis=1).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove features with more than 60% of NaNs\n",
    "# eb0_features_lab_df = eb0_features_lab_df.dropna(\n",
    "#     thresh=len(eb0_features_lab_df) * 0.6, axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per sample\n",
    "eb0_features_lab_df.isna().sum(axis=1).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find sampling frequency\n",
    "eb0_features_lab_df[\"DateTime\"].diff().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_lab_df = eb0_features_lab_df.resample(\"D\", on=\"DateTime\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing Conductivity 11-2022 outliers, multiply by 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(\n",
    "    data=eb0_features_lab_df,\n",
    "    x=\"DateTime\",\n",
    "    y=\"Conductivitat a 20oC\",\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=eb0_features_lab_df[eb0_features_lab_df[\"Conductivitat a 20oC\"] < 600],\n",
    "    x=\"DateTime\",\n",
    "    y=\"Conductivitat a 20oC\",\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "eb0_features_lab_df[eb0_features_lab_df[\"Conductivitat a 20oC\"] < 600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing Conductivity 11-2022 outliers, multiply by 10\n",
    "eb0_features_lab_df.loc[\n",
    "    (eb0_features_lab_df.index == \"2022-11-02\")\n",
    "    | (eb0_features_lab_df.index == \"2022-11-29\"),\n",
    "    \"Conductivitat a 20oC\",\n",
    "] *= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate missing values\n",
    "eb0_features_lab_df = eb0_features_lab_df.interpolate(method=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_lab_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_lab_df.fillna(method=\"bfill\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in eb0_features_lab_df.columns.difference([\"DateTime\"]):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(data=eb0_features_lab_df, x=\"DateTime\", y=column)\n",
    "    plt.title(column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per feature\n",
    "print(eb1_features_lab_df.isna().sum() / len(eb1_features_lab_df) * 100)\n",
    "print()\n",
    "print(\"Total number of samples: \", len(eb1_features_lab_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EB0\n",
    "\n",
    "Color                                     25.487365\n",
    "Conductivitat a 20oC                       5.703971\n",
    "Mercuri                                    7.364621\n",
    "Quantitat més abundant de partícules    94.151625\n",
    "Sulfats                                   84.187726\n",
    "Temperatura                               61.227437\n",
    "Terbolesa                                  5.703971\n",
    "pH                                         5.703971\n",
    "Índex UV                                 92.707581"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per sample\n",
    "eb1_features_lab_df.isna().sum(axis=1).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove features with more than 60% of NaNs\n",
    "# eb1_features_lab_df = eb1_features_lab_df.dropna(\n",
    "#     thresh=len(eb1_features_lab_df) * 0.6, axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per sample\n",
    "eb1_features_lab_df.isna().sum(axis=1).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find sampling frequency\n",
    "eb1_features_lab_df[\"DateTime\"].diff().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df = eb1_features_lab_df.resample(\"D\", on=\"DateTime\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate missing values\n",
    "eb1_features_lab_df = eb1_features_lab_df.interpolate(method=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in eb1_features_lab_df.columns.difference([\"DateTime\"]):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(data=eb1_features_lab_df, x=\"DateTime\", y=column)\n",
    "    plt.title(column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per feature\n",
    "print(eb1_targets_lab_df.isna().sum() / len(eb1_targets_lab_df) * 100)\n",
    "print()\n",
    "print(\"Total number of samples: \", len(eb1_targets_lab_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per feature\n",
    "print(eb0_sensor_df.isna().sum() / len(eb0_sensor_df) * 100)\n",
    "print()\n",
    "print(\"Total number of samples: \", len(eb0_sensor_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per sample\n",
    "eb0_sensor_df.isna().sum(axis=1).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop useless and NaN columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_columns = [\n",
    "    \"ALARMA ESPECTRAL\",\n",
    "    \"OX\",\n",
    "    \"PARTICULES\",\n",
    "    \"RATIO_TERB_SIG\",\n",
    "    \"RATIO_TLF_UV\",\n",
    "    \"SULFAT\",\n",
    "    \"TLF\",\n",
    "    \"VIS436\",\n",
    "    \"VIS525\",\n",
    "    \"VIS620\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eb0_sensor_df = eb0_sensor_df.drop(useless_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find sampling frequency\n",
    "eb0_sensor_df[\"DateTime\"].diff().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_sensor_df = eb0_sensor_df.resample(\"D\", on=\"DateTime\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate missing values\n",
    "eb0_sensor_df = eb0_sensor_df.interpolate(method=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_lab_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in eb0_sensor_df.columns.difference([\"DateTime\"]):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(data=eb0_sensor_df, x=\"DateTime\", y=column)\n",
    "    plt.title(column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_sensor_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_columns = [\n",
    "    \"ALARMA SPECTRAL\",\n",
    "    \"DOC\",\n",
    "    \"ORP\",\n",
    "    \"PARTICULES\",\n",
    "    \"TEMPERATURA\",\n",
    "    \"TLF\",\n",
    "    \"TOC\",\n",
    "    \"UVA\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eb1_sensor_df = eb1_sensor_df.drop(useless_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find sampling frequency\n",
    "eb1_sensor_df[\"DateTime\"].diff().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_sensor_df = eb1_sensor_df.resample(\"D\", on=\"DateTime\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate missing values\n",
    "eb1_sensor_df = eb1_sensor_df.interpolate(method=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_sensor_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_sensor_df.fillna(method=\"bfill\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in eb1_sensor_df.columns.difference([\"DateTime\"]):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(data=eb1_sensor_df, x=\"DateTime\", y=column)\n",
    "    plt.title(column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_lab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_sensor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_sensor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_lab_df.reset_index(inplace=True)\n",
    "eb1_features_lab_df.reset_index(inplace=True)\n",
    "\n",
    "eb0_sensor_df.reset_index(inplace=True)\n",
    "eb1_sensor_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_lab_df.to_excel(\n",
    "    os.path.join(clean_data_folder, \"EB0_Features_Lab.xlsx\"), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_targets_lab_df.to_excel(\n",
    "    os.path.join(clean_data_folder, \"EB0_Targets_Lab.xlsx\"), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_targets_lab_df.to_excel(\n",
    "    os.path.join(clean_data_folder, \"EB1_Targets_Lab.xlsx\"), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df.to_excel(\n",
    "    os.path.join(clean_data_folder, \"EB1_Features_Lab.xlsx\"), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_sensor_df.to_excel(\n",
    "    os.path.join(clean_data_folder, \"EB0_Sensor.xlsx\"), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_sensor_df.to_excel(\n",
    "    os.path.join(clean_data_folder, \"EB1_Sensor.xlsx\"), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safecrew-3OLHM_8n-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
