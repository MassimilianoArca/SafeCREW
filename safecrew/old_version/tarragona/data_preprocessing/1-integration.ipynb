{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Raw Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(\"..\", \"data\")\n",
    "utils_folder = os.path.join(\"..\", \"utils\")\n",
    "\n",
    "raw_data_path = os.path.join(data_folder, \"Raw Data\")\n",
    "interm_data_path = os.path.join(data_folder, \"Intermediate Data\")\n",
    "\n",
    "eb_measure_path = os.path.join(raw_data_path, \"EB0_EB1.xlsx\")\n",
    "eb0_sensor_path = os.path.join(raw_data_path, \"Dades sensor online EB0\")\n",
    "eb1_sensor_path = os.path.join(raw_data_path, \"Dades sensor online EB1\")\n",
    "thm_measure_path = os.path.join(raw_data_path, \"THMs_ARBOCÌ§_2022.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EB0 - EB1 laboratory measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_eb0_measure_df = pd.read_excel(eb_measure_path, sheet_name=\"EB0\")\n",
    "raw_eb1_measure_df = pd.read_excel(eb_measure_path, sheet_name=\"EB1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_eb0_measure_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_measure_df = raw_eb0_measure_df.copy()\n",
    "\n",
    "eb0_measure_df[\"data\"] = pd.to_datetime(\n",
    "    eb0_measure_df[\"data\"], format=\"%d/%m/%Y\"\n",
    ").dt.date\n",
    "eb0_measure_df[\"SAMPDATE\"] = pd.to_datetime(\n",
    "    eb0_measure_df[\"SAMPDATE\"], format=\"%d/%m/%Y %H:%M:%S\"\n",
    ").dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_measure_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load eb0 features and targets\n",
    "with open(\n",
    "    os.path.join(utils_folder, \"lists\", \"eb0_measure_features.json\"), \"r\"\n",
    ") as f:\n",
    "    eb0_measure_features = json.load(f)\n",
    "\n",
    "with open(\n",
    "    os.path.join(utils_folder, \"lists\", \"eb0_measure_targets.json\"), \"r\"\n",
    ") as f:\n",
    "    eb0_measure_targets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with only the features of interest, where the name of the features in the list above are in the column 'ANALYTE'\n",
    "eb0_features_df = eb0_measure_df[\n",
    "    eb0_measure_df[\"ANALYTE\"].isin(eb0_measure_features)\n",
    "]\n",
    "\n",
    "eb0_features_df.drop(\n",
    "    columns=[\n",
    "        \"any_\",\n",
    "        \"FOLDERNO\",\n",
    "        \"APPRSTS\",\n",
    "        \"CLSAMPNO\",\n",
    "        \"DISPSTS\",\n",
    "        \"TESTNO\",\n",
    "        \"SINONYM\",\n",
    "        \"SINAC_SENDED\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_targets_df = eb0_measure_df[\n",
    "    eb0_measure_df[\"ANALYTE\"].isin(eb0_measure_targets)\n",
    "]\n",
    "\n",
    "eb0_targets_df.drop(\n",
    "    columns=[\n",
    "        \"any_\",\n",
    "        \"FOLDERNO\",\n",
    "        \"APPRSTS\",\n",
    "        \"CLSAMPNO\",\n",
    "        \"DISPSTS\",\n",
    "        \"TESTNO\",\n",
    "        \"SINONYM\",\n",
    "        \"SINAC_SENDED\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_df[\"RESULTASNUMERIC\"] = eb0_features_df[\"RESULTASNUMERIC\"].astype(\n",
    "    float\n",
    ")\n",
    "eb0_targets_df[\"RESULTASNUMERIC\"] = eb0_targets_df[\"RESULTASNUMERIC\"].astype(\n",
    "    float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_df.insert(\n",
    "    loc=0,\n",
    "    column=\"DateTime\",\n",
    "    value=pd.to_datetime(\n",
    "        eb0_features_df[\"data\"].astype(str)\n",
    "        + \" \"\n",
    "        + eb0_features_df[\"SAMPDATE\"].astype(str)\n",
    "    ),\n",
    ")\n",
    "\n",
    "eb0_targets_df.insert(\n",
    "    loc=0,\n",
    "    column=\"DateTime\",\n",
    "    value=pd.to_datetime(\n",
    "        eb0_targets_df[\"data\"].astype(str)\n",
    "        + \" \"\n",
    "        + eb0_targets_df[\"SAMPDATE\"].astype(str)\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_df.drop(columns=[\"data\", \"SAMPDATE\"], inplace=True)\n",
    "eb0_targets_df.drop(columns=[\"data\", \"SAMPDATE\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_df[eb0_features_df[\"ANALYTE\"] == \"Ãndex UV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_targets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame with one sample per unique DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_df = eb0_features_df.pivot_table(\n",
    "    index=pd.Grouper(key=\"DateTime\"),\n",
    "    columns=\"ANALYTE\",\n",
    "    values=\"RESULTASNUMERIC\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_targets_df = eb0_targets_df.pivot_table(\n",
    "    index=pd.Grouper(key=\"DateTime\"),\n",
    "    columns=\"ANALYTE\",\n",
    "    values=\"RESULTASNUMERIC\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_targets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_df.dropna(how=\"all\", inplace=True)\n",
    "eb0_targets_df.dropna(how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_min_date = eb0_features_df.index.min()\n",
    "eb0_max_date = eb0_features_df.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_df.reset_index(inplace=True)\n",
    "eb0_targets_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_targets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_df.to_excel(\n",
    "    os.path.join(interm_data_path, \"EB0_Features_Lab.xlsx\"), index=False\n",
    ")\n",
    "\n",
    "eb0_targets_df.to_excel(\n",
    "    os.path.join(interm_data_path, \"EB0_Targets_Lab.xlsx\"), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_eb1_measure_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_measure_df = raw_eb1_measure_df.copy()\n",
    "\n",
    "eb1_measure_df[\"data\"] = pd.to_datetime(\n",
    "    eb1_measure_df[\"data\"], format=\"%d/%m/%Y\"\n",
    ").dt.date\n",
    "eb1_measure_df[\"SAMPDATE\"] = pd.to_datetime(\n",
    "    eb1_measure_df[\"SAMPDATE\"], format=\"%d/%m/%Y %H:%M:%S\"\n",
    ").dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_measure_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load eb1 features and targets\n",
    "with open(\n",
    "    os.path.join(utils_folder, \"lists\", \"eb1_measure_features.json\"), \"r\"\n",
    ") as f:\n",
    "    eb1_measure_features = json.load(f)\n",
    "\n",
    "with open(\n",
    "    os.path.join(utils_folder, \"lists\", \"eb1_measure_targets.json\"), \"r\"\n",
    ") as f:\n",
    "    eb1_measure_targets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_df = eb1_measure_df[\n",
    "    eb1_measure_df[\"ANALYTE\"].isin(eb1_measure_features)\n",
    "]\n",
    "\n",
    "eb1_features_df.drop(\n",
    "    columns=[\n",
    "        \"any_\",\n",
    "        \"FOLDERNO\",\n",
    "        \"APPRSTS\",\n",
    "        \"CLSAMPNO\",\n",
    "        \"DISPSTS\",\n",
    "        \"TESTNO\",\n",
    "        \"SINONYM\",\n",
    "        \"SINAC_SENDED\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_targets_df = eb1_measure_df[\n",
    "    eb1_measure_df[\"ANALYTE\"].isin(eb1_measure_targets)\n",
    "]\n",
    "\n",
    "eb1_targets_df.drop(\n",
    "    columns=[\n",
    "        \"any_\",\n",
    "        \"FOLDERNO\",\n",
    "        \"APPRSTS\",\n",
    "        \"CLSAMPNO\",\n",
    "        \"DISPSTS\",\n",
    "        \"TESTNO\",\n",
    "        \"SINONYM\",\n",
    "        \"SINAC_SENDED\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_df[\"RESULTASNUMERIC\"] = eb1_features_df[\"RESULTASNUMERIC\"].astype(\n",
    "    float\n",
    ")\n",
    "eb1_targets_df[\"RESULTASNUMERIC\"] = eb1_targets_df[\"RESULTASNUMERIC\"].astype(\n",
    "    float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_df.insert(\n",
    "    loc=0,\n",
    "    column=\"DateTime\",\n",
    "    value=pd.to_datetime(\n",
    "        eb1_features_df[\"data\"].astype(str)\n",
    "        + \" \"\n",
    "        + eb1_features_df[\"SAMPDATE\"].astype(str)\n",
    "    ),\n",
    ")\n",
    "\n",
    "eb1_targets_df.insert(\n",
    "    loc=0,\n",
    "    column=\"DateTime\",\n",
    "    value=pd.to_datetime(\n",
    "        eb1_targets_df[\"data\"].astype(str)\n",
    "        + \" \"\n",
    "        + eb1_targets_df[\"SAMPDATE\"].astype(str)\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_df.drop(columns=[\"data\", \"SAMPDATE\"], inplace=True)\n",
    "eb1_targets_df.drop(columns=[\"data\", \"SAMPDATE\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_targets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame with one sample per unique DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_df = eb1_features_df.pivot_table(\n",
    "    index=pd.Grouper(key=\"DateTime\"),\n",
    "    columns=\"ANALYTE\",\n",
    "    values=\"RESULTASNUMERIC\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_targets_df = eb1_targets_df.pivot_table(\n",
    "    index=pd.Grouper(key=\"DateTime\"),\n",
    "    columns=\"ANALYTE\",\n",
    "    values=\"RESULTASNUMERIC\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_targets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_df.dropna(how=\"all\", inplace=True)\n",
    "eb1_targets_df.dropna(how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_min_date = eb1_features_df.index.min()\n",
    "eb1_max_date = eb1_features_df.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_df.reset_index(inplace=True)\n",
    "eb1_targets_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_df.to_excel(\n",
    "    os.path.join(interm_data_path, \"EB1_Features_Lab.xlsx\"), index=False\n",
    ")\n",
    "\n",
    "eb1_targets_df.to_excel(\n",
    "    os.path.join(interm_data_path, \"EB1_Targets_Lab.xlsx\"), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Sensors Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_folder(folder_path):\n",
    "    df_dict = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        f = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(f):\n",
    "            if not filename.startswith(\".\"):\n",
    "                if filename.endswith(\".csv\"):\n",
    "                    with open(os.path.join(folder_path, filename), \"r\") as file:\n",
    "                        lines = file.readlines()\n",
    "\n",
    "                        corrected_lines = []\n",
    "                        line_iter = iter(lines)\n",
    "                        max_len = 0\n",
    "                        for line in line_iter:\n",
    "                            if len(line.split(\";\")) > max_len:\n",
    "                                max_len = len(line.split(\";\"))\n",
    "\n",
    "                            if len(line.split(\";\")) < max_len:\n",
    "                                try:\n",
    "                                    line = line + next(line_iter)\n",
    "                                except StopIteration:\n",
    "                                    pass\n",
    "\n",
    "                            if \"n/a;\\n\" in line:\n",
    "                                if not line.endswith(\"n/a;\\n\"):\n",
    "                                    line = line.replace(\"n/a;\\n\", \"n/a;\")\n",
    "                                    line = line.rstrip(\";\\n\") + \"\\n\"\n",
    "                                else:\n",
    "                                    line = line.replace(\"n/a;\\n\", \"n/a;\")\n",
    "                                    line = line.rstrip(\";\") + \"\\n\"\n",
    "                            else:\n",
    "                                line = line.rstrip(\";\\n\") + \"\\n\"\n",
    "\n",
    "                            corrected_lines.append(line)\n",
    "\n",
    "                        # Write the corrected lines to a new file\n",
    "                        corrected_file = os.path.join(folder_path, filename)\n",
    "                        with open(corrected_file, \"w\") as file:\n",
    "                            file.writelines(corrected_lines)\n",
    "\n",
    "                    # Load the corrected file with pandas\n",
    "                    df = pd.read_csv(corrected_file, sep=\";\", na_filter=False)\n",
    "                elif filename.endswith(\".xlsx\"):\n",
    "                    df = pd.read_excel(f)\n",
    "                else:\n",
    "                    raise Exception(\"File format not supported\")\n",
    "                df_dict[pathlib.Path(filename).stem] = df\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EB0 online sensor readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_eb0_sensor_df_dict = load_data_from_folder(eb0_sensor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {}\n",
    "for key in deepcopy(raw_eb0_sensor_df_dict).keys():\n",
    "    new_key = key.partition(\"_\")[2].upper()\n",
    "    new_dict[new_key] = deepcopy(raw_eb0_sensor_df_dict).pop(key)\n",
    "raw_eb0_sensor_df_dict = new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_eb0_sensor_df_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_eb0_sensor_df_dict[\"COND\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_sensor_df_dict = deepcopy(raw_eb0_sensor_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in eb0_sensor_df_dict.items():\n",
    "    item[\"Fecha\"] = pd.to_datetime(item[\"Fecha\"], format=\"%d/%m/%Y\").dt.date\n",
    "    item[\"HORA\"] = pd.to_datetime(item[\"HORA\"], format=\"%H:%M:%S\").dt.time\n",
    "    item.insert(\n",
    "        loc=0,\n",
    "        column=\"DateTime\",\n",
    "        value=pd.to_datetime(\n",
    "            item[\"Fecha\"].astype(str) + \" \" + item[\"HORA\"].astype(str)\n",
    "        ),\n",
    "    )\n",
    "    item.drop(columns=[\"Fecha\", \"HORA\"], inplace=True)\n",
    "    for col in item.columns[1:]:\n",
    "        item[col] = item[col].replace(\"n/a\", None, regex=True)\n",
    "        item.dropna(inplace=True)\n",
    "        item[col] = item[col].replace(\",\", \".\", regex=True)\n",
    "        item[col] = item[col].astype(float)\n",
    "\n",
    "    eb0_sensor_df_dict[key] = item[\n",
    "        (item[\"DateTime\"] >= eb0_min_date) & (item[\"DateTime\"] <= eb0_max_date)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the column that contains the measured value is the first one containing _PV\n",
    "# rename it with the name of the measured parameter\n",
    "for key, item in eb0_sensor_df_dict.items():\n",
    "    for col in item.columns:\n",
    "        if \"_PV\" in col:\n",
    "            item.rename(columns={col: key}, inplace=True)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a sample is considered valid if the columns after the one containing the measured value (the second one) are all equal to 0\n",
    "# if not, the sample is considered invalid and is dropped\n",
    "for key, item in eb0_sensor_df_dict.items():\n",
    "    # Select the columns after the second one that contain '_VM', 'VA' and 'F1' and check if all values are equal to 0\n",
    "    selected_columns = item.columns[2:].tolist()\n",
    "    filtered_columns = (\n",
    "        item.filter(selected_columns).filter(like=\"_VM\").columns.tolist()\n",
    "        + item.filter(selected_columns).filter(like=\"VA\").columns.tolist()\n",
    "        + item.filter(selected_columns).filter(like=\"F1\").columns.tolist()\n",
    "    )\n",
    "\n",
    "    mask = (item[filtered_columns] != 0).any(axis=1)\n",
    "\n",
    "    # Drop the rows where the mask is True\n",
    "    item.drop(item[mask].index, inplace=True)\n",
    "\n",
    "    # Drop the columns after the second one\n",
    "    item.drop(columns=item.columns[2:], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the median sampling rate for each sensor to retrieve the most frequent sampling rate\n",
    "sampling_rates = {}\n",
    "for key, item in eb0_sensor_df_dict.items():\n",
    "    sampling_rates[key] = item[\"DateTime\"].diff().median()\n",
    "\n",
    "# get the most frequent sampling rate\n",
    "sampling_rate = max(\n",
    "    set(sampling_rates.values()), key=list(sampling_rates.values()).count\n",
    ")\n",
    "\n",
    "# resample the dataframes to the most frequent sampling rate\n",
    "for key, item in eb0_sensor_df_dict.items():\n",
    "    item.set_index(\"DateTime\", inplace=True)\n",
    "    item = item[~item.index.duplicated(keep=\"first\")]\n",
    "    item = item.resample(sampling_rate).interpolate(method=\"time\")\n",
    "    item.reset_index(inplace=True)\n",
    "    eb0_sensor_df_dict[key] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the final DataFrame with the first DataFrame in the dictionary\n",
    "eb0_sensor_df = next(iter(eb0_sensor_df_dict.values()))\n",
    "\n",
    "# Merge the rest of the DataFrames\n",
    "for key, df in list(eb0_sensor_df_dict.items())[1:]:\n",
    "    eb0_sensor_df = eb0_sensor_df.merge(df, on=\"DateTime\", how=\"outer\")\n",
    "\n",
    "# Sort the final DataFrame by 'DateTime'\n",
    "eb0_sensor_df.sort_values(\"DateTime\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort columns after DateTime by name\n",
    "eb0_sensor_df = eb0_sensor_df.reindex(sorted(eb0_sensor_df.columns), axis=1)\n",
    "\n",
    "# move DateTime to the first column\n",
    "col = eb0_sensor_df.pop(\"DateTime\")\n",
    "eb0_sensor_df.insert(0, \"DateTime\", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_sensor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare TEMP and TEMP_AIGUA with Temperatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_temp_df = eb0_features_df[[\"DateTime\", \"Temperatura\"]].copy()\n",
    "\n",
    "sensor_temp_df = eb0_sensor_df[[\"DateTime\", \"TEMP\"]].copy()\n",
    "sensor_temp_aigua_df = eb0_sensor_df[[\"DateTime\", \"TEMP_AIGUA\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(data=lab_temp_df, x=\"DateTime\", y=\"Temperatura\", label=\"Lab\")\n",
    "sns.lineplot(data=sensor_temp_df, x=\"DateTime\", y=\"TEMP\", label=\"Sensor\")\n",
    "sns.lineplot(\n",
    "    data=sensor_temp_aigua_df,\n",
    "    x=\"DateTime\",\n",
    "    y=\"TEMP_AIGUA\",\n",
    "    label=\"Sensor_water\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop TEMP from the sensor dataframe and keep only TEMP_AIGUA\n",
    "eb0_sensor_df.drop(columns=[\"TEMP\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_sensor_df.to_excel(os.path.join(interm_data_path, \"EB0_Sensor.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EB1 online sensor readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_eb1_sensor_df_dict = load_data_from_folder(eb1_sensor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {}\n",
    "for key in deepcopy(raw_eb1_sensor_df_dict).keys():\n",
    "    new_key = \" \".join(key.split(\" \")[:-1]).upper()\n",
    "    new_dict[new_key] = deepcopy(raw_eb1_sensor_df_dict).pop(key)\n",
    "raw_eb1_sensor_df_dict = new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_eb1_sensor_df_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove SCAN variables from the dictionary since they are less reliable than the other sensors\n",
    "raw_eb1_sensor_df_dict.pop(\"TERBOLESA SCAN\")\n",
    "raw_eb1_sensor_df_dict.pop(\"UVA SCAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_eb1_sensor_df_dict[\"PH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_sensor_df_dict = deepcopy(raw_eb1_sensor_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in eb1_sensor_df_dict.items():\n",
    "    item.dropna(inplace=True)\n",
    "    item[\"Fecha\"] = pd.to_datetime(\n",
    "        item[\"Fecha\"].astype(str).str.lstrip(),\n",
    "        format=\"%d/%m/%Y\",\n",
    "        errors=\"coerce\",\n",
    "    ).dt.date\n",
    "\n",
    "    # if HORA is in the column list\n",
    "    if \"HORA\" in item.columns:\n",
    "        item.drop(item[item[\"HORA\"] == \"0\"].index, inplace=True)\n",
    "        item[\"HORA\"] = pd.to_datetime(item[\"HORA\"], format=\"%H:%M:%S\").dt.time\n",
    "\n",
    "        item.insert(\n",
    "            loc=0,\n",
    "            column=\"DateTime\",\n",
    "            value=pd.to_datetime(\n",
    "                item[\"Fecha\"].astype(str) + \" \" + item[\"HORA\"].astype(str)\n",
    "            ),\n",
    "        )\n",
    "        item.drop(columns=[\"Fecha\", \"HORA\"], inplace=True)\n",
    "    else:\n",
    "        item.insert(\n",
    "            loc=0,\n",
    "            column=\"DateTime\",\n",
    "            value=item[\"Fecha\"],\n",
    "        )\n",
    "        item.drop(columns=[\"Fecha\"], inplace=True)\n",
    "\n",
    "    for col in item.columns[1:]:\n",
    "        item[col] = item[col].replace(\"n/a\", None, regex=True)\n",
    "        item.dropna(inplace=True)\n",
    "        item[col] = item[col].replace(\",\", \".\", regex=True)\n",
    "        item[col] = item[col].astype(float)\n",
    "\n",
    "    eb1_sensor_df_dict[key] = item[\n",
    "        (item[\"DateTime\"] >= eb1_min_date) & (item[\"DateTime\"] <= eb1_max_date)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the column that contains the measured value is the first one containing _PV\n",
    "# rename it with the name of the measured parameter\n",
    "for key, item in eb1_sensor_df_dict.items():\n",
    "    for col in item.columns:\n",
    "        if \"_PV\" in col:\n",
    "            item.rename(columns={col: key}, inplace=True)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a sample is considered valid if the columns after the one containing the measured value (the second one) are all equal to 0\n",
    "# if not, the sample is considered invalid and is dropped\n",
    "for key, item in eb1_sensor_df_dict.items():\n",
    "    # Select the columns after the second one and check if all values are equal to 0\n",
    "    mask = (item.iloc[:, 2:] != 0).any(axis=1)\n",
    "\n",
    "    # Drop the rows where the mask is True\n",
    "    item.drop(item[mask].index, inplace=True)\n",
    "\n",
    "    # Drop the columns after the second one\n",
    "    item.drop(columns=item.columns[2:], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the median sampling rate for each sensor to retrieve the most frequent sampling rate\n",
    "sampling_rates = {}\n",
    "for key, item in eb1_sensor_df_dict.items():\n",
    "    sampling_rates[key] = item[\"DateTime\"].diff().median()\n",
    "\n",
    "# get the most frequent sampling rate\n",
    "sampling_rate = max(\n",
    "    set(sampling_rates.values()), key=list(sampling_rates.values()).count\n",
    ")\n",
    "\n",
    "# resample the dataframes to the most frequent sampling rate\n",
    "for key, item in eb1_sensor_df_dict.items():\n",
    "    item.set_index(\"DateTime\", inplace=True)\n",
    "    item = item[~item.index.duplicated(keep=\"first\")]\n",
    "    item = item.resample(sampling_rate).interpolate(method=\"time\")\n",
    "    item.reset_index(inplace=True)\n",
    "    eb1_sensor_df_dict[key] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the final DataFrame with the first DataFrame in the dictionary\n",
    "eb1_sensor_df = next(iter(eb1_sensor_df_dict.values()))\n",
    "\n",
    "# Merge the rest of the DataFrames\n",
    "for key, df in list(eb1_sensor_df_dict.items())[1:]:\n",
    "    eb1_sensor_df = eb1_sensor_df.merge(df, on=\"DateTime\", how=\"outer\")\n",
    "\n",
    "# Sort the final DataFrame by 'DateTime'\n",
    "eb1_sensor_df.sort_values(\"DateTime\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort columns after DateTime by name\n",
    "eb1_sensor_df = eb1_sensor_df.reindex(sorted(eb1_sensor_df.columns), axis=1)\n",
    "\n",
    "# move DateTime to the first column\n",
    "col = eb1_sensor_df.pop(\"DateTime\")\n",
    "eb1_sensor_df.insert(0, \"DateTime\", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_sensor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_sensor_df.to_excel(os.path.join(interm_data_path, \"EB1_Sensor.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THM measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the last \";\" from the last line of the file\n",
    "\n",
    "with open(thm_measure_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "    corrected_lines = []\n",
    "    line_iter = iter(lines)\n",
    "    max_len = 0\n",
    "    for line in line_iter:\n",
    "        line = line.rstrip(\";\\n\") + \"\\n\"\n",
    "        corrected_lines.append(line)\n",
    "\n",
    "with open(thm_measure_path, \"w\") as file:\n",
    "    file.writelines(corrected_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_thm_measure_df = pd.read_csv(thm_measure_path, sep=\";\", na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_thm_measure_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thm_measure_df = deepcopy(raw_thm_measure_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thm_measure_df[\"Data\"] = pd.to_datetime(\n",
    "    thm_measure_df[\"Data\"], format=\"%d/%m/%Y\"\n",
    ").dt.date\n",
    "\n",
    "\n",
    "thm_measure_df[\"Hora\"] = pd.to_datetime(\n",
    "    thm_measure_df[\"Hora\"], format=\"%Hh%M\"\n",
    ").dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thm_measure_df[[\"TCM\", \"DCBM\", \"CDBM\", \"TBM\", \"TTHMs\"]] = thm_measure_df[\n",
    "    [\"TCM\", \"DCBM\", \"CDBM\", \"TBM\", \"TTHMs\"]\n",
    "].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thm_measure_df.drop(columns=[\"PM\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union of the date and time columns\n",
    "thm_measure_df.insert(\n",
    "    loc=0,\n",
    "    column=\"DateTime\",\n",
    "    value=pd.to_datetime(\n",
    "        thm_measure_df[\"Data\"].astype(str)\n",
    "        + \" \"\n",
    "        + thm_measure_df[\"Hora\"].astype(str)\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thm_measure_df.drop(columns=[\"Data\", \"Hora\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thm_measure_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thm_measure_df.to_excel(os.path.join(interm_data_path, \"THMs.xlsx\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiments-XEWf3URI-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
