{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supply Points Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "from copy import deepcopy\n",
    "from pathvalidate import sanitize_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(os.path.join(\"..\", \"data\"))\n",
    "raw_data_folder = os.path.join(data_folder, \"Raw Data\")\n",
    "\n",
    "datasets_folder = os.path.join(data_folder, \"Intermediate Data\")\n",
    "\n",
    "histograms_folder = os.path.join(data_folder, \"Histograms\")\n",
    "NaNvsNumber_folder = os.path.join(data_folder, \"NaNvsNumber\")\n",
    "timeseries_folder = os.path.join(data_folder, \"Timeseries\")\n",
    "boxplot_folder = os.path.join(data_folder, \"Boxplots\")\n",
    "store_folder = os.path.join(data_folder, \"temporary results\")\n",
    "metadata_folder = os.path.join(data_folder, \"Metadata\")\n",
    "\n",
    "raw_grab_samples_path = os.path.join(\n",
    "    datasets_folder, \"All grab samples - supply points.xlsx\"\n",
    ")\n",
    "house_codes_path = os.path.join(datasets_folder, \"Case-Codici.xlsx\")\n",
    "\n",
    "sensor_data_folder = os.path.join(raw_data_folder, \"Case dell'acqua - Sensori\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_values(series):\n",
    "    num_nans = series.isna().sum()\n",
    "    num_numbers = series[\n",
    "        series.apply(lambda x: isinstance(x, (int, float)))\n",
    "    ].count()\n",
    "    return pd.Series([num_nans, num_numbers], index=[\"NaN\", \"numbers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_grab_samples_df = pd.read_excel(raw_grab_samples_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from json file the columns\n",
    "with open(os.path.join(store_folder, \"columns_types.json\"), \"r\") as f:\n",
    "    column_types = json.load(f)\n",
    "\n",
    "all_metadata_columns = column_types[\"metadata_columns\"]\n",
    "all_feature_columns = column_types[\"features_columns\"]\n",
    "all_target_columns = column_types[\"targets_columns\"]\n",
    "\n",
    "metadata_columns = list(\n",
    "    set(all_metadata_columns) & set(raw_grab_samples_df.columns)\n",
    ")\n",
    "feature_columns = list(\n",
    "    set(all_feature_columns) & set(raw_grab_samples_df.columns)\n",
    ")\n",
    "target_columns = list(\n",
    "    set(all_target_columns) & set(raw_grab_samples_df.columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Case dell'Acqua - Overall Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN vs Strings vs Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram = raw_grab_samples_df[feature_columns + target_columns].apply(\n",
    "    count_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram.loc[\"Total\"] = histogram.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see Strings add 'Strings' to the list below\n",
    "ax = histogram.T[[\"NaN\", \"numbers\"]].plot.bar(figsize=(30, 10))\n",
    "\n",
    "for label in ax.get_xticklabels():\n",
    "    label.set_color(\"green\" if label.get_text() in feature_columns else \"grey\")\n",
    "\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.02))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "for column in feature_columns + target_columns:\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    hist = raw_grab_samples_df[column].where(\n",
    "        raw_grab_samples_df[column].apply(lambda x: isinstance(x, (int, float)))\n",
    "    )\n",
    "    count, bins, patches = plt.hist(\n",
    "        hist.dropna(), bins=30, edgecolor=\"black\", linewidth=1.2\n",
    "    )\n",
    "    plt.title(\n",
    "        column\n",
    "        + \" - Count: \"\n",
    "        + str(hist.count())\n",
    "        + \" / \"\n",
    "        + str(raw_grab_samples_df.shape[0])\n",
    "    )\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    # Set x-ticks to bin edges and x-tick labels to intervals\n",
    "    plt.xticks(\n",
    "        bins[:-1],\n",
    "        [f\"{bins[i]:.2f}-{bins[i+1]:.2f}\" for i in range(len(bins) - 1)],\n",
    "        rotation=\"vertical\",\n",
    "        fontsize=8,\n",
    "    )\n",
    "\n",
    "    for p in patches:\n",
    "        plt.annotate(\n",
    "            str(int(p.get_height())),\n",
    "            (p.get_x() + p.get_width() / 2, p.get_height() * 1.02),\n",
    "            ha=\"center\",  # horizontal alignment is center\n",
    "        )\n",
    "\n",
    "    directory = os.path.join(histograms_folder, \"Grab Overall\")\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    plt.savefig(\n",
    "        os.path.join(\n",
    "            directory,\n",
    "            sanitize_filename(column) + \".png\",\n",
    "        ),\n",
    "        dpi=300,\n",
    "    )\n",
    "\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "for col in feature_columns + target_columns:\n",
    "    sanitized_col = sanitize_filename(col)\n",
    "    # Extract unit of measure from column name\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(\n",
    "        x=\"Data di prelievo\",\n",
    "        y=col,\n",
    "        data=raw_grab_samples_df,\n",
    "        legend=False,\n",
    "        color=\"red\",\n",
    "        errorbar=None,\n",
    "    )\n",
    "    # directory = os.path.join(timeseries_folder, \"Grab Overall\")\n",
    "    # if not os.path.exists(directory):\n",
    "    #     os.makedirs(directory)\n",
    "    # plt.savefig(f\"{directory}/{sanitized_col}.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Case dell'Acqua - Overall Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Codes Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_code_df = pd.read_excel(house_codes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_code_df[\"Casa dell'acqua\"][7] = houses_code_df[\"Casa dell'acqua\"][\n",
    "    7\n",
    "].rstrip()\n",
    "\n",
    "houses_code_df.loc[4] = [\"Chiostergi\", \"HOUSE_CHIOSTERGI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_code_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Overall Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep just rows of raw_grab_samples_df that have a Codice punto di prelievo\n",
    "# that is contained in the houses_code_df Codice Punto di Prelievo\n",
    "grab_samples_df = raw_grab_samples_df.merge(\n",
    "    houses_code_df,\n",
    "    left_on=\"Codice punto di prelievo\",\n",
    "    right_on=\"Codice Punto di Prelievo\",\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "grab_samples_df.drop(\n",
    "    columns=[\"Casa dell'acqua\", \"Codice Punto di Prelievo\"], inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_samples_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN vs Strings vs Numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram = grab_samples_df[feature_columns + target_columns].apply(\n",
    "    count_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram.loc[\"Total\"] = histogram.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 20})\n",
    "\n",
    "ax = histogram.T[[\"NaN\", \"numbers\"]].plot.bar(figsize=(30, 10))\n",
    "plt.legend(edgecolor=\"black\")\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\n",
    "        str(int(p.get_height())),\n",
    "        (p.get_x() + p.get_width() / 2, p.get_height() * 1.02),\n",
    "        ha=\"center\",  # horizontal alignment is center\n",
    "    )\n",
    "\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(), rotation=45, horizontalalignment=\"right\", fontsize=25\n",
    ")\n",
    "for label in ax.get_xticklabels():\n",
    "    label.set_color(\"green\" if label.get_text() in feature_columns else \"grey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Distributions Divergence to Exploit More Data (All vs Selected Overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# TODO da rivedere, non biosgna usare gli stessi dati in entrambe le distribuzioni\n",
    "# Initialize a dictionary to store the KL divergence for each feature\n",
    "\n",
    "\n",
    "kl_divergences = {}\n",
    "js_divergences = {}\n",
    "tv_distances = {}\n",
    "w_distances = {}\n",
    "\n",
    "# For each feature in the DataFrame\n",
    "for feature in columns:\n",
    "    # # Compute the probability distribution of the feature in each DataFrame\n",
    "    # pdist_raw = np.histogram(raw_grab_samples_df[feature].dropna(), bins=100, density=True)[0]\n",
    "    # pdist_grab = np.histogram(grab_samples_df[feature].dropna(), bins=100, density=True)[0]\n",
    "\n",
    "    # # Add a small constant to avoid division by zero\n",
    "    # pdist_raw = pdist_raw + np.finfo(np.float64).eps\n",
    "    # pdist_grab = pdist_grab + np.finfo(np.float64).eps\n",
    "\n",
    "    if (\n",
    "        raw_grab_samples_df[feature].dropna().empty\n",
    "        or grab_samples_df[feature].dropna().empty\n",
    "        or len(grab_samples_df[feature].dropna().unique()) == 1\n",
    "    ):\n",
    "        continue\n",
    "\n",
    "    kde_raw = gaussian_kde(raw_grab_samples_df[feature].dropna())\n",
    "    kde_grab = gaussian_kde(grab_samples_df[feature].dropna())\n",
    "\n",
    "    # Evaluate the KDEs on a range of values\n",
    "    x = np.linspace(\n",
    "        min(raw_grab_samples_df[feature].min(), grab_samples_df[feature].min()),\n",
    "        max(raw_grab_samples_df[feature].max(), grab_samples_df[feature].max()),\n",
    "        100,\n",
    "    )\n",
    "    try:\n",
    "        pdist_raw = kde_raw(x)\n",
    "        pdist_grab = kde_grab(x)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    pdist_raw = kde_raw(x)\n",
    "    pdist_grab = kde_grab(x)\n",
    "\n",
    "    # Compute the KL divergence and store it in the dictionary\n",
    "    kl_divergences[feature] = stats.entropy(pdist_raw, pdist_grab)\n",
    "    js_divergences[feature] = jensenshannon(pdist_raw, pdist_grab)\n",
    "    tv_distances[feature] = np.sum(np.abs(pdist_raw - pdist_grab)) / 2\n",
    "    w_distances[feature] = wasserstein_distance(pdist_raw, pdist_grab)\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "kl_divergences_df = pd.DataFrame.from_dict(\n",
    "    kl_divergences, orient=\"index\", columns=[\"KL Divergence\"]\n",
    ")\n",
    "js_divergences_df = pd.DataFrame.from_dict(\n",
    "    js_divergences, orient=\"index\", columns=[\"JS Divergence\"]\n",
    ")\n",
    "tv_distances_df = pd.DataFrame.from_dict(\n",
    "    tv_distances, orient=\"index\", columns=[\"TV Distance\"]\n",
    ")\n",
    "w_distances_df = pd.DataFrame.from_dict(\n",
    "    w_distances, orient=\"index\", columns=[\"Wasserstein Distance\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kl_divergences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# js_divergences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tv_distances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_distances_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Between Case dell'Acqua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_columns = [\n",
    "    \"Concentr. ioni idrogeno al prelievo (unità pH)\",\n",
    "    \"Temperatura (°C)\",\n",
    "    \"TOC - carbonio organico totale (mg/L di C)\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = AffinityPropagation(affinity=\"precomputed\")\n",
    "\n",
    "# List of unique house codes\n",
    "house_codes = grab_samples_df[\"Codice punto di prelievo\"].unique()\n",
    "\n",
    "# Compute the affinity matrix\n",
    "for feature in similarity_columns:\n",
    "    affinity_matrix = np.zeros((len(house_codes), len(house_codes)))\n",
    "    for i, house1 in enumerate(house_codes):\n",
    "        for j, house2 in enumerate(house_codes):\n",
    "            if house1 == house2:\n",
    "                continue\n",
    "            affinity_matrix[i, j] = wasserstein_distance(\n",
    "                grab_samples_df[\n",
    "                    grab_samples_df[\"Codice punto di prelievo\"] == house1\n",
    "                ][feature].dropna(),\n",
    "                grab_samples_df[\n",
    "                    grab_samples_df[\"Codice punto di prelievo\"] == house2\n",
    "                ][feature].dropna(),\n",
    "            )\n",
    "\n",
    "    # normalize the affinity matrix to have similarity values between 0 and 1\n",
    "    affinity_matrix = 1 - (affinity_matrix - affinity_matrix.min()) / (\n",
    "        affinity_matrix.max() - affinity_matrix.min()\n",
    "    )\n",
    "\n",
    "    prop.fit(affinity_matrix)\n",
    "\n",
    "    print(f\"Feature: {feature}\")\n",
    "    print(f\"Number of clusters: {len(prop.cluster_centers_indices_)}\")\n",
    "\n",
    "    # Print cluster centers\n",
    "    print(\"Cluster centers:\")\n",
    "    for center_index in prop.cluster_centers_indices_:\n",
    "        print(house_codes[center_index])\n",
    "\n",
    "    # Print houses in each cluster\n",
    "    for cluster_id in range(len(prop.cluster_centers_indices_)):\n",
    "        print(f\"Cluster {cluster_id}:\")\n",
    "        for i, label in enumerate(prop.labels_):\n",
    "            if label == cluster_id:\n",
    "                print(house_codes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Case dell'Acqua - One by One Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN vs Strings vs Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in grab_samples_df[\"Codice punto di prelievo\"].unique():\n",
    "    histogram = grab_samples_df[\n",
    "        grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "    ][feature_columns + target_columns].apply(count_values)\n",
    "    histogram.loc[\"Total\"] = histogram.sum()\n",
    "    ax = histogram.T[[\"NaN\", \"numbers\"]].plot.bar(figsize=(30, 10))\n",
    "    ax.set_title(code)\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(\n",
    "            str(int(p.get_height())),\n",
    "            (p.get_x() + p.get_width() / 2, p.get_height() * 1.02),\n",
    "            ha=\"center\",  # horizontal alignment is center\n",
    "        )\n",
    "\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_color(\n",
    "            \"green\" if label.get_text() in feature_columns else \"grey\"\n",
    "        )\n",
    "\n",
    "    directory = os.path.join(NaNvsNumber_folder, \"Grab by House\")\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    plt.savefig(\n",
    "        os.path.join(\n",
    "            directory,\n",
    "            sanitize_filename(code) + \".png\",\n",
    "        ),\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.rcParams.update({\"font.size\": 20})\n",
    "\n",
    "for code in grab_samples_df[\"Codice punto di prelievo\"].unique():\n",
    "    for column in feature_columns + target_columns:\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        hist = grab_samples_df[\n",
    "            grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "        ][column].where(\n",
    "            grab_samples_df[\n",
    "                grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "            ][column].apply(lambda x: isinstance(x, (int, float)))\n",
    "        )\n",
    "        count, bins, patches = plt.hist(\n",
    "            hist.dropna(), bins=30, edgecolor=\"black\", linewidth=1.2\n",
    "        )\n",
    "        plt.title(\n",
    "            code\n",
    "            + \" - \"\n",
    "            + column\n",
    "            + \" - Count: \"\n",
    "            + str(hist.count())\n",
    "            + \" / \"\n",
    "            + str(\n",
    "                grab_samples_df[\n",
    "                    grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "                ].shape[0]\n",
    "            )\n",
    "        )\n",
    "        plt.ylabel(\"Frequency\")\n",
    "\n",
    "        # Set x-ticks to bin edges and x-tick labels to intervals\n",
    "        plt.xticks(\n",
    "            bins[:-1],\n",
    "            [f\"{bins[i]:.2f}-{bins[i+1]:.2f}\" for i in range(len(bins) - 1)],\n",
    "            rotation=\"vertical\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "\n",
    "        for p in patches:\n",
    "            plt.annotate(\n",
    "                str(int(p.get_height())),\n",
    "                (p.get_x() + p.get_width() / 2, p.get_height() * 1.02),\n",
    "                ha=\"center\",  # horizontal alignment is center\n",
    "            )\n",
    "\n",
    "        directory = os.path.join(histograms_folder, \"Grab by House\", code)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        plt.savefig(\n",
    "            os.path.join(\n",
    "                directory,\n",
    "                sanitize_filename(column) + \".png\",\n",
    "            ),\n",
    "            dpi=300,\n",
    "        )\n",
    "\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 14})\n",
    "\n",
    "for punto in grab_samples_df[\"Codice punto di prelievo\"].unique():\n",
    "    for col in feature_columns + target_columns:\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        sns.lineplot(\n",
    "            x=\"Data di prelievo\",\n",
    "            y=col,\n",
    "            data=grab_samples_df[\n",
    "                grab_samples_df[\"Codice punto di prelievo\"] == punto\n",
    "            ],\n",
    "            legend=False,\n",
    "            color=\"red\",\n",
    "            ax=plt.gca(),\n",
    "        )\n",
    "        # directory = os.path.join(timeseries_folder, \"Grab by House\", punto)\n",
    "        # if not os.path.exists(directory):\n",
    "        #     os.makedirs(directory)\n",
    "        # filename = sanitize_filename(f\"{col}.png\")\n",
    "        # plt.savefig(os.path.join(directory, filename), dpi=300)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Distributions Divergence to Exploit More Data (All vs Selected One by One)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# TODO da rivedere, non biosgna usare gli stessi dati in entrambe le distribuzioni\n",
    "\n",
    "kl_divergences = {}\n",
    "js_divergences = {}\n",
    "tv_distances = {}\n",
    "w_distances = {}\n",
    "\n",
    "\n",
    "codes = grab_samples_df[\"Codice punto di prelievo\"].unique()\n",
    "\n",
    "for code in codes:\n",
    "    kl_divergences[code] = {}\n",
    "    js_divergences[code] = {}\n",
    "    tv_distances[code] = {}\n",
    "    w_distances[code] = {}\n",
    "\n",
    "    for feature in columns:\n",
    "        # # Compute the probability distribution of the feature in each DataFrame\n",
    "        # pdist_raw = np.histogram(raw_grab_samples_df[feature].dropna(), bins=100, density=True)[0]\n",
    "        # pdist_grab = np.histogram(grab_samples_df[feature].dropna(), bins=100, density=True)[0]\n",
    "\n",
    "        # # Add a small constant to avoid division by zero\n",
    "        # pdist_raw = pdist_raw + np.finfo(np.float64).eps\n",
    "        # pdist_grab = pdist_grab + np.finfo(np.float64).eps\n",
    "\n",
    "        if (\n",
    "            raw_grab_samples_df[feature].dropna().empty\n",
    "            or grab_samples_df[\n",
    "                grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "            ][feature]\n",
    "            .dropna()\n",
    "            .empty\n",
    "            or len(\n",
    "                grab_samples_df[\n",
    "                    grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "                ][feature]\n",
    "                .dropna()\n",
    "                .unique()\n",
    "            )\n",
    "            == 1\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        kde_raw = gaussian_kde(raw_grab_samples_df[feature].dropna())\n",
    "        kde_grab = gaussian_kde(\n",
    "            grab_samples_df[\n",
    "                grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "            ][feature].dropna()\n",
    "        )\n",
    "\n",
    "        # Evaluate the KDEs on a range of values\n",
    "        x = np.linspace(\n",
    "            min(\n",
    "                raw_grab_samples_df[feature].min(),\n",
    "                grab_samples_df[\n",
    "                    grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "                ][feature].min(),\n",
    "            ),\n",
    "            max(\n",
    "                raw_grab_samples_df[feature].max(),\n",
    "                grab_samples_df[\n",
    "                    grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "                ][feature].max(),\n",
    "            ),\n",
    "            100,\n",
    "        )\n",
    "        pdist_raw = kde_raw(x)\n",
    "        pdist_grab = kde_grab(x)\n",
    "\n",
    "        # Compute the KL divergence and store it in the dictionary\n",
    "        kl_divergences[code][feature] = stats.entropy(pdist_raw, pdist_grab)\n",
    "        js_divergences[code][feature] = jensenshannon(pdist_raw, pdist_grab)\n",
    "        tv_distances[code][feature] = np.sum(np.abs(pdist_raw - pdist_grab)) / 2\n",
    "        w_distances[code][feature] = wasserstein_distance(pdist_raw, pdist_grab)\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "kl_divergences_df = pd.DataFrame.from_dict(kl_divergences, orient=\"index\")\n",
    "js_divergences_df = pd.DataFrame.from_dict(js_divergences, orient=\"index\")\n",
    "tv_distances_df = pd.DataFrame.from_dict(tv_distances, orient=\"index\")\n",
    "w_distances_df = pd.DataFrame.from_dict(w_distances, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kl_divergences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# js_divergences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tv_distances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_distances_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save wasserstein distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_distances_df.to_excel(\n",
    "#     \"/Users/massimilianoarca/Documents/PoliMi/Research Grant/SafeCREW/Data/Milano/wasserstein_distances.xlsx\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Range for each Supply Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = {}\n",
    "\n",
    "\n",
    "codes = grab_samples_df[\"Codice punto di prelievo\"].unique()\n",
    "\n",
    "for code in codes:\n",
    "    time_range[code] = {}\n",
    "\n",
    "    for feature in feature_columns + target_columns:\n",
    "        # # Compute the probability distribution of the feature in each DataFrame\n",
    "        # pdist_raw = np.histogram(raw_grab_samples_df[feature].dropna(), bins=100, density=True)[0]\n",
    "        # pdist_grab = np.histogram(grab_samples_df[feature].dropna(), bins=100, density=True)[0]\n",
    "\n",
    "        # # Add a small constant to avoid division by zero\n",
    "        # pdist_raw = pdist_raw + np.finfo(np.float64).eps\n",
    "        # pdist_grab = pdist_grab + np.finfo(np.float64).eps\n",
    "\n",
    "        temp_df = grab_samples_df[\n",
    "            grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "        ][[\"Data di prelievo\", feature]]\n",
    "        temp_df.dropna(inplace=True)\n",
    "\n",
    "        min_time = temp_df[\"Data di prelievo\"].min()\n",
    "        max_time = temp_df[\"Data di prelievo\"].max()\n",
    "        length = temp_df.shape[0]\n",
    "\n",
    "        time_range[code][feature] = {\n",
    "            \"start_time\": min_time,\n",
    "            \"end_time\": max_time,\n",
    "            \"n_samples\": length,\n",
    "        }\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "time_range_df = pd.DataFrame.from_dict(time_range, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensor Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for file in os.listdir(sensor_data_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        temp_df = pd.read_csv(\n",
    "            os.path.join(sensor_data_folder, file), header=1, sep=\";\"\n",
    "        )\n",
    "        location_name = file.split(\"_\")[0]\n",
    "        temp_df.insert(0, \"Location\", location_name)\n",
    "        code = houses_code_df[\n",
    "            houses_code_df[\"Casa dell'acqua\"] == location_name\n",
    "        ][\"Codice Punto di Prelievo\"].values[0]\n",
    "        temp_df.insert(1, \"Codice Punto di Prelievo\", code)\n",
    "        df_list.append(temp_df)\n",
    "\n",
    "raw_sensor_data_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sensor_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get columns that do not contain the string 'Status'\n",
    "sensor_columns = raw_sensor_data_df.columns[\n",
    "    ~raw_sensor_data_df.columns.str.contains(\"Status\")\n",
    "]\n",
    "sensor_columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN vs Strings vs Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in raw_sensor_data_df[\"Codice Punto di Prelievo\"].unique():\n",
    "    histogram = raw_sensor_data_df[\n",
    "        raw_sensor_data_df[\"Codice Punto di Prelievo\"] == code\n",
    "    ][sensor_columns.to_list()[4:]].apply(count_values)\n",
    "    histogram.loc[\"Total\"] = histogram.sum()\n",
    "    ax = histogram.T[[\"NaN\", \"numbers\"]].plot.bar(figsize=(30, 10))\n",
    "    ax.set_title(code)\n",
    "\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(\n",
    "            str(int(p.get_height())),\n",
    "            (p.get_x() + p.get_width() / 2, p.get_height() * 1.02),\n",
    "            ha=\"center\",  # horizontal alignment is center\n",
    "        )\n",
    "\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_color(\n",
    "            \"green\" if label.get_text() in feature_columns else \"grey\"\n",
    "        )\n",
    "\n",
    "    directory = os.path.join(NaNvsNumber_folder, \"Sensor by House\")\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    plt.savefig(\n",
    "        os.path.join(\n",
    "            directory,\n",
    "            sanitize_filename(code) + \".png\",\n",
    "        ),\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histrogram Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "for code in raw_sensor_data_df[\"Codice Punto di Prelievo\"].unique():\n",
    "    for column in sensor_columns.to_list()[4:]:\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        hist = raw_sensor_data_df[\n",
    "            raw_sensor_data_df[\"Codice Punto di Prelievo\"] == code\n",
    "        ][column].where(\n",
    "            raw_sensor_data_df[\n",
    "                raw_sensor_data_df[\"Codice Punto di Prelievo\"] == code\n",
    "            ][column].apply(lambda x: isinstance(x, (int, float)))\n",
    "        )\n",
    "        count, bins, patches = plt.hist(\n",
    "            hist.dropna(), bins=30, edgecolor=\"black\", linewidth=1.2\n",
    "        )\n",
    "        plt.title(\n",
    "            code\n",
    "            + \" - \"\n",
    "            + column\n",
    "            + \" - Count: \"\n",
    "            + str(hist.count())\n",
    "            + \" / \"\n",
    "            + str(\n",
    "                raw_sensor_data_df[\n",
    "                    raw_sensor_data_df[\"Codice Punto di Prelievo\"] == code\n",
    "                ].shape[0]\n",
    "            )\n",
    "        )\n",
    "        plt.ylabel(\"Frequency\")\n",
    "\n",
    "        # Set x-ticks to bin edges and x-tick labels to intervals\n",
    "        plt.xticks(\n",
    "            bins[:-1],\n",
    "            [f\"{bins[i]:.2f}-{bins[i+1]:.2f}\" for i in range(len(bins) - 1)],\n",
    "            rotation=\"vertical\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "\n",
    "        # Add count for every bar\n",
    "        for p in patches:\n",
    "            plt.annotate(\n",
    "                str(int(p.get_height())),\n",
    "                (p.get_x() + p.get_width() / 2, p.get_height() * 1.02),\n",
    "                ha=\"center\",  # horizontal alignment is center\n",
    "            )\n",
    "\n",
    "        directory = os.path.join(histograms_folder, \"Sensor by House\", code)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        plt.savefig(\n",
    "            os.path.join(\n",
    "                directory,\n",
    "                sanitize_filename(column) + \".png\",\n",
    "            ),\n",
    "            dpi=300,\n",
    "        )\n",
    "\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "# group by codice punto di prelievo and plot every column\n",
    "for punto in raw_sensor_data_df[\"Codice Punto di Prelievo\"].unique():\n",
    "    for col in raw_sensor_data_df.columns:\n",
    "        # check if column belongs to float type\n",
    "        if raw_sensor_data_df[col].dtype == float:\n",
    "            sanitized_col = col.split(\"-\")[0].rstrip()\n",
    "            # Extract unit of measure from column name\n",
    "            unit_of_measure = (\n",
    "                col.split(\"[\")[1].split(\"]\")[0] if \"[\" in col else \"\"\n",
    "            )\n",
    "            raw_sensor_data_df[\n",
    "                raw_sensor_data_df[\"Codice Punto di Prelievo\"] == punto\n",
    "            ].plot(\n",
    "                x=\"Measurement interval=900[sec] (Export-Aggregation disabled)\",\n",
    "                y=col,\n",
    "                legend=False,\n",
    "                title=f\"{punto} - {sanitized_col} [{unit_of_measure}]\",\n",
    "                fontsize=8,\n",
    "                figsize=(40, 10),\n",
    "            )\n",
    "            directory = os.path.join(\n",
    "                timeseries_folder, \"Sensor by House\", punto\n",
    "            )\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            plt.savefig(f\"{directory}/{sanitized_col}.png\", dpi=300)\n",
    "\n",
    "            # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Grab and Sensor samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_df = raw_sensor_data_df.copy()\n",
    "grab_df = grab_samples_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to float all the feature and target columns of grab_df\n",
    "for col in feature_columns + target_columns:\n",
    "    grab_df[col] = grab_df[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_columns = grab_df.columns[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_df[\n",
    "    \"Measurement interval=900[sec] (Export-Aggregation disabled)\"\n",
    "] = pd.to_datetime(\n",
    "    sensor_df[\"Measurement interval=900[sec] (Export-Aggregation disabled)\"],\n",
    "    format=\"%d/%m/%Y %H:%M\",\n",
    ")\n",
    "grab_df[\"Data di prelievo\"] = pd.to_datetime(\n",
    "    grab_df[\"Data di prelievo\"], format=\"%Y-%m-%d\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Common Columns between the two dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For the moment the common columns are taken manually\n",
    "\"\"\"\n",
    "\n",
    "column_mapping = {\n",
    "    \"Data di prelievo\": \"Measurement interval=900[sec] (Export-Aggregation disabled)\",\n",
    "    # \"Colore (CU)\": \"COLORtrue - Measured value [Hazen-eq.] (Limit:0.00-300.00)\",\n",
    "    \"TOC - carbonio organico totale (mg/L di C)\": \"TOCeq - Measured value [mg/l] (Limit:0.00-22.00)\",\n",
    "    # \"Conduttività a 20°C (µS/cm)\": \"Conductivity - Measured value [uS/cm] (Limit:0.10-600000.00)\",\n",
    "    # \"Cloro residuo libero (mg/L di Cl2)\": \"Free Chlorine - Measured value [mg/l] (Limit:0.00-2.00)\",\n",
    "    \"Concentr. ioni idrogeno al prelievo (unità pH)\": \"pH - Measured value (Limit:0.00-14.00)\",\n",
    "    \"Temperatura (°C)\": \"Temperature - Measured value [C] (Limit:-5.00-100.00)\",\n",
    "    \"Codice punto di prelievo\": \"Codice Punto di Prelievo\",\n",
    "}\n",
    "\n",
    "inverse_column_mapping = {v: k for k, v in column_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_features = list(column_mapping.keys())[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count of each common feature for each Supply Point grab and sensor samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_count = pd.DataFrame()\n",
    "\n",
    "for code in grab_df[\"Codice punto di prelievo\"].unique():\n",
    "    for grab_col, sensor_col in list(column_mapping.items())[1:-1]:\n",
    "        if (grab_col, \"Grab\") not in table_count.columns:\n",
    "            table_count[(grab_col, \"Grab\")] = np.nan\n",
    "        if (grab_col, \"Sensor\") not in table_count.columns:\n",
    "            table_count[(grab_col, \"Sensor\")] = np.nan\n",
    "\n",
    "        grab_count = grab_df[grab_df[\"Codice punto di prelievo\"] == code][\n",
    "            grab_col\n",
    "        ].count()\n",
    "        sensor_count = sensor_df[sensor_df[\"Codice Punto di Prelievo\"] == code][\n",
    "            sensor_col\n",
    "        ].count()\n",
    "\n",
    "        table_count.loc[code, [(grab_col, \"Grab\")]] = grab_count\n",
    "        table_count.loc[code, [(grab_col, \"Sensor\")]] = sensor_count\n",
    "\n",
    "    tot_grab_count = grab_df[grab_df[\"Codice punto di prelievo\"] == code].shape[\n",
    "        0\n",
    "    ]\n",
    "    tot_sensor_count = sensor_df[\n",
    "        sensor_df[\"Codice Punto di Prelievo\"] == code\n",
    "    ].shape[0]\n",
    "\n",
    "    if (\"N Samples\", \"Grab\") not in table_count.columns:\n",
    "        table_count[(\"N Samples\", \"Grab\")] = np.nan\n",
    "    if (\"N Samples\", \"Sensor\") not in table_count.columns:\n",
    "        table_count[(\"N Samples\", \"Sensor\")] = np.nan\n",
    "\n",
    "    table_count.loc[code, [(\"N Samples\", \"Grab\")]] = tot_grab_count\n",
    "    table_count.loc[code, [(\"N Samples\", \"Sensor\")]] = tot_sensor_count\n",
    "\n",
    "\n",
    "# Convert the column index to a MultiIndex\n",
    "table_count.columns = pd.MultiIndex.from_tuples(\n",
    "    table_count.columns, names=[\"Parameter\", \"Source\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_count.to_excel(os.path.join(store_folder, \"table_count.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with grab_columns\n",
    "grabs = pd.DataFrame(data=grab_columns, columns=[\"grab_columns\"])\n",
    "\n",
    "# create dataframe with sensor_columns\n",
    "sensors = pd.DataFrame(data=sensor_columns, columns=[\"sensor_columns\"])\n",
    "\n",
    "grabs.to_excel(os.path.join(store_folder, \"grab_columns.xlsx\"))\n",
    "sensors.to_excel(os.path.join(store_folder, \"sensor_columns.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns = pd.DataFrame(\n",
    "    column_mapping.items(), columns=[\"Grab\", \"Sensor\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns.to_excel(os.path.join(store_folder, \"common_columns.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename sensor df columns with grab df columns\n",
    "\n",
    "sensor_df.rename(columns=inverse_column_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Tests and Distribution Distances for selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergences = {}\n",
    "js_divergences = {}\n",
    "tv_distances = {}\n",
    "w_distances = {}\n",
    "\n",
    "hypothesis_tests = {}\n",
    "\n",
    "\n",
    "codes = grab_df[\"Codice punto di prelievo\"].unique()\n",
    "\n",
    "for code in codes:\n",
    "    kl_divergences[code] = {}\n",
    "    js_divergences[code] = {}\n",
    "    tv_distances[code] = {}\n",
    "    w_distances[code] = {}\n",
    "\n",
    "    hypothesis_tests[code] = {}\n",
    "\n",
    "    code_grab_df = grab_df[grab_df[\"Codice punto di prelievo\"] == code]\n",
    "    code_sensor_df = sensor_df[sensor_df[\"Codice punto di prelievo\"] == code]\n",
    "\n",
    "    for feature in common_features:\n",
    "        # Compute the probability distribution of the feature in each DataFrame\n",
    "        pdist_grab = np.histogram(\n",
    "            code_grab_df[feature].dropna(), bins=100, density=True\n",
    "        )[0]\n",
    "        pdist_sensor = np.histogram(\n",
    "            code_sensor_df[feature].dropna(), bins=100, density=True\n",
    "        )[0]\n",
    "\n",
    "        # Add a small constant to avoid division by zero\n",
    "        pdist_grab = pdist_grab + np.finfo(np.float64).eps\n",
    "        pdist_sensor = pdist_sensor + np.finfo(np.float64).eps\n",
    "\n",
    "        \"\"\"if (\n",
    "            raw_grab_samples_df[feature].dropna().empty\n",
    "            or grab_samples_df[\n",
    "                grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "            ][feature]\n",
    "            .dropna()\n",
    "            .empty\n",
    "            or len(\n",
    "                grab_samples_df[\n",
    "                    grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "                ][feature]\n",
    "                .dropna()\n",
    "                .unique()\n",
    "            )\n",
    "            == 1\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        kde_raw = gaussian_kde(raw_grab_samples_df[feature].dropna())\n",
    "        kde_grab = gaussian_kde(\n",
    "            grab_samples_df[\n",
    "                grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "            ][feature].dropna()\n",
    "        )\n",
    "\n",
    "        # Evaluate the KDEs on a range of values\n",
    "        x = np.linspace(\n",
    "            min(\n",
    "                raw_grab_samples_df[feature].min(),\n",
    "                grab_samples_df[\n",
    "                    grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "                ][feature].min(),\n",
    "            ),\n",
    "            max(\n",
    "                raw_grab_samples_df[feature].max(),\n",
    "                grab_samples_df[\n",
    "                    grab_samples_df[\"Codice punto di prelievo\"] == code\n",
    "                ][feature].max(),\n",
    "            ),\n",
    "            100,\n",
    "        )\n",
    "        pdist_raw = kde_raw(x)\n",
    "        pdist_grab = kde_grab(x)\"\"\"\n",
    "\n",
    "        # Compute the distribution distances and store them in the dictionaries\n",
    "        kl_divergences[code][feature] = stats.entropy(pdist_sensor, pdist_grab)\n",
    "        js_divergences[code][feature] = jensenshannon(pdist_sensor, pdist_grab)\n",
    "        tv_distances[code][feature] = (\n",
    "            np.sum(np.abs(pdist_sensor - pdist_grab)) / 2\n",
    "        )\n",
    "        w_distances[code][feature] = wasserstein_distance(\n",
    "            pdist_sensor, pdist_grab\n",
    "        )\n",
    "\n",
    "        # Compute the hypothesis tests and store them in the dictionaries\n",
    "        try:\n",
    "            t_stat, p_value = stats.ttest_ind(\n",
    "                code_grab_df[feature].dropna(),\n",
    "                code_sensor_df[feature].dropna(),\n",
    "                equal_var=True,\n",
    "            )\n",
    "            hypothesis_tests[code][feature] = (t_stat, p_value)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        t_stat, p_value = stats.ttest_ind(\n",
    "            code_grab_df[feature].dropna(),\n",
    "            code_sensor_df[feature].dropna(),\n",
    "            equal_var=False,\n",
    "        )\n",
    "        hypothesis_tests[code][feature] = (t_stat, p_value)\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "kl_divergences_df = pd.DataFrame.from_dict(kl_divergences, orient=\"index\")\n",
    "js_divergences_df = pd.DataFrame.from_dict(js_divergences, orient=\"index\")\n",
    "tv_distances_df = pd.DataFrame.from_dict(tv_distances, orient=\"index\")\n",
    "w_distances_df = pd.DataFrame.from_dict(w_distances, orient=\"index\")\n",
    "\n",
    "\n",
    "hypothesis_tests_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (i, j): hypothesis_tests[i][j]\n",
    "        for i in hypothesis_tests.keys()\n",
    "        for j in hypothesis_tests[i].keys()\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")\n",
    "\n",
    "hypothesis_tests_df.index = pd.MultiIndex.from_tuples(\n",
    "    hypothesis_tests_df.index, names=[\"Code\", \"Feature\"]\n",
    ")\n",
    "hypothesis_tests_df.columns = [\"T-Statistic\", \"P-Value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_tests_df.to_excel(\n",
    "    os.path.join(store_folder, \"hypothesis_tests.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Timeseries Plots for each selected Supply Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "codes = grab_df[\"Codice punto di prelievo\"].unique()\n",
    "\n",
    "for code in codes:\n",
    "    code_grab_df = grab_df[grab_df[\"Codice punto di prelievo\"] == code]\n",
    "    code_sensor_df = sensor_df[sensor_df[\"Codice punto di prelievo\"] == code]\n",
    "\n",
    "    # print date range for each house\n",
    "    print(\n",
    "        f\"House {code} date range LAB: {code_grab_df['Data di prelievo'].min()} - {code_grab_df['Data di prelievo'].max()}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"House {code} date range SENSOR: {code_sensor_df['Data di prelievo'].min()} - {code_sensor_df['Data di prelievo'].max()}\"\n",
    "    )\n",
    "    print()\n",
    "    for column in common_features:\n",
    "        plt.figure(figsize=(40, 20))\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=code_sensor_df,\n",
    "            x=\"Data di prelievo\",\n",
    "            y=column,\n",
    "            color=\"red\",\n",
    "            errorbar=None,\n",
    "        )\n",
    "        sns.lineplot(\n",
    "            data=code_grab_df,\n",
    "            x=\"Data di prelievo\",\n",
    "            y=column,\n",
    "            color=\"blue\",\n",
    "            errorbar=None,\n",
    "        )\n",
    "        # sns.scatterplot(data=code_grab_df, x=\"Data di prelievo\", y=column, color=\"blue\", marker=\"x\")\n",
    "\n",
    "        plt.title(code, fontsize=20)\n",
    "        plt.xlabel(\"Time\", fontsize=20)\n",
    "        plt.ylabel(column, fontsize=20)\n",
    "\n",
    "        custom_lines = [\n",
    "            Line2D([0], [0], color=\"red\", lw=4),\n",
    "            Line2D([0], [0], color=\"blue\", lw=4),\n",
    "        ]\n",
    "        plt.legend(custom_lines, [\"Sensor\", \"Grab\"])\n",
    "\n",
    "        #     directory = os.path.join(\n",
    "        #         timeseries_folder, \"Grab vs Sensor by House\", code\n",
    "        #     )\n",
    "        #     if not os.path.exists(directory):\n",
    "        #         os.makedirs(directory)\n",
    "        #     filename = sanitize_filename(f\"{column}.png\")\n",
    "        #     # plt.savefig(os.path.join(directory, filename), dpi=300)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Boxplots for each selected Supply Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 12})\n",
    "\n",
    "fig, axs = plt.subplots(1, len(common_features), figsize=(20, 10))\n",
    "\n",
    "for column in common_features:\n",
    "    # boxplot of grab and sensor data\n",
    "    grab = deepcopy(grab_df[column])\n",
    "    sensor = deepcopy(sensor_df[column])\n",
    "\n",
    "    # rename columns\n",
    "    grab.name = \"Grab\"\n",
    "    sensor.name = \"Sensor\"\n",
    "\n",
    "    if column == \"TOC - carbonio organico totale (mg/L di C)\":\n",
    "        sensor = sensor[sensor < 10]\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=[grab, sensor],\n",
    "        palette=\"Set3\",\n",
    "        ax=axs[common_features.index(column)],\n",
    "    )\n",
    "\n",
    "    if column == \"TOC - carbonio organico totale (mg/L di C)\":\n",
    "        axs[common_features.index(column)].set_title(\"TOC\")\n",
    "\n",
    "    elif column == \"Concentr. ioni idrogeno al prelievo (unità pH)\":\n",
    "        axs[common_features.index(column)].set_title(\"pH\")\n",
    "\n",
    "    else:\n",
    "        axs[common_features.index(column)].set_title(\"Water Temperature\")\n",
    "\n",
    "    # directory = os.path.join(\n",
    "    #     boxplot_folder, \"Grab vs Sensor by House\", code\n",
    "    # )\n",
    "    # if not os.path.exists(directory):\n",
    "    #     os.makedirs(directory)\n",
    "    # filename = sanitize_filename(f\"{column}.png\")\n",
    "    # plt.savefig(os.path.join(directory, filename), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a table for each index summarizing the time_range_df by showing the number of samples, the start time and the end time for each feature in each house\n",
    "for code in raw_sensor_data_df[\"Codice Punto di Prelievo\"].unique():\n",
    "    with pd.ExcelWriter(\n",
    "        os.path.join(metadata_folder, f\"{code}.xlsx\")\n",
    "    ) as writer:\n",
    "        df = pd.DataFrame()\n",
    "        for column in list(column_mapping.keys())[1:-1]:\n",
    "            row = time_range_df.loc[code, column]\n",
    "            if isinstance(row, dict):\n",
    "                temp_df = pd.DataFrame(\n",
    "                    index=list(row.keys()),\n",
    "                    data=list(row.values()),\n",
    "                    columns=[column],\n",
    "                )\n",
    "                df = pd.concat([df, temp_df], axis=1)\n",
    "                # df.to_excel(writer, sheet_name=sanitize_filename(column))\n",
    "            else:\n",
    "                continue\n",
    "        min_time = pd.to_datetime(\n",
    "            raw_sensor_data_df[\n",
    "                raw_sensor_data_df[\"Codice Punto di Prelievo\"] == code\n",
    "            ][\"Measurement interval=900[sec] (Export-Aggregation disabled)\"],\n",
    "            format=\"%d/%m/%Y %H:%M\",\n",
    "            dayfirst=True,\n",
    "        ).min()\n",
    "        max_time = pd.to_datetime(\n",
    "            raw_sensor_data_df[\n",
    "                raw_sensor_data_df[\"Codice Punto di Prelievo\"] == code\n",
    "            ][\"Measurement interval=900[sec] (Export-Aggregation disabled)\"],\n",
    "            format=\"%d/%m/%Y %H:%M\",\n",
    "            dayfirst=True,\n",
    "        ).max()\n",
    "        sens_df = pd.DataFrame(\n",
    "            index=[\"start_time\", \"end_time\"],\n",
    "            data=[min_time, max_time],\n",
    "            columns=[\"sensor\"],\n",
    "        )\n",
    "        df = pd.concat([df, sens_df], axis=1)\n",
    "        df.to_excel(writer, sheet_name=code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common time interval between sensor and grab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in codes:\n",
    "    code_grab_df = grab_df[grab_df[\"Codice punto di prelievo\"] == code]\n",
    "    code_sensor_df = sensor_df[sensor_df[\"Codice punto di prelievo\"] == code]\n",
    "\n",
    "    print(f\"==== {code} ====\")\n",
    "    print(\n",
    "        \"Sensor: \"\n",
    "        + str(code_sensor_df[\"Data di prelievo\"].min())\n",
    "        + \" - \"\n",
    "        + str(code_sensor_df[\"Data di prelievo\"].max())\n",
    "    )\n",
    "    print(\n",
    "        \"Grab: \"\n",
    "        + str(code_grab_df[\"Data di prelievo\"].min())\n",
    "        + \" - \"\n",
    "        + str(code_grab_df[\"Data di prelievo\"].max())\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    if code == \"HOUSE_CERMENATE\":\n",
    "        pass\n",
    "\n",
    "    # get samples that are in the common time range\n",
    "    grab_time_range_df = code_grab_df[\n",
    "        (\n",
    "            code_grab_df[\"Data di prelievo\"]\n",
    "            >= code_sensor_df[\"Data di prelievo\"].min()\n",
    "        )\n",
    "        & (\n",
    "            code_grab_df[\"Data di prelievo\"]\n",
    "            <= code_sensor_df[\"Data di prelievo\"].max()\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    sensor_time_range_df = code_sensor_df[\n",
    "        (\n",
    "            code_sensor_df[\"Data di prelievo\"]\n",
    "            >= code_grab_df[\"Data di prelievo\"].min()\n",
    "        )\n",
    "        & (\n",
    "            code_sensor_df[\"Data di prelievo\"]\n",
    "            <= code_grab_df[\"Data di prelievo\"].max()\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # plot the samples in the common time range for each feature with different colors\n",
    "    # for column in common_features:\n",
    "    # plt.figure(figsize=(40, 10))\n",
    "\n",
    "    # sns.lineplot(\n",
    "    #     data=sensor_time_range_df,\n",
    "    #     x=\"Data di prelievo\",\n",
    "    #     y=column,\n",
    "    #     color=\"red\",\n",
    "    #     errorbar=None,\n",
    "    # )\n",
    "\n",
    "    # sns.lineplot(\n",
    "    #     data=grab_time_range_df,\n",
    "    #     x=\"Data di prelievo\",\n",
    "    #     y=column,\n",
    "    #     color=\"blue\",\n",
    "    #     errorbar=None,\n",
    "    # )\n",
    "\n",
    "    # sns.scatterplot(\n",
    "    #     data=grab_time_range_df,\n",
    "    #     x=\"Data di prelievo\",\n",
    "    #     y=column,\n",
    "    #     color=\"blue\",\n",
    "    # )\n",
    "\n",
    "    # plt.title(code, fontsize=20)\n",
    "    # plt.xlabel(\"Time\", fontsize=20)\n",
    "    # plt.ylabel(column, fontsize=20)\n",
    "\n",
    "    # custom_lines = [\n",
    "    #     Line2D([0], [0], color=\"red\", lw=4),\n",
    "    #     Line2D([0], [0], color=\"blue\", lw=4),\n",
    "    # ]\n",
    "    # plt.legend(custom_lines, [\"Sensor\", \"Grab\"])\n",
    "\n",
    "    # directory = os.path.join(timeseries_folder, \"Common Time Range\", code)\n",
    "    # if not os.path.exists(directory):\n",
    "    #     os.makedirs(directory)\n",
    "    # filename = sanitize_filename(f\"{column}.png\")\n",
    "    # plt.savefig(os.path.join(directory, filename), dpi=300)\n",
    "    # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safecrew-3OLHM_8n-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
