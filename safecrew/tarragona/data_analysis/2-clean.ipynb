{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Sensor and Lab samples Clean Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "from utils.functions.normalize_string import normalize_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(\"..\", \"data\")\n",
    "utils_folder = os.path.join(\"..\", \"utils\")\n",
    "\n",
    "clean_data_folder = os.path.join(data_folder, \"Clean Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_lab_df = pd.read_excel(\n",
    "    os.path.join(clean_data_folder, \"EB0_Features_Lab.xlsx\")\n",
    ")\n",
    "\n",
    "eb0_targets_lab_df = pd.read_excel(\n",
    "    os.path.join(clean_data_folder, \"EB0_Targets_Lab.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df = pd.read_excel(\n",
    "    os.path.join(clean_data_folder, \"EB1_Features_Lab.xlsx\")\n",
    ")\n",
    "\n",
    "eb1_targets_lab_df = pd.read_excel(\n",
    "    os.path.join(clean_data_folder, \"EB1_Targets_Lab.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_sensor_df = pd.read_excel(\n",
    "    os.path.join(clean_data_folder, \"EB0_Sensor.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_sensor_df = pd.read_excel(\n",
    "    os.path.join(clean_data_folder, \"EB1_Sensor.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thms_df = pd.read_excel(os.path.join(clean_data_folder, \"THMs.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO change json names in 1-intermediate.ipynb and in the mappings folder in utils\n",
    "# import feature mappings\n",
    "with open(\n",
    "    os.path.join(utils_folder, \"mappings\", \"eb0_features_mapping.json\")\n",
    ") as f:\n",
    "    eb0_features_mapping = json.load(f)\n",
    "\n",
    "with open(\n",
    "    os.path.join(utils_folder, \"mappings\", \"eb1_features_mapping.json\")\n",
    ") as f:\n",
    "    eb1_features_mapping = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_sensor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab vs Sensor Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_lab_df.columns = [\n",
    "    normalize_string(c) for c in eb0_features_lab_df.columns\n",
    "]\n",
    "\n",
    "eb0_features_mapping = {\n",
    "    normalize_string(k): v for k, v in eb0_features_mapping.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab_key, sensor_key in eb0_features_mapping.items():\n",
    "    lab_key = normalize_string(lab_key)\n",
    "    if lab_key in eb0_features_lab_df.columns:\n",
    "        lab_df = eb0_features_lab_df[lab_key]\n",
    "        sensor_df = eb0_sensor_df[sensor_key]\n",
    "\n",
    "        # remove 0 values from sensor data\n",
    "        # sensor_df = sensor_df[sensor_df != 0]\n",
    "\n",
    "        if not lab_df.empty and not sensor_df.empty:\n",
    "            plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "            sns.histplot(\n",
    "                data=sensor_df,\n",
    "                kde=True,\n",
    "                bins=100,\n",
    "                alpha=0.5,\n",
    "                stat=\"probability\",\n",
    "                label=\"Sensor Data\",\n",
    "            )\n",
    "\n",
    "            sns.histplot(\n",
    "                data=lab_df,\n",
    "                kde=True,\n",
    "                bins=100,\n",
    "                stat=\"probability\",\n",
    "                label=\"Lab Data\",\n",
    "            )\n",
    "\n",
    "            plt.title(lab_key)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            # The y-axis of a histplot with stat=\"probability\" corresponds\n",
    "            # to the probability that a value belongs to a certain bar.\n",
    "            # The sum of the bar heights must be 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab_key, sensor_key in eb0_features_mapping.items():\n",
    "    lab_key = normalize_string(lab_key)\n",
    "    if lab_key in eb0_features_lab_df.columns:\n",
    "        lab_df = eb0_features_lab_df[lab_key]\n",
    "        sensor_df = eb0_sensor_df[sensor_key]\n",
    "\n",
    "        # remove 0 values from sensor data\n",
    "        sensor_df = sensor_df[sensor_df != 0]\n",
    "\n",
    "        if not lab_df.empty and not sensor_df.empty:\n",
    "            plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "            sns.boxplot(data=[lab_df, sensor_df], palette=\"Set3\")\n",
    "\n",
    "            plt.title(lab_key)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab_key, sensor_key in eb0_features_mapping.items():\n",
    "    lab_key = normalize_string(lab_key)\n",
    "    if lab_key in eb0_features_lab_df.columns:\n",
    "        lab_df = eb0_features_lab_df[[\"DateTime\", lab_key]]\n",
    "        sensor_df = eb0_sensor_df[[\"DateTime\", sensor_key]]\n",
    "\n",
    "        # remove 0 values from sensor data\n",
    "        sensor_df = sensor_df[sensor_df != 0]\n",
    "\n",
    "        if not lab_df.empty and not sensor_df.empty:\n",
    "            plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"DateTime\",\n",
    "                y=lab_key,\n",
    "                data=lab_df,\n",
    "                color=\"blue\",\n",
    "                label=\"Lab Data\",\n",
    "            )\n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"DateTime\",\n",
    "                y=sensor_key,\n",
    "                data=sensor_df,\n",
    "                color=\"red\",\n",
    "                label=\"Sensor Data\",\n",
    "            )\n",
    "\n",
    "            plt.title(lab_key)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Common Time Range data + Hypothesis Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MAPE function\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb0_features_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 30})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_hypothesis_tests = {}\n",
    "t_hypothesis_tests = {}\n",
    "u_hypothesis_tests = {}\n",
    "\n",
    "mapes = {}\n",
    "\n",
    "mapping = {\n",
    "    'Color': 'Color (mg Pt-Co/L)',\n",
    "    'Conductivitat a 20oC': 'Conductivity (µS/cm)',\n",
    "    f\"{list(eb0_features_mapping.keys())[2]}\": 'Most Abundant Particle Size (part/mL)',\n",
    "    'pH': 'pH',\n",
    "    'Mercuri': 'Mercury (µg/L)',\n",
    "    'Sulfats': 'Sulfates (mg/L)',\n",
    "    'Temperatura': 'Temperature (°C)',\n",
    "    'Terbolesa': 'Turbidity (NTU)',\n",
    "    f\"{list(eb0_features_mapping.keys())[-1]}\": 'UVA254 (Abs/m)',\n",
    "    \n",
    "}\n",
    "\n",
    "# get common time range samples for lab and sensor data\n",
    "for lab_key, sensor_key in eb0_features_mapping.items():\n",
    "    lab_key = normalize_string(lab_key)\n",
    "    if lab_key in eb0_features_lab_df.columns:\n",
    "        lab_df = eb0_features_lab_df[[\"DateTime\", lab_key]]\n",
    "        sensor_df = eb0_sensor_df[[\"DateTime\", sensor_key]]\n",
    "\n",
    "        # remove 0 values from sensor data\n",
    "        sensor_df = sensor_df[sensor_df != 0]\n",
    "        \n",
    "        lab_key = mapping[lab_key]\n",
    "        lab_df.columns = [\"DateTime\", lab_key]\n",
    "\n",
    "        if not lab_df.empty and not sensor_df.empty:\n",
    "            lab_time_range_df = lab_df[\n",
    "                (lab_df[\"DateTime\"] >= sensor_df[\"DateTime\"].min())\n",
    "                & (lab_df[\"DateTime\"] <= sensor_df[\"DateTime\"].max())\n",
    "            ]\n",
    "\n",
    "            sensor_time_range_df = sensor_df[\n",
    "                (sensor_df[\"DateTime\"] >= lab_df[\"DateTime\"].min())\n",
    "                & (sensor_df[\"DateTime\"] <= lab_df[\"DateTime\"].max())\n",
    "            ]\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"DateTime\",\n",
    "                y=lab_key,\n",
    "                data=lab_time_range_df,\n",
    "                color=\"blue\",\n",
    "                label=\"Lab Data\",\n",
    "            )\n",
    "\n",
    "            sns.lineplot(\n",
    "                x=\"DateTime\",\n",
    "                y=sensor_key,\n",
    "                data=sensor_time_range_df,\n",
    "                color=\"red\",\n",
    "                label=\"Sensor Data\",\n",
    "            )\n",
    "            \n",
    "            # plot the number of non-NaN samples in the common time range for lab and sensor data\n",
    "            \n",
    "            count_lab_samples = lab_time_range_df[lab_key].dropna().count()\n",
    "            \n",
    "            count_sensor_samples = sensor_time_range_df[sensor_key].dropna().count()\n",
    "            \n",
    "            # compute mean difference between lab and sensor data with the same time range\n",
    "            # if lab_key == \"Conductivity (µS/cm)\":\n",
    "            \n",
    "            #     mean_diff = np.abs(np.mean(lab_time_range_df[lab_key].dropna().values - sensor_time_range_df[sensor_key].dropna().values))\n",
    "            #     std_diff = np.std(lab_time_range_df[lab_key].dropna().values - sensor_time_range_df[sensor_key].dropna().values)\n",
    "                \n",
    "            #     # add box with the mean difference between lab and sensor data\n",
    "            #     props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "                \n",
    "            #     plt.text(\n",
    "            #         x=lab_time_range_df[\"DateTime\"].min(),\n",
    "            #         y=lab_time_range_df[lab_key].max(),\n",
    "            #         s=f\"Mean Difference: {mean_diff:.2f} ± {std_diff:.2f}\",\n",
    "            #         color=\"black\",\n",
    "            #         fontsize=15,\n",
    "            #         bbox=props,\n",
    "            #     )\n",
    "            \n",
    "            \n",
    "\n",
    "            scaled_lab_df = StandardScaler().fit_transform(\n",
    "                lab_df[lab_key].dropna().values.reshape(-1, 1)\n",
    "            )\n",
    "            scaled_sensor_df = StandardScaler().fit_transform(\n",
    "                sensor_df[sensor_key].dropna().values.reshape(-1, 1)\n",
    "            )\n",
    "\n",
    "            scaled_lab_df = pd.DataFrame(scaled_lab_df, columns=[lab_key])\n",
    "            scaled_sensor_df = pd.DataFrame(scaled_sensor_df, columns=[sensor_key])\n",
    "            \n",
    "            # plot the date such that the year is displayed only once\n",
    "            ax.xaxis.set_major_locator(matplotlib.dates.MonthLocator((1,2,5,8,11)))\n",
    "            \n",
    "            ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%b \\n%Y'))\n",
    "\n",
    "            plt.setp(ax.get_xticklabels(), rotation=0, ha=\"center\")\n",
    "            \n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ks_hypothesis_tests).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(t_hypothesis_tests).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(u_hypothesis_tests).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divs = {}\n",
    "js_divs = {}\n",
    "tv_dists = {}\n",
    "w_dists = {}\n",
    "\n",
    "for lab_key, sensor_key in eb0_features_mapping.items():\n",
    "    # Compute the probability distribution of the feature in each DataFrame\n",
    "    if lab_key not in eb0_features_lab_df.columns:\n",
    "        continue\n",
    "    lab_df = eb0_features_lab_df[lab_key]\n",
    "    sensor_df = eb0_sensor_df[sensor_key]\n",
    "\n",
    "    lab_pdist = np.histogram(lab_df.dropna(), bins=100, density=True)[0]\n",
    "    sensor_pdist = np.histogram(sensor_df.dropna(), bins=100, density=True)[0]\n",
    "\n",
    "    # Add a small constant to avoid division by zero\n",
    "    lab_pdist = lab_pdist + np.finfo(np.float64).eps\n",
    "    sensor_pdist = sensor_pdist + np.finfo(np.float64).eps\n",
    "\n",
    "    # Compute divergence metrics\n",
    "    kl_div = stats.entropy(lab_pdist, sensor_pdist)\n",
    "    js_div = jensenshannon(lab_pdist, sensor_pdist)\n",
    "    tv_dist = np.sum(np.abs(lab_pdist - sensor_pdist)) / 2\n",
    "    w_dist = wasserstein_distance(lab_pdist, sensor_pdist)\n",
    "\n",
    "    kl_divs[lab_key] = kl_div\n",
    "    js_divs[lab_key] = js_div\n",
    "    tv_dists[lab_key] = tv_dist\n",
    "    w_dists[lab_key] = w_dist\n",
    "\n",
    "\n",
    "kl_divs = pd.Series(kl_divs)\n",
    "js_divs = pd.Series(js_divs)\n",
    "tv_dists = pd.Series(tv_dists)\n",
    "w_dists = pd.Series(w_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df.columns = [\n",
    "    normalize_string(c) for c in eb1_features_lab_df.columns\n",
    "]\n",
    "\n",
    "eb1_features_mapping = {\n",
    "    normalize_string(k): v for k, v in eb1_features_mapping.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab_key, sensor_key in eb1_features_mapping.items():\n",
    "    lab_key = normalize_string(lab_key)\n",
    "    if lab_key not in eb1_features_lab_df.columns:\n",
    "        continue\n",
    "    lab_df = eb1_features_lab_df[lab_key]\n",
    "    sensor_df = eb1_sensor_df[sensor_key]\n",
    "\n",
    "    # remove 0 values from sensor data\n",
    "    sensor_df = sensor_df[sensor_df != 0]\n",
    "\n",
    "    if not lab_df.empty and not sensor_df.empty:\n",
    "        plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "        # counts, bins, patches = plt.hist(\n",
    "        #     lab_df,\n",
    "        #     bins=100,\n",
    "        #     color=\"blue\",\n",
    "        #     alpha=0.5,\n",
    "        #     label=\"Lab\",\n",
    "        #     density=True,\n",
    "        # )\n",
    "        # # # Add counts as annotations\n",
    "        # # for count, bin in zip(counts, bins):\n",
    "        # #     plt.text(bin, count, str(int(count)))\n",
    "\n",
    "        # plt.hist(\n",
    "        #     sensor_df,\n",
    "        #     bins=100,\n",
    "        #     color=\"red\",\n",
    "        #     alpha=0.5,\n",
    "        #     label=\"Sensor\",\n",
    "        #     density=True,\n",
    "        # )\n",
    "\n",
    "        sns.histplot(\n",
    "            data=sensor_df,\n",
    "            kde=True,\n",
    "            bins=100,\n",
    "            alpha=0.5,\n",
    "            stat=\"probability\",\n",
    "            label=\"Sensor Data\",\n",
    "        )\n",
    "\n",
    "        sns.histplot(\n",
    "            data=lab_df,\n",
    "            kde=True,\n",
    "            bins=100,\n",
    "            stat=\"probability\",\n",
    "            label=\"Lab Data\",\n",
    "        )\n",
    "\n",
    "        plt.title(lab_key)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # The y-axis of a histplot with stat=\"probability\" corresponds\n",
    "        # to the probability that a value belongs to a certain bar.\n",
    "        # The sum of the bar heights must be 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab_key, sensor_key in eb1_features_mapping.items():\n",
    "    lab_key = normalize_string(lab_key)\n",
    "    if lab_key not in eb1_features_lab_df.columns:\n",
    "        continue\n",
    "    lab_df = eb1_features_lab_df[lab_key]\n",
    "    sensor_df = eb1_sensor_df[sensor_key]\n",
    "\n",
    "    # remove 0 values from sensor data\n",
    "    sensor_df = sensor_df[sensor_df != 0]\n",
    "\n",
    "    if not lab_df.empty and not sensor_df.empty:\n",
    "        plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "        sns.boxplot(data=[lab_df, sensor_df], palette=\"Set3\")\n",
    "\n",
    "        plt.title(lab_key)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab_key, sensor_key in eb1_features_mapping.items():\n",
    "    lab_key = normalize_string(lab_key)\n",
    "    if lab_key not in eb1_features_lab_df.columns:\n",
    "        continue\n",
    "    lab_df = eb1_features_lab_df[[\"DateTime\", lab_key]]\n",
    "    sensor_df = eb1_sensor_df[[\"DateTime\", sensor_key]]\n",
    "\n",
    "    # remove 0 values from sensor data\n",
    "    sensor_df = sensor_df[sensor_df[sensor_key] != 0]\n",
    "\n",
    "    if not lab_df.empty and not sensor_df.empty:\n",
    "        plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "        sns.lineplot(\n",
    "            x=\"DateTime\",\n",
    "            y=lab_key,\n",
    "            data=lab_df,\n",
    "            color=\"blue\",\n",
    "            label=\"Lab Data\",\n",
    "        )\n",
    "\n",
    "        sns.lineplot(\n",
    "            x=\"DateTime\",\n",
    "            y=sensor_key,\n",
    "            data=sensor_df,\n",
    "            color=\"red\",\n",
    "            label=\"Sensor Data\",\n",
    "        )\n",
    "\n",
    "        # sns.scatterplot(\n",
    "        #     x=\"DateTime\",\n",
    "        #     y=sensor_key,\n",
    "        #     data=sensor_df,\n",
    "        #     color=\"red\",\n",
    "        #     label=\"Sensor Data\",)\n",
    "\n",
    "        plt.title(lab_key)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Common Time Range data + Hypothesis Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_hypothesis_tests = {}\n",
    "t_hypothesis_tests = {}\n",
    "u_hypothesis_tests = {}\n",
    "\n",
    "# get common time range samples for lab and sensor data\n",
    "for lab_key, sensor_key in eb1_features_mapping.items():\n",
    "    lab_key = normalize_string(lab_key)\n",
    "    if lab_key not in eb1_features_lab_df.columns:\n",
    "        continue\n",
    "    lab_df = eb1_features_lab_df[[\"DateTime\", lab_key]]\n",
    "    sensor_df = eb1_sensor_df[[\"DateTime\", sensor_key]]\n",
    "\n",
    "    # remove 0 values from sensor data\n",
    "    sensor_df = sensor_df[sensor_df != 0]\n",
    "    \n",
    "    if not lab_df.empty and not sensor_df.empty:\n",
    "        lab_time_range_df = lab_df[\n",
    "            (lab_df[\"DateTime\"] >= sensor_df[\"DateTime\"].min())\n",
    "            & (lab_df[\"DateTime\"] <= sensor_df[\"DateTime\"].max())\n",
    "        ]\n",
    "\n",
    "        sensor_time_range_df = sensor_df[\n",
    "            (sensor_df[\"DateTime\"] >= lab_df[\"DateTime\"].min())\n",
    "            & (sensor_df[\"DateTime\"] <= lab_df[\"DateTime\"].max())\n",
    "        ]\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "\n",
    "        sns.lineplot(\n",
    "            x=\"DateTime\",\n",
    "            y=lab_key,\n",
    "            data=lab_time_range_df,\n",
    "            color=\"blue\",\n",
    "            label=\"Lab Data\",\n",
    "        )\n",
    "\n",
    "        sns.lineplot(\n",
    "            x=\"DateTime\",\n",
    "            y=sensor_key,\n",
    "            data=sensor_time_range_df,\n",
    "            color=\"red\",\n",
    "            label=\"Sensor Data\",\n",
    "        )\n",
    "\n",
    "        # two sample KS test\n",
    "        ks_result, ks_p_value = stats.ks_2samp(\n",
    "            lab_df[lab_key], sensor_df[sensor_key]\n",
    "        )\n",
    "        t_result, t_p_value = stats.ttest_ind(\n",
    "            lab_df[lab_key].dropna(), sensor_df[sensor_key].dropna()\n",
    "        )\n",
    "        u_result, u_p_value = stats.mannwhitneyu(\n",
    "            lab_df[lab_key].dropna(), sensor_df[sensor_key].dropna()\n",
    "        )\n",
    "\n",
    "        ks_hypothesis_tests[lab_key] = {\n",
    "            \"ks_test\": ks_result,\n",
    "            \"p_value\": ks_p_value,\n",
    "        }\n",
    "\n",
    "        t_hypothesis_tests[lab_key] = {\"t_test\": t_result, \"p_value\": t_p_value}\n",
    "\n",
    "        u_hypothesis_tests[lab_key] = {\"u_test\": u_result, \"p_value\": u_p_value}\n",
    "\n",
    "        plt.title(lab_key)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ks_hypothesis_tests).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(t_hypothesis_tests).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(u_hypothesis_tests).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divs = {}\n",
    "js_divs = {}\n",
    "tv_dists = {}\n",
    "w_dists = {}\n",
    "\n",
    "for lab_key, sensor_key in eb1_features_mapping.items():\n",
    "    # Compute the probability distribution of the feature in each DataFrame\n",
    "    if lab_key not in eb1_features_lab_df.columns:\n",
    "        continue\n",
    "    lab_df = eb1_features_lab_df[lab_key]\n",
    "    sensor_df = eb1_sensor_df[sensor_key]\n",
    "\n",
    "    lab_pdist = np.histogram(lab_df.dropna(), bins=100, density=True)[0]\n",
    "    sensor_pdist = np.histogram(sensor_df.dropna(), bins=100, density=True)[0]\n",
    "\n",
    "    # Add a small constant to avoid division by zero\n",
    "    lab_pdist = lab_pdist + np.finfo(np.float64).eps\n",
    "    sensor_pdist = sensor_pdist + np.finfo(np.float64).eps\n",
    "\n",
    "    # Compute divergence metrics\n",
    "    kl_div = stats.entropy(lab_pdist, sensor_pdist)\n",
    "    js_div = jensenshannon(lab_pdist, sensor_pdist)\n",
    "    tv_dist = np.sum(np.abs(lab_pdist - sensor_pdist)) / 2\n",
    "    w_dist = wasserstein_distance(lab_pdist, sensor_pdist)\n",
    "\n",
    "    kl_divs[lab_key] = kl_div\n",
    "    js_divs[lab_key] = js_div\n",
    "    tv_dists[lab_key] = tv_dist\n",
    "    w_dists[lab_key] = w_dist\n",
    "\n",
    "\n",
    "kl_divs = pd.Series(kl_divs)\n",
    "js_divs = pd.Series(js_divs)\n",
    "tv_dists = pd.Series(tv_dists)\n",
    "w_dists = pd.Series(w_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Data Feature-Target Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trihalometh_columns = [\n",
    "    \"Cloroform\",\n",
    "    \"Bromodiclorometà\",\n",
    "    \"Dibromoclorometà\",\n",
    "    \"Bromoform\",\n",
    "]\n",
    "\n",
    "acid_columns = [\n",
    "    \"àcid bromocloroacètic\",\n",
    "    \"àcid dibromoacètic\",\n",
    "    \"àcid dicloroacètic\",\n",
    "    \"àcid monobromoacètic\",\n",
    "    \"àcid monocloroacètic\",\n",
    "]\n",
    "\n",
    "other_columns = [\n",
    "    \"Clorat\",\n",
    "    \"Clorit\",\n",
    "]\n",
    "\n",
    "trihalometh_mapping = {\n",
    "    \"Cloroform\": \"TCM\",\n",
    "    \"Bromodiclorometà\": \"DCBM\",\n",
    "    \"Dibromoclorometà\": \"CDBM\",\n",
    "    \"Bromoform\": \"TBM\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EB1 - THMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eb1_key, thm_key in trihalometh_mapping.items():\n",
    "    plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "    lab_df = eb1_targets_lab_df[[\"DateTime\", eb1_key]]\n",
    "    lab_df = lab_df[lab_df != 0]\n",
    "\n",
    "    thms = thms_df[[\"DateTime\", thm_key]]\n",
    "\n",
    "    sns.lineplot(\n",
    "        x=\"DateTime\", y=eb1_key, data=lab_df, color=\"blue\", label=\"Lab Data\"\n",
    "    )\n",
    "\n",
    "    sns.lineplot(x=\"DateTime\", y=thm_key, data=thms, color=\"red\", label=\"THMs\")\n",
    "\n",
    "    plt.title(eb1_key)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join on same day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_targets_lab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df[\"Date\"] = eb1_features_lab_df[\"DateTime\"].dt.date\n",
    "eb1_targets_lab_df[\"Date\"] = eb1_targets_lab_df[\"DateTime\"].dt.date\n",
    "\n",
    "eb1_lab_df = pd.merge(\n",
    "    eb1_features_lab_df, eb1_targets_lab_df, on=\"Date\", how=\"inner\"\n",
    ")\n",
    "\n",
    "eb1_features_lab_df.drop(columns=[\"Date\"], inplace=True)\n",
    "eb1_targets_lab_df.drop(columns=[\"Date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_lab_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join on previous day EB(t-1) -> THMs(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_features_lab_df[\"Date\"] = eb1_features_lab_df[\"DateTime\"].dt.date\n",
    "eb1_targets_lab_df[\"Date\"] = (\n",
    "    eb1_targets_lab_df[\"DateTime\"] - pd.Timedelta(days=1)\n",
    ").dt.date\n",
    "\n",
    "eb1_lab_df = pd.merge(\n",
    "    eb1_features_lab_df, eb1_targets_lab_df, on=\"Date\", how=\"inner\"\n",
    ")\n",
    "\n",
    "eb1_features_lab_df.drop(columns=[\"Date\"], inplace=True)\n",
    "eb1_targets_lab_df.drop(columns=[\"Date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb1_lab_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Tests Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safecrew-3OLHM_8n-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
